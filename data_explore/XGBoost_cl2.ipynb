{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.linalg import LinAlgError\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import reduce_mem_usage, read_csv, datapath, drop_features, tmppath, Box_Cox, train_drop_features, getTrainTest, minmax_target, combine_feature, auto_feature_make\n",
    "\n",
    "from base import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 3.96 MB\n",
      "Decreased by 50.8%\n",
      "Memory usage after optimization is: 1.14 MB\n",
      "Decreased by 50.0%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(read_csv(tmppath + 'Box_Subtrain.csv'))\n",
    "test = reduce_mem_usage(read_csv(tmppath + 'Box_Subtest.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['emd_lable2'], axis=1)\n",
    "Y_train = train['emd_lable2'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_list = ['seg_flight', 'seg_cabin', 'pref_orig_m6_2', 'pref_line_y1_2',\n",
    "                 'pref_line_y1_3', 'pref_line_y2_2', 'pref_line_y2_3', 'pref_line_y3_3'\n",
    "    , 'pref_line_y3_4', 'pref_line_y3_5', 'pref_aircraft_y3_3', 'pref_city_y1_2',\n",
    "                 'pref_city_y3_4', 'pref_dest_city_m6', 'pref_dest_city_y3'\n",
    "    , 'pref_month_y3_1', 'seg_dep_time_month']  # 训练中需要剔除的特征都是离散型的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = X_train.columns.tolist()\n",
    "continue_list = list(set(feature_list) - set(discrete_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = minmax_target(X_train, test, Y_train, continue_list, discrete_list) # 离散值编码与连续特征归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =getTrainTest(X_train, Y_train)# 线下验证，80%训练集，20%验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train[continue_list], label=y_train)\n",
    "dtest = xgb.DMatrix(x_test[continue_list], label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=3,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=10000,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0,\n",
    "                     min_child_weight=5,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'base_score': None,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 5,\n",
       " 'monotone_constraints': None,\n",
       " 'n_jobs': 4,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 0.8,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None,\n",
       " 'seed': 27}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.get_xgb_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "初始自定义参数下的得分结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.6235640301318268 0.9208733179908042\n",
      "f1= 0.3556581986143187 0.9098398169336385\n",
      "precision_score= 0.5579710144927537 0.9890547263681592\n",
      "recall_score= 0.26101694915254237 0.8423728813559322\n",
      "accuracy= 0.9404736505227225 0.9894905308082155\n",
      "auc= 0.6235640301318268 0.9208733179908042\n",
      "#####混淆矩阵#########\n",
      "[[4331   61]\n",
      " [ 218   77]] [[17554    11]\n",
      " [  186   994]]\n"
     ]
    }
   ],
   "source": [
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[0]\ttrain-auc:0.65991+0.00298\ttest-auc:0.65879+0.01129\n",
      "[1]\ttrain-auc:0.66150+0.00346\ttest-auc:0.65958+0.01008\n",
      "[2]\ttrain-auc:0.66822+0.00615\ttest-auc:0.66270+0.01364\n",
      "[3]\ttrain-auc:0.66921+0.00535\ttest-auc:0.66616+0.01110\n",
      "[4]\ttrain-auc:0.67106+0.00484\ttest-auc:0.66835+0.01233\n",
      "[5]\ttrain-auc:0.67225+0.00446\ttest-auc:0.66882+0.01203\n",
      "[6]\ttrain-auc:0.67511+0.00457\ttest-auc:0.67103+0.01148\n",
      "[7]\ttrain-auc:0.67577+0.00389\ttest-auc:0.67126+0.01081\n",
      "[8]\ttrain-auc:0.67801+0.00490\ttest-auc:0.67399+0.01531\n",
      "[9]\ttrain-auc:0.69049+0.00794\ttest-auc:0.68302+0.01252\n",
      "[10]\ttrain-auc:0.69421+0.00720\ttest-auc:0.68607+0.00950\n",
      "[11]\ttrain-auc:0.69954+0.00990\ttest-auc:0.68964+0.00832\n",
      "[12]\ttrain-auc:0.70463+0.01239\ttest-auc:0.69371+0.01000\n",
      "[13]\ttrain-auc:0.70634+0.01213\ttest-auc:0.69384+0.00862\n",
      "[14]\ttrain-auc:0.71120+0.01138\ttest-auc:0.70034+0.01196\n",
      "[15]\ttrain-auc:0.71699+0.01030\ttest-auc:0.70520+0.01587\n",
      "[16]\ttrain-auc:0.71868+0.00964\ttest-auc:0.70550+0.01291\n",
      "[17]\ttrain-auc:0.71973+0.00881\ttest-auc:0.70562+0.01253\n",
      "[18]\ttrain-auc:0.72168+0.00892\ttest-auc:0.70798+0.01376\n",
      "[19]\ttrain-auc:0.72381+0.00532\ttest-auc:0.71095+0.01768\n",
      "[20]\ttrain-auc:0.72644+0.00468\ttest-auc:0.71443+0.01920\n",
      "[21]\ttrain-auc:0.72778+0.00586\ttest-auc:0.71522+0.01737\n",
      "[22]\ttrain-auc:0.72870+0.00814\ttest-auc:0.71492+0.01619\n",
      "[23]\ttrain-auc:0.73017+0.00811\ttest-auc:0.71558+0.01613\n",
      "[24]\ttrain-auc:0.73120+0.00654\ttest-auc:0.71717+0.01795\n",
      "[25]\ttrain-auc:0.73358+0.00671\ttest-auc:0.71848+0.01787\n",
      "[26]\ttrain-auc:0.73474+0.00605\ttest-auc:0.71899+0.01908\n",
      "[27]\ttrain-auc:0.73592+0.00617\ttest-auc:0.71964+0.01897\n",
      "[28]\ttrain-auc:0.73614+0.00650\ttest-auc:0.71879+0.01845\n",
      "[29]\ttrain-auc:0.73842+0.00542\ttest-auc:0.72021+0.01962\n",
      "[30]\ttrain-auc:0.74003+0.00521\ttest-auc:0.72088+0.02014\n",
      "[31]\ttrain-auc:0.74106+0.00555\ttest-auc:0.72111+0.01976\n",
      "[32]\ttrain-auc:0.74311+0.00576\ttest-auc:0.72328+0.01938\n",
      "[33]\ttrain-auc:0.74386+0.00564\ttest-auc:0.72401+0.01989\n",
      "[34]\ttrain-auc:0.74491+0.00539\ttest-auc:0.72432+0.01995\n",
      "[35]\ttrain-auc:0.74738+0.00624\ttest-auc:0.72619+0.01895\n",
      "[36]\ttrain-auc:0.74838+0.00576\ttest-auc:0.72598+0.01920\n",
      "[37]\ttrain-auc:0.75009+0.00574\ttest-auc:0.72737+0.01881\n",
      "[38]\ttrain-auc:0.75115+0.00529\ttest-auc:0.72742+0.01887\n",
      "[39]\ttrain-auc:0.75224+0.00552\ttest-auc:0.72766+0.01891\n",
      "[40]\ttrain-auc:0.75345+0.00569\ttest-auc:0.72734+0.01851\n",
      "[41]\ttrain-auc:0.75524+0.00482\ttest-auc:0.72862+0.02033\n",
      "[42]\ttrain-auc:0.75577+0.00508\ttest-auc:0.72810+0.02097\n",
      "[43]\ttrain-auc:0.75617+0.00560\ttest-auc:0.72844+0.02103\n",
      "[44]\ttrain-auc:0.75786+0.00477\ttest-auc:0.72939+0.02189\n",
      "[45]\ttrain-auc:0.75851+0.00464\ttest-auc:0.72965+0.02178\n",
      "[46]\ttrain-auc:0.75970+0.00420\ttest-auc:0.72992+0.02216\n",
      "[47]\ttrain-auc:0.76081+0.00403\ttest-auc:0.73030+0.02145\n",
      "[48]\ttrain-auc:0.76148+0.00353\ttest-auc:0.73072+0.02164\n",
      "[49]\ttrain-auc:0.76310+0.00462\ttest-auc:0.73186+0.02125\n",
      "[50]\ttrain-auc:0.76451+0.00429\ttest-auc:0.73209+0.02102\n",
      "[51]\ttrain-auc:0.76515+0.00447\ttest-auc:0.73239+0.02174\n",
      "[52]\ttrain-auc:0.76691+0.00477\ttest-auc:0.73351+0.02137\n",
      "[53]\ttrain-auc:0.76803+0.00465\ttest-auc:0.73373+0.02119\n",
      "[54]\ttrain-auc:0.76893+0.00464\ttest-auc:0.73423+0.02135\n",
      "[55]\ttrain-auc:0.76946+0.00468\ttest-auc:0.73391+0.02126\n",
      "[56]\ttrain-auc:0.77046+0.00468\ttest-auc:0.73411+0.02103\n",
      "[57]\ttrain-auc:0.77106+0.00444\ttest-auc:0.73384+0.02089\n",
      "[58]\ttrain-auc:0.77210+0.00472\ttest-auc:0.73427+0.02137\n",
      "[59]\ttrain-auc:0.77323+0.00518\ttest-auc:0.73434+0.02094\n",
      "[60]\ttrain-auc:0.77401+0.00504\ttest-auc:0.73437+0.02141\n",
      "[61]\ttrain-auc:0.77475+0.00538\ttest-auc:0.73416+0.02112\n",
      "[62]\ttrain-auc:0.77537+0.00558\ttest-auc:0.73408+0.02121\n",
      "[63]\ttrain-auc:0.77608+0.00570\ttest-auc:0.73462+0.02022\n",
      "[64]\ttrain-auc:0.77699+0.00587\ttest-auc:0.73532+0.02014\n",
      "[65]\ttrain-auc:0.77754+0.00600\ttest-auc:0.73555+0.02009\n",
      "[66]\ttrain-auc:0.77837+0.00583\ttest-auc:0.73636+0.02003\n",
      "[67]\ttrain-auc:0.77907+0.00570\ttest-auc:0.73685+0.01935\n",
      "[68]\ttrain-auc:0.77986+0.00620\ttest-auc:0.73653+0.01923\n",
      "[69]\ttrain-auc:0.78065+0.00632\ttest-auc:0.73707+0.01869\n",
      "[70]\ttrain-auc:0.78136+0.00645\ttest-auc:0.73695+0.01844\n",
      "[71]\ttrain-auc:0.78229+0.00644\ttest-auc:0.73706+0.01844\n",
      "[72]\ttrain-auc:0.78289+0.00650\ttest-auc:0.73673+0.01900\n",
      "[73]\ttrain-auc:0.78343+0.00671\ttest-auc:0.73728+0.01914\n",
      "[74]\ttrain-auc:0.78437+0.00723\ttest-auc:0.73793+0.01859\n",
      "[75]\ttrain-auc:0.78531+0.00681\ttest-auc:0.73816+0.01909\n",
      "[76]\ttrain-auc:0.78601+0.00681\ttest-auc:0.73804+0.01920\n",
      "[77]\ttrain-auc:0.78681+0.00638\ttest-auc:0.73802+0.01925\n",
      "[78]\ttrain-auc:0.78738+0.00658\ttest-auc:0.73788+0.01919\n",
      "[79]\ttrain-auc:0.78805+0.00682\ttest-auc:0.73792+0.01914\n",
      "[80]\ttrain-auc:0.78875+0.00653\ttest-auc:0.73823+0.01941\n",
      "[81]\ttrain-auc:0.78936+0.00654\ttest-auc:0.73830+0.01983\n",
      "[82]\ttrain-auc:0.78959+0.00664\ttest-auc:0.73791+0.01975\n",
      "[83]\ttrain-auc:0.79007+0.00648\ttest-auc:0.73791+0.02031\n",
      "[84]\ttrain-auc:0.79125+0.00616\ttest-auc:0.73809+0.02062\n",
      "[85]\ttrain-auc:0.79159+0.00609\ttest-auc:0.73813+0.02043\n",
      "[86]\ttrain-auc:0.79180+0.00619\ttest-auc:0.73810+0.02019\n",
      "[87]\ttrain-auc:0.79246+0.00610\ttest-auc:0.73834+0.02034\n",
      "[88]\ttrain-auc:0.79286+0.00614\ttest-auc:0.73852+0.02028\n",
      "[89]\ttrain-auc:0.79344+0.00629\ttest-auc:0.73884+0.02032\n",
      "[90]\ttrain-auc:0.79408+0.00594\ttest-auc:0.73865+0.02053\n",
      "[91]\ttrain-auc:0.79468+0.00569\ttest-auc:0.73839+0.02017\n",
      "[92]\ttrain-auc:0.79503+0.00576\ttest-auc:0.73833+0.01989\n",
      "[93]\ttrain-auc:0.79546+0.00577\ttest-auc:0.73819+0.02022\n",
      "[94]\ttrain-auc:0.79599+0.00554\ttest-auc:0.73799+0.02080\n",
      "[95]\ttrain-auc:0.79640+0.00551\ttest-auc:0.73766+0.02070\n",
      "[96]\ttrain-auc:0.79680+0.00564\ttest-auc:0.73805+0.02096\n",
      "[97]\ttrain-auc:0.79754+0.00564\ttest-auc:0.73783+0.02097\n",
      "[98]\ttrain-auc:0.79825+0.00582\ttest-auc:0.73753+0.02105\n",
      "[99]\ttrain-auc:0.79857+0.00585\ttest-auc:0.73767+0.02096\n",
      "[100]\ttrain-auc:0.79931+0.00561\ttest-auc:0.73798+0.02111\n",
      "[101]\ttrain-auc:0.79960+0.00585\ttest-auc:0.73821+0.02107\n",
      "[102]\ttrain-auc:0.80057+0.00572\ttest-auc:0.73878+0.02107\n",
      "[103]\ttrain-auc:0.80130+0.00531\ttest-auc:0.73904+0.02100\n",
      "[104]\ttrain-auc:0.80182+0.00546\ttest-auc:0.73917+0.02083\n",
      "[105]\ttrain-auc:0.80229+0.00538\ttest-auc:0.73947+0.02091\n",
      "[106]\ttrain-auc:0.80272+0.00545\ttest-auc:0.73944+0.02087\n",
      "[107]\ttrain-auc:0.80350+0.00503\ttest-auc:0.73933+0.02070\n",
      "[108]\ttrain-auc:0.80375+0.00497\ttest-auc:0.73948+0.02069\n",
      "[109]\ttrain-auc:0.80448+0.00509\ttest-auc:0.73950+0.02075\n",
      "[110]\ttrain-auc:0.80523+0.00505\ttest-auc:0.74019+0.02052\n",
      "[111]\ttrain-auc:0.80559+0.00483\ttest-auc:0.74032+0.02039\n",
      "[112]\ttrain-auc:0.80602+0.00488\ttest-auc:0.74037+0.02048\n",
      "[113]\ttrain-auc:0.80664+0.00487\ttest-auc:0.74044+0.02027\n",
      "[114]\ttrain-auc:0.80727+0.00484\ttest-auc:0.74125+0.01995\n",
      "[115]\ttrain-auc:0.80783+0.00461\ttest-auc:0.74110+0.01970\n",
      "[116]\ttrain-auc:0.80863+0.00439\ttest-auc:0.74121+0.02025\n",
      "[117]\ttrain-auc:0.80888+0.00434\ttest-auc:0.74103+0.02031\n",
      "[118]\ttrain-auc:0.80937+0.00434\ttest-auc:0.74087+0.02011\n",
      "[119]\ttrain-auc:0.80997+0.00460\ttest-auc:0.74094+0.01982\n",
      "[120]\ttrain-auc:0.81033+0.00438\ttest-auc:0.74099+0.01968\n",
      "[121]\ttrain-auc:0.81073+0.00447\ttest-auc:0.74098+0.01986\n",
      "[122]\ttrain-auc:0.81134+0.00459\ttest-auc:0.74126+0.01968\n",
      "[123]\ttrain-auc:0.81167+0.00469\ttest-auc:0.74170+0.01966\n",
      "[124]\ttrain-auc:0.81243+0.00478\ttest-auc:0.74158+0.01977\n",
      "[125]\ttrain-auc:0.81287+0.00472\ttest-auc:0.74175+0.01977\n",
      "[126]\ttrain-auc:0.81357+0.00463\ttest-auc:0.74190+0.01997\n",
      "[127]\ttrain-auc:0.81423+0.00437\ttest-auc:0.74206+0.02009\n",
      "[128]\ttrain-auc:0.81477+0.00435\ttest-auc:0.74224+0.01998\n",
      "[129]\ttrain-auc:0.81517+0.00441\ttest-auc:0.74242+0.02010\n",
      "[130]\ttrain-auc:0.81545+0.00440\ttest-auc:0.74235+0.01998\n",
      "[131]\ttrain-auc:0.81584+0.00429\ttest-auc:0.74245+0.02011\n",
      "[132]\ttrain-auc:0.81622+0.00443\ttest-auc:0.74260+0.02009\n",
      "[133]\ttrain-auc:0.81660+0.00463\ttest-auc:0.74259+0.02019\n",
      "[134]\ttrain-auc:0.81694+0.00446\ttest-auc:0.74275+0.02013\n",
      "[135]\ttrain-auc:0.81747+0.00446\ttest-auc:0.74310+0.02023\n",
      "[136]\ttrain-auc:0.81781+0.00452\ttest-auc:0.74288+0.02025\n",
      "[137]\ttrain-auc:0.81812+0.00443\ttest-auc:0.74335+0.02053\n",
      "[138]\ttrain-auc:0.81844+0.00441\ttest-auc:0.74317+0.02070\n",
      "[139]\ttrain-auc:0.81866+0.00443\ttest-auc:0.74346+0.02054\n",
      "[140]\ttrain-auc:0.81904+0.00454\ttest-auc:0.74326+0.02064\n",
      "[141]\ttrain-auc:0.81929+0.00434\ttest-auc:0.74285+0.02091\n",
      "[142]\ttrain-auc:0.81963+0.00424\ttest-auc:0.74296+0.02119\n",
      "[143]\ttrain-auc:0.81999+0.00414\ttest-auc:0.74279+0.02124\n",
      "[144]\ttrain-auc:0.82054+0.00404\ttest-auc:0.74275+0.02150\n",
      "[145]\ttrain-auc:0.82096+0.00424\ttest-auc:0.74310+0.02165\n",
      "[146]\ttrain-auc:0.82125+0.00413\ttest-auc:0.74295+0.02167\n",
      "[147]\ttrain-auc:0.82162+0.00396\ttest-auc:0.74296+0.02170\n",
      "[148]\ttrain-auc:0.82208+0.00374\ttest-auc:0.74299+0.02164\n",
      "[149]\ttrain-auc:0.82233+0.00368\ttest-auc:0.74279+0.02150\n",
      "[150]\ttrain-auc:0.82275+0.00372\ttest-auc:0.74295+0.02159\n",
      "[151]\ttrain-auc:0.82319+0.00365\ttest-auc:0.74307+0.02192\n",
      "[152]\ttrain-auc:0.82338+0.00351\ttest-auc:0.74281+0.02214\n",
      "[153]\ttrain-auc:0.82371+0.00357\ttest-auc:0.74295+0.02206\n",
      "[154]\ttrain-auc:0.82394+0.00357\ttest-auc:0.74309+0.02185\n",
      "[155]\ttrain-auc:0.82431+0.00348\ttest-auc:0.74356+0.02187\n",
      "[156]\ttrain-auc:0.82480+0.00364\ttest-auc:0.74357+0.02195\n",
      "[157]\ttrain-auc:0.82524+0.00367\ttest-auc:0.74375+0.02173\n",
      "[158]\ttrain-auc:0.82553+0.00374\ttest-auc:0.74402+0.02195\n",
      "[159]\ttrain-auc:0.82578+0.00375\ttest-auc:0.74416+0.02209\n",
      "[160]\ttrain-auc:0.82613+0.00371\ttest-auc:0.74420+0.02213\n",
      "[161]\ttrain-auc:0.82638+0.00370\ttest-auc:0.74422+0.02218\n",
      "[162]\ttrain-auc:0.82664+0.00371\ttest-auc:0.74410+0.02199\n",
      "[163]\ttrain-auc:0.82703+0.00360\ttest-auc:0.74439+0.02216\n",
      "[164]\ttrain-auc:0.82754+0.00337\ttest-auc:0.74445+0.02151\n",
      "[165]\ttrain-auc:0.82784+0.00326\ttest-auc:0.74453+0.02120\n",
      "[166]\ttrain-auc:0.82829+0.00319\ttest-auc:0.74475+0.02137\n",
      "[167]\ttrain-auc:0.82843+0.00317\ttest-auc:0.74474+0.02122\n",
      "[168]\ttrain-auc:0.82874+0.00308\ttest-auc:0.74502+0.02119\n",
      "[169]\ttrain-auc:0.82905+0.00307\ttest-auc:0.74493+0.02137\n",
      "[170]\ttrain-auc:0.82942+0.00330\ttest-auc:0.74521+0.02113\n",
      "[171]\ttrain-auc:0.82964+0.00327\ttest-auc:0.74505+0.02131\n",
      "[172]\ttrain-auc:0.82992+0.00330\ttest-auc:0.74527+0.02102\n",
      "[173]\ttrain-auc:0.83038+0.00330\ttest-auc:0.74529+0.02119\n",
      "[174]\ttrain-auc:0.83063+0.00333\ttest-auc:0.74516+0.02130\n",
      "[175]\ttrain-auc:0.83101+0.00337\ttest-auc:0.74540+0.02105\n",
      "[176]\ttrain-auc:0.83148+0.00332\ttest-auc:0.74512+0.02109\n",
      "[177]\ttrain-auc:0.83192+0.00349\ttest-auc:0.74525+0.02087\n",
      "[178]\ttrain-auc:0.83233+0.00356\ttest-auc:0.74515+0.02112\n",
      "[179]\ttrain-auc:0.83266+0.00372\ttest-auc:0.74532+0.02101\n",
      "[180]\ttrain-auc:0.83293+0.00368\ttest-auc:0.74566+0.02119\n",
      "[181]\ttrain-auc:0.83325+0.00367\ttest-auc:0.74584+0.02118\n",
      "[182]\ttrain-auc:0.83338+0.00378\ttest-auc:0.74607+0.02101\n",
      "[183]\ttrain-auc:0.83369+0.00389\ttest-auc:0.74617+0.02095\n",
      "[184]\ttrain-auc:0.83391+0.00395\ttest-auc:0.74661+0.02069\n",
      "[185]\ttrain-auc:0.83422+0.00394\ttest-auc:0.74659+0.02071\n",
      "[186]\ttrain-auc:0.83461+0.00406\ttest-auc:0.74638+0.02077\n",
      "[187]\ttrain-auc:0.83489+0.00388\ttest-auc:0.74629+0.02068\n",
      "[188]\ttrain-auc:0.83519+0.00399\ttest-auc:0.74661+0.02064\n",
      "[189]\ttrain-auc:0.83550+0.00412\ttest-auc:0.74672+0.02049\n",
      "[190]\ttrain-auc:0.83596+0.00400\ttest-auc:0.74636+0.02076\n",
      "[191]\ttrain-auc:0.83607+0.00393\ttest-auc:0.74639+0.02082\n",
      "[192]\ttrain-auc:0.83612+0.00400\ttest-auc:0.74616+0.02086\n",
      "[193]\ttrain-auc:0.83639+0.00415\ttest-auc:0.74595+0.02086\n",
      "[194]\ttrain-auc:0.83657+0.00411\ttest-auc:0.74599+0.02103\n",
      "[195]\ttrain-auc:0.83672+0.00416\ttest-auc:0.74571+0.02104\n",
      "[196]\ttrain-auc:0.83697+0.00405\ttest-auc:0.74596+0.02125\n",
      "[197]\ttrain-auc:0.83723+0.00396\ttest-auc:0.74602+0.02141\n",
      "[198]\ttrain-auc:0.83751+0.00404\ttest-auc:0.74568+0.02158\n",
      "[199]\ttrain-auc:0.83774+0.00409\ttest-auc:0.74567+0.02163\n",
      "[200]\ttrain-auc:0.83804+0.00408\ttest-auc:0.74568+0.02171\n",
      "[201]\ttrain-auc:0.83837+0.00414\ttest-auc:0.74573+0.02165\n",
      "[202]\ttrain-auc:0.83876+0.00405\ttest-auc:0.74571+0.02201\n",
      "[203]\ttrain-auc:0.83895+0.00415\ttest-auc:0.74551+0.02212\n",
      "[204]\ttrain-auc:0.83929+0.00403\ttest-auc:0.74572+0.02212\n",
      "[205]\ttrain-auc:0.83963+0.00404\ttest-auc:0.74595+0.02214\n",
      "[206]\ttrain-auc:0.83988+0.00423\ttest-auc:0.74599+0.02208\n",
      "[207]\ttrain-auc:0.84019+0.00430\ttest-auc:0.74633+0.02218\n",
      "[208]\ttrain-auc:0.84037+0.00421\ttest-auc:0.74648+0.02194\n",
      "[209]\ttrain-auc:0.84051+0.00429\ttest-auc:0.74652+0.02191\n",
      "[210]\ttrain-auc:0.84061+0.00441\ttest-auc:0.74665+0.02191\n",
      "[211]\ttrain-auc:0.84083+0.00431\ttest-auc:0.74640+0.02175\n",
      "[212]\ttrain-auc:0.84111+0.00424\ttest-auc:0.74645+0.02174\n",
      "[213]\ttrain-auc:0.84135+0.00422\ttest-auc:0.74670+0.02179\n",
      "[214]\ttrain-auc:0.84149+0.00419\ttest-auc:0.74678+0.02157\n",
      "[215]\ttrain-auc:0.84173+0.00414\ttest-auc:0.74672+0.02166\n",
      "[216]\ttrain-auc:0.84214+0.00417\ttest-auc:0.74676+0.02203\n",
      "[217]\ttrain-auc:0.84224+0.00415\ttest-auc:0.74681+0.02200\n",
      "[218]\ttrain-auc:0.84242+0.00417\ttest-auc:0.74695+0.02208\n",
      "[219]\ttrain-auc:0.84276+0.00422\ttest-auc:0.74696+0.02220\n",
      "[220]\ttrain-auc:0.84297+0.00407\ttest-auc:0.74708+0.02238\n",
      "[221]\ttrain-auc:0.84319+0.00414\ttest-auc:0.74729+0.02219\n",
      "[222]\ttrain-auc:0.84355+0.00419\ttest-auc:0.74748+0.02243\n",
      "[223]\ttrain-auc:0.84389+0.00411\ttest-auc:0.74784+0.02237\n",
      "[224]\ttrain-auc:0.84416+0.00422\ttest-auc:0.74784+0.02229\n",
      "[225]\ttrain-auc:0.84440+0.00427\ttest-auc:0.74786+0.02225\n",
      "[226]\ttrain-auc:0.84484+0.00408\ttest-auc:0.74783+0.02208\n",
      "[227]\ttrain-auc:0.84529+0.00407\ttest-auc:0.74791+0.02199\n",
      "[228]\ttrain-auc:0.84553+0.00422\ttest-auc:0.74763+0.02195\n",
      "[229]\ttrain-auc:0.84582+0.00420\ttest-auc:0.74758+0.02205\n",
      "[230]\ttrain-auc:0.84597+0.00414\ttest-auc:0.74741+0.02208\n",
      "[231]\ttrain-auc:0.84622+0.00419\ttest-auc:0.74720+0.02219\n",
      "[232]\ttrain-auc:0.84650+0.00405\ttest-auc:0.74747+0.02248\n",
      "[233]\ttrain-auc:0.84681+0.00409\ttest-auc:0.74744+0.02255\n",
      "[234]\ttrain-auc:0.84704+0.00418\ttest-auc:0.74754+0.02238\n",
      "[235]\ttrain-auc:0.84728+0.00409\ttest-auc:0.74738+0.02236\n",
      "[236]\ttrain-auc:0.84736+0.00411\ttest-auc:0.74719+0.02230\n",
      "[237]\ttrain-auc:0.84761+0.00414\ttest-auc:0.74703+0.02240\n",
      "[238]\ttrain-auc:0.84792+0.00389\ttest-auc:0.74722+0.02248\n",
      "[239]\ttrain-auc:0.84821+0.00379\ttest-auc:0.74720+0.02234\n",
      "[240]\ttrain-auc:0.84834+0.00382\ttest-auc:0.74717+0.02254\n",
      "[241]\ttrain-auc:0.84871+0.00391\ttest-auc:0.74743+0.02220\n",
      "[242]\ttrain-auc:0.84885+0.00396\ttest-auc:0.74738+0.02223\n",
      "[243]\ttrain-auc:0.84914+0.00387\ttest-auc:0.74752+0.02216\n",
      "[244]\ttrain-auc:0.84932+0.00372\ttest-auc:0.74758+0.02219\n",
      "[245]\ttrain-auc:0.84966+0.00376\ttest-auc:0.74742+0.02211\n",
      "[246]\ttrain-auc:0.84981+0.00373\ttest-auc:0.74746+0.02186\n",
      "[247]\ttrain-auc:0.85027+0.00362\ttest-auc:0.74759+0.02157\n",
      "[248]\ttrain-auc:0.85060+0.00358\ttest-auc:0.74784+0.02178\n",
      "[249]\ttrain-auc:0.85081+0.00347\ttest-auc:0.74778+0.02173\n",
      "[250]\ttrain-auc:0.85097+0.00353\ttest-auc:0.74783+0.02179\n",
      "[251]\ttrain-auc:0.85124+0.00356\ttest-auc:0.74778+0.02185\n",
      "[252]\ttrain-auc:0.85146+0.00348\ttest-auc:0.74779+0.02181\n",
      "[253]\ttrain-auc:0.85176+0.00362\ttest-auc:0.74780+0.02170\n",
      "[254]\ttrain-auc:0.85198+0.00351\ttest-auc:0.74783+0.02197\n",
      "[255]\ttrain-auc:0.85210+0.00351\ttest-auc:0.74786+0.02187\n",
      "[256]\ttrain-auc:0.85241+0.00348\ttest-auc:0.74813+0.02186\n",
      "[257]\ttrain-auc:0.85264+0.00342\ttest-auc:0.74812+0.02194\n",
      "[258]\ttrain-auc:0.85283+0.00336\ttest-auc:0.74797+0.02180\n",
      "[259]\ttrain-auc:0.85299+0.00328\ttest-auc:0.74815+0.02164\n",
      "[260]\ttrain-auc:0.85307+0.00328\ttest-auc:0.74825+0.02166\n",
      "[261]\ttrain-auc:0.85326+0.00322\ttest-auc:0.74804+0.02157\n",
      "[262]\ttrain-auc:0.85351+0.00320\ttest-auc:0.74806+0.02159\n",
      "[263]\ttrain-auc:0.85358+0.00322\ttest-auc:0.74817+0.02170\n",
      "[264]\ttrain-auc:0.85379+0.00329\ttest-auc:0.74825+0.02183\n",
      "[265]\ttrain-auc:0.85397+0.00338\ttest-auc:0.74823+0.02168\n",
      "[266]\ttrain-auc:0.85416+0.00340\ttest-auc:0.74812+0.02168\n",
      "[267]\ttrain-auc:0.85445+0.00348\ttest-auc:0.74808+0.02160\n",
      "[268]\ttrain-auc:0.85463+0.00344\ttest-auc:0.74814+0.02158\n",
      "[269]\ttrain-auc:0.85473+0.00344\ttest-auc:0.74832+0.02162\n",
      "[270]\ttrain-auc:0.85497+0.00351\ttest-auc:0.74810+0.02166\n",
      "[271]\ttrain-auc:0.85530+0.00323\ttest-auc:0.74801+0.02182\n",
      "[272]\ttrain-auc:0.85550+0.00316\ttest-auc:0.74812+0.02203\n",
      "[273]\ttrain-auc:0.85569+0.00313\ttest-auc:0.74808+0.02189\n",
      "[274]\ttrain-auc:0.85583+0.00310\ttest-auc:0.74818+0.02178\n",
      "[275]\ttrain-auc:0.85594+0.00317\ttest-auc:0.74805+0.02187\n",
      "[276]\ttrain-auc:0.85613+0.00318\ttest-auc:0.74825+0.02172\n",
      "[277]\ttrain-auc:0.85635+0.00326\ttest-auc:0.74812+0.02175\n",
      "[278]\ttrain-auc:0.85656+0.00336\ttest-auc:0.74805+0.02176\n",
      "[279]\ttrain-auc:0.85683+0.00337\ttest-auc:0.74816+0.02180\n",
      "[280]\ttrain-auc:0.85701+0.00345\ttest-auc:0.74822+0.02170\n",
      "[281]\ttrain-auc:0.85721+0.00349\ttest-auc:0.74828+0.02169\n",
      "[282]\ttrain-auc:0.85742+0.00347\ttest-auc:0.74823+0.02150\n",
      "[283]\ttrain-auc:0.85754+0.00356\ttest-auc:0.74827+0.02151\n",
      "[284]\ttrain-auc:0.85769+0.00358\ttest-auc:0.74819+0.02146\n",
      "[285]\ttrain-auc:0.85782+0.00347\ttest-auc:0.74821+0.02154\n",
      "[286]\ttrain-auc:0.85816+0.00335\ttest-auc:0.74841+0.02164\n",
      "[287]\ttrain-auc:0.85845+0.00342\ttest-auc:0.74857+0.02135\n",
      "[288]\ttrain-auc:0.85858+0.00349\ttest-auc:0.74860+0.02126\n",
      "[289]\ttrain-auc:0.85884+0.00343\ttest-auc:0.74851+0.02137\n",
      "[290]\ttrain-auc:0.85901+0.00347\ttest-auc:0.74835+0.02125\n",
      "[291]\ttrain-auc:0.85926+0.00359\ttest-auc:0.74833+0.02112\n",
      "[292]\ttrain-auc:0.85937+0.00359\ttest-auc:0.74846+0.02122\n",
      "[293]\ttrain-auc:0.85962+0.00355\ttest-auc:0.74844+0.02119\n",
      "[294]\ttrain-auc:0.85986+0.00370\ttest-auc:0.74851+0.02123\n",
      "[295]\ttrain-auc:0.86009+0.00368\ttest-auc:0.74839+0.02128\n",
      "[296]\ttrain-auc:0.86041+0.00364\ttest-auc:0.74841+0.02140\n",
      "[297]\ttrain-auc:0.86060+0.00366\ttest-auc:0.74841+0.02134\n",
      "[298]\ttrain-auc:0.86075+0.00360\ttest-auc:0.74841+0.02140\n",
      "[299]\ttrain-auc:0.86087+0.00360\ttest-auc:0.74844+0.02149\n",
      "[300]\ttrain-auc:0.86095+0.00363\ttest-auc:0.74828+0.02164\n",
      "[301]\ttrain-auc:0.86112+0.00352\ttest-auc:0.74831+0.02153\n",
      "[302]\ttrain-auc:0.86131+0.00373\ttest-auc:0.74837+0.02141\n",
      "[303]\ttrain-auc:0.86151+0.00373\ttest-auc:0.74845+0.02158\n",
      "[304]\ttrain-auc:0.86155+0.00367\ttest-auc:0.74853+0.02141\n",
      "[305]\ttrain-auc:0.86184+0.00377\ttest-auc:0.74864+0.02132\n",
      "[306]\ttrain-auc:0.86201+0.00373\ttest-auc:0.74884+0.02136\n",
      "[307]\ttrain-auc:0.86225+0.00372\ttest-auc:0.74901+0.02107\n",
      "[308]\ttrain-auc:0.86246+0.00371\ttest-auc:0.74873+0.02121\n",
      "[309]\ttrain-auc:0.86254+0.00377\ttest-auc:0.74886+0.02122\n",
      "[310]\ttrain-auc:0.86264+0.00382\ttest-auc:0.74887+0.02126\n",
      "[311]\ttrain-auc:0.86275+0.00385\ttest-auc:0.74885+0.02132\n",
      "[312]\ttrain-auc:0.86280+0.00390\ttest-auc:0.74912+0.02121\n",
      "[313]\ttrain-auc:0.86302+0.00394\ttest-auc:0.74908+0.02121\n",
      "[314]\ttrain-auc:0.86327+0.00398\ttest-auc:0.74904+0.02115\n",
      "[315]\ttrain-auc:0.86343+0.00400\ttest-auc:0.74918+0.02110\n",
      "[316]\ttrain-auc:0.86352+0.00406\ttest-auc:0.74900+0.02110\n",
      "[317]\ttrain-auc:0.86389+0.00397\ttest-auc:0.74892+0.02098\n",
      "[318]\ttrain-auc:0.86414+0.00392\ttest-auc:0.74888+0.02076\n",
      "[319]\ttrain-auc:0.86429+0.00389\ttest-auc:0.74888+0.02079\n",
      "[320]\ttrain-auc:0.86443+0.00387\ttest-auc:0.74884+0.02069\n",
      "[321]\ttrain-auc:0.86460+0.00381\ttest-auc:0.74878+0.02072\n",
      "[322]\ttrain-auc:0.86469+0.00392\ttest-auc:0.74880+0.02073\n",
      "[323]\ttrain-auc:0.86485+0.00398\ttest-auc:0.74864+0.02089\n",
      "[324]\ttrain-auc:0.86520+0.00394\ttest-auc:0.74875+0.02105\n",
      "[325]\ttrain-auc:0.86527+0.00389\ttest-auc:0.74863+0.02114\n",
      "[326]\ttrain-auc:0.86526+0.00394\ttest-auc:0.74862+0.02125\n",
      "[327]\ttrain-auc:0.86537+0.00395\ttest-auc:0.74870+0.02127\n",
      "[328]\ttrain-auc:0.86548+0.00406\ttest-auc:0.74882+0.02121\n",
      "[329]\ttrain-auc:0.86564+0.00406\ttest-auc:0.74890+0.02093\n",
      "[330]\ttrain-auc:0.86583+0.00405\ttest-auc:0.74869+0.02090\n",
      "[331]\ttrain-auc:0.86602+0.00409\ttest-auc:0.74880+0.02099\n",
      "[332]\ttrain-auc:0.86622+0.00418\ttest-auc:0.74875+0.02102\n",
      "[333]\ttrain-auc:0.86643+0.00427\ttest-auc:0.74878+0.02089\n",
      "[334]\ttrain-auc:0.86665+0.00433\ttest-auc:0.74866+0.02097\n",
      "[335]\ttrain-auc:0.86675+0.00431\ttest-auc:0.74852+0.02095\n",
      "[336]\ttrain-auc:0.86695+0.00445\ttest-auc:0.74846+0.02103\n",
      "[337]\ttrain-auc:0.86713+0.00432\ttest-auc:0.74845+0.02113\n",
      "[338]\ttrain-auc:0.86722+0.00431\ttest-auc:0.74840+0.02096\n",
      "[339]\ttrain-auc:0.86744+0.00432\ttest-auc:0.74824+0.02097\n",
      "[340]\ttrain-auc:0.86767+0.00426\ttest-auc:0.74846+0.02095\n",
      "[341]\ttrain-auc:0.86782+0.00432\ttest-auc:0.74850+0.02086\n",
      "[342]\ttrain-auc:0.86803+0.00422\ttest-auc:0.74854+0.02067\n",
      "[343]\ttrain-auc:0.86830+0.00426\ttest-auc:0.74841+0.02081\n",
      "[344]\ttrain-auc:0.86852+0.00415\ttest-auc:0.74865+0.02119\n",
      "[345]\ttrain-auc:0.86871+0.00414\ttest-auc:0.74860+0.02101\n",
      "[346]\ttrain-auc:0.86883+0.00418\ttest-auc:0.74861+0.02081\n",
      "[347]\ttrain-auc:0.86897+0.00421\ttest-auc:0.74862+0.02082\n",
      "[348]\ttrain-auc:0.86908+0.00415\ttest-auc:0.74863+0.02086\n",
      "[349]\ttrain-auc:0.86926+0.00415\ttest-auc:0.74877+0.02069\n",
      "[350]\ttrain-auc:0.86946+0.00414\ttest-auc:0.74864+0.02064\n",
      "[351]\ttrain-auc:0.86960+0.00419\ttest-auc:0.74844+0.02057\n",
      "[352]\ttrain-auc:0.86979+0.00403\ttest-auc:0.74840+0.02070\n",
      "[353]\ttrain-auc:0.86985+0.00413\ttest-auc:0.74850+0.02077\n",
      "[354]\ttrain-auc:0.87003+0.00410\ttest-auc:0.74859+0.02087\n",
      "[355]\ttrain-auc:0.87025+0.00406\ttest-auc:0.74857+0.02081\n",
      "[356]\ttrain-auc:0.87033+0.00403\ttest-auc:0.74857+0.02091\n",
      "[357]\ttrain-auc:0.87065+0.00399\ttest-auc:0.74865+0.02112\n",
      "[358]\ttrain-auc:0.87078+0.00400\ttest-auc:0.74869+0.02094\n",
      "[359]\ttrain-auc:0.87090+0.00415\ttest-auc:0.74862+0.02103\n",
      "[360]\ttrain-auc:0.87104+0.00417\ttest-auc:0.74882+0.02101\n",
      "[361]\ttrain-auc:0.87125+0.00421\ttest-auc:0.74905+0.02096\n",
      "[362]\ttrain-auc:0.87140+0.00417\ttest-auc:0.74902+0.02098\n",
      "[363]\ttrain-auc:0.87155+0.00417\ttest-auc:0.74897+0.02105\n",
      "[364]\ttrain-auc:0.87184+0.00415\ttest-auc:0.74923+0.02085\n",
      "[365]\ttrain-auc:0.87221+0.00402\ttest-auc:0.74906+0.02067\n",
      "[366]\ttrain-auc:0.87244+0.00404\ttest-auc:0.74914+0.02082\n",
      "[367]\ttrain-auc:0.87265+0.00402\ttest-auc:0.74899+0.02078\n",
      "[368]\ttrain-auc:0.87278+0.00400\ttest-auc:0.74901+0.02073\n",
      "[369]\ttrain-auc:0.87288+0.00406\ttest-auc:0.74917+0.02079\n",
      "[370]\ttrain-auc:0.87308+0.00402\ttest-auc:0.74939+0.02094\n",
      "[371]\ttrain-auc:0.87314+0.00411\ttest-auc:0.74947+0.02084\n",
      "[372]\ttrain-auc:0.87325+0.00414\ttest-auc:0.74945+0.02081\n",
      "[373]\ttrain-auc:0.87344+0.00406\ttest-auc:0.74938+0.02080\n",
      "[374]\ttrain-auc:0.87356+0.00396\ttest-auc:0.74931+0.02115\n",
      "[375]\ttrain-auc:0.87370+0.00400\ttest-auc:0.74922+0.02123\n",
      "[376]\ttrain-auc:0.87381+0.00399\ttest-auc:0.74909+0.02120\n",
      "[377]\ttrain-auc:0.87397+0.00385\ttest-auc:0.74920+0.02120\n",
      "[378]\ttrain-auc:0.87406+0.00381\ttest-auc:0.74926+0.02124\n",
      "[379]\ttrain-auc:0.87417+0.00390\ttest-auc:0.74943+0.02122\n",
      "[380]\ttrain-auc:0.87431+0.00385\ttest-auc:0.74939+0.02135\n",
      "[381]\ttrain-auc:0.87441+0.00388\ttest-auc:0.74936+0.02139\n",
      "[382]\ttrain-auc:0.87448+0.00391\ttest-auc:0.74936+0.02121\n",
      "[383]\ttrain-auc:0.87468+0.00399\ttest-auc:0.74977+0.02111\n",
      "[384]\ttrain-auc:0.87482+0.00398\ttest-auc:0.74974+0.02112\n",
      "[385]\ttrain-auc:0.87500+0.00407\ttest-auc:0.74989+0.02123\n",
      "[386]\ttrain-auc:0.87504+0.00406\ttest-auc:0.74985+0.02122\n",
      "[387]\ttrain-auc:0.87523+0.00409\ttest-auc:0.74978+0.02123\n",
      "[388]\ttrain-auc:0.87542+0.00409\ttest-auc:0.74971+0.02122\n",
      "[389]\ttrain-auc:0.87555+0.00414\ttest-auc:0.74966+0.02115\n",
      "[390]\ttrain-auc:0.87571+0.00422\ttest-auc:0.74952+0.02124\n",
      "[391]\ttrain-auc:0.87573+0.00424\ttest-auc:0.74961+0.02113\n",
      "[392]\ttrain-auc:0.87594+0.00418\ttest-auc:0.74940+0.02114\n",
      "[393]\ttrain-auc:0.87604+0.00414\ttest-auc:0.74913+0.02116\n",
      "[394]\ttrain-auc:0.87615+0.00423\ttest-auc:0.74911+0.02119\n",
      "[395]\ttrain-auc:0.87626+0.00419\ttest-auc:0.74933+0.02096\n",
      "[396]\ttrain-auc:0.87635+0.00419\ttest-auc:0.74926+0.02108\n",
      "[397]\ttrain-auc:0.87655+0.00413\ttest-auc:0.74927+0.02094\n",
      "[398]\ttrain-auc:0.87668+0.00415\ttest-auc:0.74938+0.02107\n",
      "[399]\ttrain-auc:0.87690+0.00424\ttest-auc:0.74935+0.02113\n",
      "[400]\ttrain-auc:0.87700+0.00421\ttest-auc:0.74945+0.02102\n",
      "[401]\ttrain-auc:0.87713+0.00425\ttest-auc:0.74947+0.02105\n",
      "[402]\ttrain-auc:0.87736+0.00421\ttest-auc:0.74969+0.02092\n",
      "[403]\ttrain-auc:0.87746+0.00417\ttest-auc:0.74977+0.02089\n",
      "[404]\ttrain-auc:0.87762+0.00402\ttest-auc:0.74986+0.02091\n",
      "[405]\ttrain-auc:0.87781+0.00406\ttest-auc:0.74978+0.02088\n",
      "[406]\ttrain-auc:0.87798+0.00394\ttest-auc:0.74985+0.02071\n",
      "[407]\ttrain-auc:0.87811+0.00390\ttest-auc:0.74999+0.02074\n",
      "[408]\ttrain-auc:0.87824+0.00395\ttest-auc:0.74982+0.02079\n",
      "[409]\ttrain-auc:0.87842+0.00392\ttest-auc:0.74957+0.02084\n",
      "[410]\ttrain-auc:0.87856+0.00392\ttest-auc:0.74945+0.02085\n",
      "[411]\ttrain-auc:0.87879+0.00383\ttest-auc:0.74929+0.02097\n",
      "[412]\ttrain-auc:0.87900+0.00386\ttest-auc:0.74958+0.02091\n",
      "[413]\ttrain-auc:0.87911+0.00375\ttest-auc:0.74943+0.02083\n",
      "[414]\ttrain-auc:0.87918+0.00372\ttest-auc:0.74953+0.02090\n",
      "[415]\ttrain-auc:0.87925+0.00380\ttest-auc:0.74951+0.02102\n",
      "[416]\ttrain-auc:0.87941+0.00381\ttest-auc:0.74954+0.02105\n",
      "[417]\ttrain-auc:0.87957+0.00390\ttest-auc:0.74946+0.02101\n",
      "[418]\ttrain-auc:0.87973+0.00390\ttest-auc:0.74941+0.02100\n",
      "[419]\ttrain-auc:0.87988+0.00391\ttest-auc:0.74923+0.02101\n",
      "[420]\ttrain-auc:0.88002+0.00394\ttest-auc:0.74928+0.02117\n",
      "[421]\ttrain-auc:0.88020+0.00403\ttest-auc:0.74915+0.02116\n",
      "[422]\ttrain-auc:0.88032+0.00408\ttest-auc:0.74928+0.02104\n",
      "[423]\ttrain-auc:0.88048+0.00419\ttest-auc:0.74944+0.02114\n",
      "[424]\ttrain-auc:0.88058+0.00421\ttest-auc:0.74941+0.02113\n",
      "[425]\ttrain-auc:0.88072+0.00417\ttest-auc:0.74954+0.02083\n",
      "[426]\ttrain-auc:0.88075+0.00415\ttest-auc:0.74957+0.02093\n",
      "[427]\ttrain-auc:0.88091+0.00413\ttest-auc:0.74973+0.02091\n",
      "[428]\ttrain-auc:0.88107+0.00415\ttest-auc:0.74971+0.02110\n",
      "[429]\ttrain-auc:0.88124+0.00416\ttest-auc:0.74966+0.02119\n",
      "[430]\ttrain-auc:0.88129+0.00413\ttest-auc:0.74956+0.02126\n",
      "[431]\ttrain-auc:0.88141+0.00415\ttest-auc:0.74961+0.02120\n",
      "[432]\ttrain-auc:0.88155+0.00414\ttest-auc:0.74955+0.02119\n",
      "[433]\ttrain-auc:0.88157+0.00411\ttest-auc:0.74955+0.02108\n",
      "[434]\ttrain-auc:0.88167+0.00407\ttest-auc:0.74948+0.02103\n",
      "[435]\ttrain-auc:0.88177+0.00406\ttest-auc:0.74957+0.02111\n",
      "[436]\ttrain-auc:0.88197+0.00401\ttest-auc:0.74955+0.02102\n",
      "[437]\ttrain-auc:0.88207+0.00399\ttest-auc:0.74973+0.02083\n",
      "[438]\ttrain-auc:0.88221+0.00390\ttest-auc:0.74960+0.02070\n",
      "[439]\ttrain-auc:0.88231+0.00392\ttest-auc:0.74945+0.02070\n",
      "[440]\ttrain-auc:0.88252+0.00391\ttest-auc:0.74971+0.02051\n",
      "[441]\ttrain-auc:0.88252+0.00384\ttest-auc:0.74966+0.02045\n",
      "[442]\ttrain-auc:0.88267+0.00382\ttest-auc:0.74970+0.02041\n",
      "[443]\ttrain-auc:0.88278+0.00384\ttest-auc:0.74980+0.02054\n",
      "[444]\ttrain-auc:0.88293+0.00402\ttest-auc:0.74997+0.02044\n",
      "[445]\ttrain-auc:0.88305+0.00403\ttest-auc:0.74985+0.02055\n",
      "[446]\ttrain-auc:0.88316+0.00407\ttest-auc:0.74977+0.02046\n",
      "[447]\ttrain-auc:0.88323+0.00399\ttest-auc:0.74981+0.02061\n",
      "[448]\ttrain-auc:0.88334+0.00404\ttest-auc:0.75006+0.02038\n",
      "[449]\ttrain-auc:0.88345+0.00400\ttest-auc:0.75003+0.02002\n",
      "[450]\ttrain-auc:0.88352+0.00401\ttest-auc:0.75001+0.01992\n",
      "[451]\ttrain-auc:0.88357+0.00402\ttest-auc:0.75020+0.01989\n",
      "[452]\ttrain-auc:0.88364+0.00404\ttest-auc:0.75024+0.02006\n",
      "[453]\ttrain-auc:0.88374+0.00406\ttest-auc:0.75020+0.02016\n",
      "[454]\ttrain-auc:0.88381+0.00402\ttest-auc:0.75018+0.02032\n",
      "[455]\ttrain-auc:0.88394+0.00399\ttest-auc:0.75030+0.02031\n",
      "[456]\ttrain-auc:0.88400+0.00398\ttest-auc:0.75037+0.02038\n",
      "[457]\ttrain-auc:0.88415+0.00394\ttest-auc:0.75040+0.02045\n",
      "[458]\ttrain-auc:0.88427+0.00398\ttest-auc:0.75031+0.02030\n",
      "[459]\ttrain-auc:0.88435+0.00409\ttest-auc:0.75029+0.02028\n",
      "[460]\ttrain-auc:0.88449+0.00413\ttest-auc:0.75027+0.02029\n",
      "[461]\ttrain-auc:0.88457+0.00408\ttest-auc:0.75021+0.02032\n",
      "[462]\ttrain-auc:0.88477+0.00399\ttest-auc:0.75033+0.02019\n",
      "[463]\ttrain-auc:0.88493+0.00400\ttest-auc:0.75053+0.02008\n",
      "[464]\ttrain-auc:0.88512+0.00409\ttest-auc:0.75032+0.02029\n",
      "[465]\ttrain-auc:0.88525+0.00424\ttest-auc:0.75029+0.02031\n",
      "[466]\ttrain-auc:0.88537+0.00425\ttest-auc:0.75037+0.02036\n",
      "[467]\ttrain-auc:0.88553+0.00417\ttest-auc:0.75050+0.02043\n",
      "[468]\ttrain-auc:0.88557+0.00418\ttest-auc:0.75034+0.02050\n",
      "[469]\ttrain-auc:0.88576+0.00418\ttest-auc:0.75041+0.02049\n",
      "[470]\ttrain-auc:0.88586+0.00422\ttest-auc:0.75052+0.02056\n",
      "[471]\ttrain-auc:0.88602+0.00427\ttest-auc:0.75037+0.02062\n",
      "[472]\ttrain-auc:0.88611+0.00422\ttest-auc:0.75034+0.02061\n",
      "[473]\ttrain-auc:0.88621+0.00415\ttest-auc:0.75021+0.02070\n",
      "[474]\ttrain-auc:0.88632+0.00411\ttest-auc:0.75028+0.02065\n",
      "[475]\ttrain-auc:0.88644+0.00403\ttest-auc:0.75047+0.02069\n",
      "[476]\ttrain-auc:0.88654+0.00402\ttest-auc:0.75058+0.02052\n",
      "[477]\ttrain-auc:0.88670+0.00402\ttest-auc:0.75071+0.02057\n",
      "[478]\ttrain-auc:0.88683+0.00413\ttest-auc:0.75074+0.02051\n",
      "[479]\ttrain-auc:0.88695+0.00411\ttest-auc:0.75076+0.02048\n",
      "[480]\ttrain-auc:0.88700+0.00419\ttest-auc:0.75079+0.02035\n",
      "[481]\ttrain-auc:0.88711+0.00420\ttest-auc:0.75089+0.02047\n",
      "[482]\ttrain-auc:0.88710+0.00416\ttest-auc:0.75087+0.02054\n",
      "[483]\ttrain-auc:0.88738+0.00418\ttest-auc:0.75070+0.02024\n",
      "[484]\ttrain-auc:0.88743+0.00411\ttest-auc:0.75078+0.02018\n",
      "[485]\ttrain-auc:0.88757+0.00409\ttest-auc:0.75093+0.02025\n",
      "[486]\ttrain-auc:0.88771+0.00406\ttest-auc:0.75113+0.02024\n",
      "[487]\ttrain-auc:0.88776+0.00405\ttest-auc:0.75130+0.02015\n",
      "[488]\ttrain-auc:0.88799+0.00395\ttest-auc:0.75144+0.02024\n",
      "[489]\ttrain-auc:0.88812+0.00396\ttest-auc:0.75168+0.02001\n",
      "[490]\ttrain-auc:0.88827+0.00394\ttest-auc:0.75191+0.01988\n",
      "[491]\ttrain-auc:0.88841+0.00396\ttest-auc:0.75184+0.01981\n",
      "[492]\ttrain-auc:0.88849+0.00396\ttest-auc:0.75199+0.01974\n",
      "[493]\ttrain-auc:0.88874+0.00405\ttest-auc:0.75186+0.01976\n",
      "[494]\ttrain-auc:0.88886+0.00412\ttest-auc:0.75206+0.01987\n",
      "[495]\ttrain-auc:0.88892+0.00413\ttest-auc:0.75204+0.01994\n",
      "[496]\ttrain-auc:0.88899+0.00412\ttest-auc:0.75211+0.01985\n",
      "[497]\ttrain-auc:0.88925+0.00405\ttest-auc:0.75195+0.01988\n",
      "[498]\ttrain-auc:0.88938+0.00409\ttest-auc:0.75198+0.01982\n",
      "[499]\ttrain-auc:0.88947+0.00401\ttest-auc:0.75183+0.01966\n",
      "[500]\ttrain-auc:0.88963+0.00406\ttest-auc:0.75172+0.01966\n",
      "[501]\ttrain-auc:0.88971+0.00405\ttest-auc:0.75182+0.01955\n",
      "[502]\ttrain-auc:0.88988+0.00406\ttest-auc:0.75187+0.01962\n",
      "[503]\ttrain-auc:0.89005+0.00418\ttest-auc:0.75190+0.01954\n",
      "[504]\ttrain-auc:0.89009+0.00419\ttest-auc:0.75187+0.01925\n",
      "[505]\ttrain-auc:0.89021+0.00417\ttest-auc:0.75196+0.01939\n",
      "[506]\ttrain-auc:0.89030+0.00405\ttest-auc:0.75205+0.01939\n",
      "[507]\ttrain-auc:0.89043+0.00409\ttest-auc:0.75181+0.01936\n",
      "[508]\ttrain-auc:0.89062+0.00413\ttest-auc:0.75163+0.01954\n",
      "[509]\ttrain-auc:0.89070+0.00411\ttest-auc:0.75147+0.01969\n",
      "[510]\ttrain-auc:0.89089+0.00406\ttest-auc:0.75148+0.01964\n",
      "[511]\ttrain-auc:0.89101+0.00405\ttest-auc:0.75136+0.01981\n",
      "[512]\ttrain-auc:0.89116+0.00407\ttest-auc:0.75142+0.01974\n",
      "[513]\ttrain-auc:0.89128+0.00409\ttest-auc:0.75129+0.01982\n",
      "[514]\ttrain-auc:0.89137+0.00404\ttest-auc:0.75121+0.01963\n",
      "[515]\ttrain-auc:0.89151+0.00403\ttest-auc:0.75122+0.01968\n",
      "[516]\ttrain-auc:0.89155+0.00405\ttest-auc:0.75114+0.01973\n",
      "[517]\ttrain-auc:0.89169+0.00402\ttest-auc:0.75109+0.01985\n",
      "[518]\ttrain-auc:0.89181+0.00401\ttest-auc:0.75095+0.01988\n",
      "[519]\ttrain-auc:0.89194+0.00402\ttest-auc:0.75108+0.01987\n",
      "[520]\ttrain-auc:0.89204+0.00401\ttest-auc:0.75107+0.02002\n",
      "[521]\ttrain-auc:0.89206+0.00404\ttest-auc:0.75103+0.02000\n",
      "[522]\ttrain-auc:0.89219+0.00387\ttest-auc:0.75088+0.01999\n",
      "[523]\ttrain-auc:0.89232+0.00388\ttest-auc:0.75084+0.01997\n",
      "[524]\ttrain-auc:0.89241+0.00390\ttest-auc:0.75083+0.02013\n",
      "[525]\ttrain-auc:0.89254+0.00391\ttest-auc:0.75076+0.02031\n",
      "[526]\ttrain-auc:0.89260+0.00389\ttest-auc:0.75094+0.02038\n",
      "[527]\ttrain-auc:0.89268+0.00399\ttest-auc:0.75103+0.02039\n",
      "[528]\ttrain-auc:0.89281+0.00398\ttest-auc:0.75092+0.02027\n",
      "[529]\ttrain-auc:0.89292+0.00397\ttest-auc:0.75110+0.02021\n",
      "[530]\ttrain-auc:0.89308+0.00386\ttest-auc:0.75115+0.02012\n",
      "[531]\ttrain-auc:0.89320+0.00385\ttest-auc:0.75123+0.02019\n",
      "[532]\ttrain-auc:0.89327+0.00390\ttest-auc:0.75133+0.02010\n",
      "[533]\ttrain-auc:0.89333+0.00391\ttest-auc:0.75130+0.02012\n",
      "[534]\ttrain-auc:0.89341+0.00388\ttest-auc:0.75128+0.02008\n",
      "[535]\ttrain-auc:0.89347+0.00389\ttest-auc:0.75136+0.02030\n",
      "[536]\ttrain-auc:0.89364+0.00384\ttest-auc:0.75119+0.02027\n",
      "[537]\ttrain-auc:0.89374+0.00389\ttest-auc:0.75113+0.02038\n",
      "[538]\ttrain-auc:0.89385+0.00395\ttest-auc:0.75137+0.02041\n",
      "[539]\ttrain-auc:0.89399+0.00389\ttest-auc:0.75136+0.02039\n",
      "[540]\ttrain-auc:0.89414+0.00395\ttest-auc:0.75148+0.02033\n",
      "[541]\ttrain-auc:0.89421+0.00392\ttest-auc:0.75147+0.02028\n",
      "[542]\ttrain-auc:0.89427+0.00381\ttest-auc:0.75148+0.02032\n",
      "[543]\ttrain-auc:0.89433+0.00381\ttest-auc:0.75145+0.02010\n",
      "[544]\ttrain-auc:0.89450+0.00385\ttest-auc:0.75138+0.02018\n",
      "[545]\ttrain-auc:0.89462+0.00387\ttest-auc:0.75139+0.02019\n",
      "Stopping. Best iteration:\n",
      "[496]\ttrain-auc:0.88899+0.00412\ttest-auc:0.75211+0.01985\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\training.py:20: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_result = xgb.cv(xgb1.get_xgb_params(),\n",
    "dtrain,\n",
    "num_boost_round=xgb1.get_params()['n_estimators'],\n",
    "nfold=5,\n",
    "metrics='auc',\n",
    "early_stopping_rounds=50,\n",
    "callbacks=[xgb.callback.early_stop(50),\n",
    "xgb.callback.print_evaluation(period=1,show_stdv=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到最佳迭代次数为496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=3,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=496,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0,\n",
    "                     min_child_weight=5,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.5279028125096478 0.5822285988604071\n",
      "f1= 0.10625 0.28077753779697623\n",
      "precision_score= 0.68 0.9330143540669856\n",
      "recall_score= 0.0576271186440678 0.1652542372881356\n",
      "accuracy= 0.9389801578835075 0.9467057882101894\n",
      "auc= 0.5279028125096477 0.5822285988604071\n",
      "#####混淆矩阵#########\n",
      "[[4384    8]\n",
      " [ 278   17]] [[17551    14]\n",
      " [  985   195]]\n"
     ]
    }
   ],
   "source": [
    "##修改为最佳迭代次数后的得分结果\n",
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "调优max_depth和min_child_weight参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best_params: {'max_depth': 7, 'min_child_weight': 1}\n",
      "best_score: 0.20693081275440658\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':range(1,9,2),\n",
    "'min_child_weight':range(1,9,2)}\n",
    "grid_search = GridSearchCV(xgb1,param_grid,scoring='f1',iid=False,cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print('best_params:', grid_search.best_params_)\n",
    "print('best_score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到最佳max_depth和min_child_weight分别为7和1，下面在进行一次范围更小的调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:32:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:32:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:34:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:35:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best_params: {'max_depth': 8, 'min_child_weight': 1}\n",
      "best_score: 0.22644978521631268\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':[6,7,8],\n",
    "'min_child_weight':[1,2,3]}\n",
    "grid_search = GridSearchCV(xgb1,param_grid,scoring='f1',iid=False,cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print('best_params:', grid_search.best_params_)\n",
    "print('best_score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到最佳max_depth和min_child_weight分别为8和1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=496,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:38:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.6090183229909543 0.9153933091133659\n",
      "f1= 0.34196891191709844 0.9037309995393827\n",
      "precision_score= 0.7252747252747253 0.9899091826437941\n",
      "recall_score= 0.22372881355932203 0.8313559322033899\n",
      "accuracy= 0.9458075528056326 0.9888503600960256\n",
      "auc= 0.6090183229909543 0.9153933091133659\n",
      "#####混淆矩阵#########\n",
      "[[4367   25]\n",
      " [ 229   66]] [[17555    10]\n",
      " [  199   981]]\n"
     ]
    }
   ],
   "source": [
    "##修改为最佳max_depth和min_child_weight后的得分结果\n",
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对gamma参数进行调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:46:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:46:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:46:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:48:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best_params: {'gamma': 1}\n",
      "best_score: 0.19551296611700808\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'gamma':[1,2,3,4,5,6,7,8,9]}\n",
    "grid_search = GridSearchCV(xgb1,param_grid,scoring='f1',iid=False,cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print('best_params:', grid_search.best_params_)\n",
    "print('best_score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里发现最优gamma值为1 但是分数反而下降了，所以在精细化一些调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:03:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:04:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best_params: {'gamma': 0.1}\n",
      "best_score: 0.2331615178149474\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'gamma':[i/10.0 for i in range(0,10)]}\n",
    "grid_search = GridSearchCV(xgb1,param_grid,scoring='f1',iid=False,cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print('best_params:', grid_search.best_params_)\n",
    "print('best_score:', grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里得到最优gamma值为0.1，分数有所提高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=496,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.6138753820505696 0.9154502405110316\n",
      "f1= 0.35294117647058826 0.9045643153526972\n",
      "precision_score= 0.71875 0.9919110212335692\n",
      "recall_score= 0.23389830508474577 0.8313559322033899\n",
      "accuracy= 0.946020908896949 0.9889570552147239\n",
      "auc= 0.6138753820505696 0.9154502405110317\n",
      "#####混淆矩阵#########\n",
      "[[4365   27]\n",
      " [ 226   69]] [[17557     8]\n",
      " [  199   981]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##修改为最佳gamma后的得分结果\n",
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面调优subsample和colsample_bytree参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:09:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:12:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:13:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:14:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:15:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:17:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:18:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:19:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:20:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:21:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best_params: {'colsample_bytree': 0.9, 'subsample': 0.7}\n",
      "best_score: 0.2372598767848127\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'subsample':[i/10.0 for i in range(5,11)],\n",
    "              'colsample_bytree':[i/10.0 for i in range(5,11)]}\n",
    "grid_search = GridSearchCV(xgb1,param_grid,scoring='f1',iid=False,cv=5)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print('best_params:', grid_search.best_params_)\n",
    "print('best_score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得出分数有所提高，最佳colsample_bytree值为0.9，最佳subsample值为0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=496,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.7,\n",
    "                     colsample_bytree=0.9,\n",
    "                     seed=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.598621144762434 0.9201112574601842\n",
      "f1= 0.3141361256544503 0.910091743119266\n",
      "precision_score= 0.6896551724137931 0.992\n",
      "recall_score= 0.2033898305084746 0.8406779661016949\n",
      "accuracy= 0.9441007040751014 0.9895438783675646\n",
      "auc= 0.5986211447624339 0.9201112574601843\n",
      "#####混淆矩阵#########\n",
      "[[4365   27]\n",
      " [ 235   60]] [[17557     8]\n",
      " [  188   992]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##修改为最佳gamma后的得分结果\n",
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这里验证的结果发现结果变差了，故仍然采用未改动之前的参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=496,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调节正则化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:34:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:34:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:35:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:36:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:37:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "best_params: {'reg_lambda': 0.3}\n",
      "best_score: 0.24355632527389875\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'reg_lambda':[i/10.0 for i in range(1,11)]}\n",
    "grid_search = GridSearchCV(xgb1, param_grid, scoring='f1', iid=False, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print('best_params:', grid_search.best_params_)\n",
    "print('best_score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得出f1分数有所提高，最优reg_labmda参数为0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=496,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     reg_lambda=0.3,\n",
    "                     seed=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.6072095643851687 0.9230488934562666\n",
      "f1= 0.3367875647668394 0.9131627056672761\n",
      "precision_score= 0.7142857142857143 0.9910714285714286\n",
      "recall_score= 0.22033898305084745 0.8466101694915255\n",
      "accuracy= 0.9453808406229998 0.9898639637236596\n",
      "auc= 0.6072095643851687 0.9230488934562665\n",
      "#####混淆矩阵#########\n",
      "[[4366   26]\n",
      " [ 230   65]] [[17556     9]\n",
      " [  181   999]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##修改为最佳reg_lambda后的得分结果\n",
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现修改后测试集分数反而降低，故改回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.1,\n",
    "                     n_estimators=496,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后调低速率，增加迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.05,\n",
    "                     n_estimators=10000,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.6483174338550832 0.9897418547091432\n",
      "f1= 0.4155251141552512 0.9825902335456476\n",
      "precision_score= 0.6363636363636364 0.9846808510638297\n",
      "recall_score= 0.30847457627118646 0.9805084745762712\n",
      "accuracy= 0.9453808406229998 0.9978127500666845\n",
      "auc= 0.6483174338550832 0.9897418547091432\n",
      "#####混淆矩阵#########\n",
      "[[4340   52]\n",
      " [ 204   91]] [[17547    18]\n",
      " [   23  1157]]\n"
     ]
    }
   ],
   "source": [
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续降低速率测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.01,\n",
    "                     n_estimators=10000,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.6347708468401717 0.9805336836061698\n",
      "f1= 0.3961352657004831 0.9746672391584371\n",
      "precision_score= 0.6890756302521008 0.9878154917319408\n",
      "recall_score= 0.27796610169491526 0.961864406779661\n",
      "accuracy= 0.9466609771708983 0.9968524939983996\n",
      "auc= 0.6347708468401717 0.9805336836061698\n",
      "#####混淆矩阵#########\n",
      "[[4355   37]\n",
      " [ 213   82]] [[17551    14]\n",
      " [   45  1135]]\n"
     ]
    }
   ],
   "source": [
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现继续降低速率效果并不好，故改回速率，然后用cv函数测试最佳迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.05,\n",
    "                     n_estimators=10000,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[0]\ttrain-auc:0.71898+0.01835\ttest-auc:0.69875+0.01339\n",
      "[1]\ttrain-auc:0.73548+0.00923\ttest-auc:0.71058+0.02621\n",
      "[2]\ttrain-auc:0.74033+0.00971\ttest-auc:0.71179+0.02656\n",
      "[3]\ttrain-auc:0.74517+0.00719\ttest-auc:0.71439+0.02418\n",
      "[4]\ttrain-auc:0.75047+0.00693\ttest-auc:0.72100+0.02672\n",
      "[5]\ttrain-auc:0.75515+0.00930\ttest-auc:0.72116+0.02829\n",
      "[6]\ttrain-auc:0.76416+0.00615\ttest-auc:0.72299+0.02655\n",
      "[7]\ttrain-auc:0.76819+0.00455\ttest-auc:0.72564+0.02560\n",
      "[8]\ttrain-auc:0.77375+0.00698\ttest-auc:0.72712+0.02542\n",
      "[9]\ttrain-auc:0.77722+0.00748\ttest-auc:0.72705+0.02525\n",
      "[10]\ttrain-auc:0.78077+0.00580\ttest-auc:0.72767+0.02692\n",
      "[11]\ttrain-auc:0.78365+0.00748\ttest-auc:0.72812+0.02596\n",
      "[12]\ttrain-auc:0.78577+0.00685\ttest-auc:0.72938+0.02613\n",
      "[13]\ttrain-auc:0.78965+0.00499\ttest-auc:0.73226+0.02394\n",
      "[14]\ttrain-auc:0.79356+0.00366\ttest-auc:0.73417+0.02503\n",
      "[15]\ttrain-auc:0.79715+0.00485\ttest-auc:0.73444+0.02539\n",
      "[16]\ttrain-auc:0.79901+0.00562\ttest-auc:0.73506+0.02528\n",
      "[17]\ttrain-auc:0.80225+0.00447\ttest-auc:0.73666+0.02478\n",
      "[18]\ttrain-auc:0.80423+0.00446\ttest-auc:0.73689+0.02398\n",
      "[19]\ttrain-auc:0.80582+0.00388\ttest-auc:0.73765+0.02422\n",
      "[20]\ttrain-auc:0.80805+0.00344\ttest-auc:0.73894+0.02417\n",
      "[21]\ttrain-auc:0.81019+0.00234\ttest-auc:0.73921+0.02390\n",
      "[22]\ttrain-auc:0.81144+0.00191\ttest-auc:0.73955+0.02433\n",
      "[23]\ttrain-auc:0.81332+0.00164\ttest-auc:0.73921+0.02371\n",
      "[24]\ttrain-auc:0.81503+0.00136\ttest-auc:0.74003+0.02232\n",
      "[25]\ttrain-auc:0.81730+0.00154\ttest-auc:0.74141+0.02215\n",
      "[26]\ttrain-auc:0.81995+0.00203\ttest-auc:0.74215+0.02261\n",
      "[27]\ttrain-auc:0.82091+0.00193\ttest-auc:0.74163+0.02204\n",
      "[28]\ttrain-auc:0.82201+0.00195\ttest-auc:0.74243+0.02137\n",
      "[29]\ttrain-auc:0.82350+0.00142\ttest-auc:0.74296+0.02167\n",
      "[30]\ttrain-auc:0.82499+0.00243\ttest-auc:0.74317+0.02184\n",
      "[31]\ttrain-auc:0.82600+0.00178\ttest-auc:0.74371+0.02158\n",
      "[32]\ttrain-auc:0.82762+0.00124\ttest-auc:0.74445+0.02129\n",
      "[33]\ttrain-auc:0.83005+0.00114\ttest-auc:0.74529+0.02194\n",
      "[34]\ttrain-auc:0.83171+0.00143\ttest-auc:0.74592+0.02210\n",
      "[35]\ttrain-auc:0.83283+0.00152\ttest-auc:0.74700+0.02222\n",
      "[36]\ttrain-auc:0.83431+0.00196\ttest-auc:0.74707+0.02189\n",
      "[37]\ttrain-auc:0.83646+0.00236\ttest-auc:0.74827+0.02100\n",
      "[38]\ttrain-auc:0.83801+0.00228\ttest-auc:0.74948+0.02120\n",
      "[39]\ttrain-auc:0.83949+0.00325\ttest-auc:0.74975+0.02121\n",
      "[40]\ttrain-auc:0.84132+0.00277\ttest-auc:0.74985+0.02125\n",
      "[41]\ttrain-auc:0.84326+0.00293\ttest-auc:0.75045+0.02151\n",
      "[42]\ttrain-auc:0.84488+0.00284\ttest-auc:0.75016+0.02146\n",
      "[43]\ttrain-auc:0.84633+0.00294\ttest-auc:0.75050+0.02114\n",
      "[44]\ttrain-auc:0.84735+0.00291\ttest-auc:0.75121+0.02132\n",
      "[45]\ttrain-auc:0.84901+0.00308\ttest-auc:0.75134+0.02132\n",
      "[46]\ttrain-auc:0.85067+0.00325\ttest-auc:0.75153+0.02122\n",
      "[47]\ttrain-auc:0.85255+0.00350\ttest-auc:0.75202+0.02099\n",
      "[48]\ttrain-auc:0.85380+0.00343\ttest-auc:0.75252+0.02108\n",
      "[49]\ttrain-auc:0.85525+0.00372\ttest-auc:0.75327+0.02066\n",
      "[50]\ttrain-auc:0.85697+0.00395\ttest-auc:0.75364+0.02055\n",
      "[51]\ttrain-auc:0.85812+0.00449\ttest-auc:0.75411+0.02070\n",
      "[52]\ttrain-auc:0.85988+0.00456\ttest-auc:0.75485+0.02042\n",
      "[53]\ttrain-auc:0.86125+0.00459\ttest-auc:0.75540+0.01987\n",
      "[54]\ttrain-auc:0.86271+0.00474\ttest-auc:0.75537+0.01948\n",
      "[55]\ttrain-auc:0.86374+0.00509\ttest-auc:0.75553+0.01930\n",
      "[56]\ttrain-auc:0.86512+0.00507\ttest-auc:0.75603+0.01867\n",
      "[57]\ttrain-auc:0.86662+0.00435\ttest-auc:0.75649+0.01917\n",
      "[58]\ttrain-auc:0.86780+0.00402\ttest-auc:0.75772+0.01918\n",
      "[59]\ttrain-auc:0.86941+0.00447\ttest-auc:0.75808+0.01901\n",
      "[60]\ttrain-auc:0.87070+0.00456\ttest-auc:0.75819+0.01901\n",
      "[61]\ttrain-auc:0.87179+0.00439\ttest-auc:0.75822+0.01913\n",
      "[62]\ttrain-auc:0.87317+0.00436\ttest-auc:0.75861+0.01922\n",
      "[63]\ttrain-auc:0.87404+0.00403\ttest-auc:0.75890+0.01920\n",
      "[64]\ttrain-auc:0.87519+0.00402\ttest-auc:0.75905+0.01904\n",
      "[65]\ttrain-auc:0.87629+0.00395\ttest-auc:0.75954+0.01925\n",
      "[66]\ttrain-auc:0.87763+0.00409\ttest-auc:0.76033+0.01945\n",
      "[67]\ttrain-auc:0.87880+0.00451\ttest-auc:0.76069+0.01929\n",
      "[68]\ttrain-auc:0.87998+0.00460\ttest-auc:0.76129+0.01940\n",
      "[69]\ttrain-auc:0.88070+0.00483\ttest-auc:0.76129+0.01897\n",
      "[70]\ttrain-auc:0.88160+0.00445\ttest-auc:0.76174+0.01880\n",
      "[71]\ttrain-auc:0.88279+0.00449\ttest-auc:0.76222+0.01919\n",
      "[72]\ttrain-auc:0.88388+0.00498\ttest-auc:0.76182+0.01922\n",
      "[73]\ttrain-auc:0.88494+0.00531\ttest-auc:0.76193+0.01947\n",
      "[74]\ttrain-auc:0.88575+0.00523\ttest-auc:0.76236+0.01900\n",
      "[75]\ttrain-auc:0.88678+0.00530\ttest-auc:0.76244+0.01885\n",
      "[76]\ttrain-auc:0.88787+0.00529\ttest-auc:0.76293+0.01884\n",
      "[77]\ttrain-auc:0.88886+0.00540\ttest-auc:0.76360+0.01851\n",
      "[78]\ttrain-auc:0.89000+0.00495\ttest-auc:0.76410+0.01863\n",
      "[79]\ttrain-auc:0.89111+0.00473\ttest-auc:0.76434+0.01875\n",
      "[80]\ttrain-auc:0.89212+0.00471\ttest-auc:0.76455+0.01845\n",
      "[81]\ttrain-auc:0.89338+0.00459\ttest-auc:0.76555+0.01802\n",
      "[82]\ttrain-auc:0.89423+0.00449\ttest-auc:0.76600+0.01806\n",
      "[83]\ttrain-auc:0.89505+0.00445\ttest-auc:0.76612+0.01789\n",
      "[84]\ttrain-auc:0.89643+0.00469\ttest-auc:0.76641+0.01803\n",
      "[85]\ttrain-auc:0.89721+0.00463\ttest-auc:0.76677+0.01786\n",
      "[86]\ttrain-auc:0.89817+0.00470\ttest-auc:0.76700+0.01783\n",
      "[87]\ttrain-auc:0.89892+0.00490\ttest-auc:0.76669+0.01774\n",
      "[88]\ttrain-auc:0.89982+0.00476\ttest-auc:0.76689+0.01753\n",
      "[89]\ttrain-auc:0.90071+0.00491\ttest-auc:0.76700+0.01725\n",
      "[90]\ttrain-auc:0.90134+0.00499\ttest-auc:0.76675+0.01693\n",
      "[91]\ttrain-auc:0.90245+0.00509\ttest-auc:0.76665+0.01677\n",
      "[92]\ttrain-auc:0.90331+0.00493\ttest-auc:0.76679+0.01671\n",
      "[93]\ttrain-auc:0.90404+0.00479\ttest-auc:0.76722+0.01683\n",
      "[94]\ttrain-auc:0.90497+0.00453\ttest-auc:0.76734+0.01663\n",
      "[95]\ttrain-auc:0.90575+0.00423\ttest-auc:0.76751+0.01681\n",
      "[96]\ttrain-auc:0.90659+0.00414\ttest-auc:0.76771+0.01673\n",
      "[97]\ttrain-auc:0.90749+0.00417\ttest-auc:0.76783+0.01615\n",
      "[98]\ttrain-auc:0.90810+0.00436\ttest-auc:0.76775+0.01615\n",
      "[99]\ttrain-auc:0.90881+0.00412\ttest-auc:0.76784+0.01617\n",
      "[100]\ttrain-auc:0.90968+0.00415\ttest-auc:0.76812+0.01658\n",
      "[101]\ttrain-auc:0.91010+0.00421\ttest-auc:0.76804+0.01636\n",
      "[102]\ttrain-auc:0.91080+0.00418\ttest-auc:0.76823+0.01685\n",
      "[103]\ttrain-auc:0.91207+0.00383\ttest-auc:0.76864+0.01686\n",
      "[104]\ttrain-auc:0.91259+0.00403\ttest-auc:0.76846+0.01713\n",
      "[105]\ttrain-auc:0.91333+0.00403\ttest-auc:0.76859+0.01696\n",
      "[106]\ttrain-auc:0.91403+0.00418\ttest-auc:0.76857+0.01693\n",
      "[107]\ttrain-auc:0.91525+0.00412\ttest-auc:0.76895+0.01706\n",
      "[108]\ttrain-auc:0.91575+0.00425\ttest-auc:0.76890+0.01725\n",
      "[109]\ttrain-auc:0.91658+0.00420\ttest-auc:0.76904+0.01698\n",
      "[110]\ttrain-auc:0.91736+0.00423\ttest-auc:0.76930+0.01696\n",
      "[111]\ttrain-auc:0.91800+0.00400\ttest-auc:0.76975+0.01723\n",
      "[112]\ttrain-auc:0.91847+0.00418\ttest-auc:0.77005+0.01690\n",
      "[113]\ttrain-auc:0.91908+0.00390\ttest-auc:0.77010+0.01703\n",
      "[114]\ttrain-auc:0.91959+0.00392\ttest-auc:0.77002+0.01681\n",
      "[115]\ttrain-auc:0.92005+0.00387\ttest-auc:0.77005+0.01677\n",
      "[116]\ttrain-auc:0.92070+0.00371\ttest-auc:0.76992+0.01696\n",
      "[117]\ttrain-auc:0.92122+0.00395\ttest-auc:0.76966+0.01672\n",
      "[118]\ttrain-auc:0.92160+0.00389\ttest-auc:0.76957+0.01670\n",
      "[119]\ttrain-auc:0.92203+0.00399\ttest-auc:0.76955+0.01667\n",
      "[120]\ttrain-auc:0.92274+0.00371\ttest-auc:0.76985+0.01680\n",
      "[121]\ttrain-auc:0.92324+0.00384\ttest-auc:0.76977+0.01686\n",
      "[122]\ttrain-auc:0.92374+0.00397\ttest-auc:0.76976+0.01677\n",
      "[123]\ttrain-auc:0.92430+0.00412\ttest-auc:0.77019+0.01659\n",
      "[124]\ttrain-auc:0.92491+0.00399\ttest-auc:0.77001+0.01660\n",
      "[125]\ttrain-auc:0.92516+0.00394\ttest-auc:0.77009+0.01703\n",
      "[126]\ttrain-auc:0.92576+0.00372\ttest-auc:0.77034+0.01703\n",
      "[127]\ttrain-auc:0.92621+0.00372\ttest-auc:0.77041+0.01715\n",
      "[128]\ttrain-auc:0.92692+0.00363\ttest-auc:0.77071+0.01695\n",
      "[129]\ttrain-auc:0.92754+0.00348\ttest-auc:0.77078+0.01675\n",
      "[130]\ttrain-auc:0.92791+0.00343\ttest-auc:0.77071+0.01685\n",
      "[131]\ttrain-auc:0.92841+0.00334\ttest-auc:0.77084+0.01677\n",
      "[132]\ttrain-auc:0.92884+0.00350\ttest-auc:0.77090+0.01649\n",
      "[133]\ttrain-auc:0.92924+0.00352\ttest-auc:0.77109+0.01656\n",
      "[134]\ttrain-auc:0.92969+0.00363\ttest-auc:0.77125+0.01655\n",
      "[135]\ttrain-auc:0.93025+0.00338\ttest-auc:0.77156+0.01668\n",
      "[136]\ttrain-auc:0.93064+0.00322\ttest-auc:0.77162+0.01677\n",
      "[137]\ttrain-auc:0.93093+0.00306\ttest-auc:0.77172+0.01694\n",
      "[138]\ttrain-auc:0.93133+0.00288\ttest-auc:0.77176+0.01699\n",
      "[139]\ttrain-auc:0.93174+0.00287\ttest-auc:0.77172+0.01668\n",
      "[140]\ttrain-auc:0.93216+0.00289\ttest-auc:0.77166+0.01679\n",
      "[141]\ttrain-auc:0.93255+0.00290\ttest-auc:0.77172+0.01662\n",
      "[142]\ttrain-auc:0.93289+0.00295\ttest-auc:0.77186+0.01668\n",
      "[143]\ttrain-auc:0.93325+0.00299\ttest-auc:0.77213+0.01662\n",
      "[144]\ttrain-auc:0.93354+0.00303\ttest-auc:0.77216+0.01637\n",
      "[145]\ttrain-auc:0.93406+0.00318\ttest-auc:0.77234+0.01624\n",
      "[146]\ttrain-auc:0.93443+0.00285\ttest-auc:0.77232+0.01620\n",
      "[147]\ttrain-auc:0.93491+0.00274\ttest-auc:0.77255+0.01635\n",
      "[148]\ttrain-auc:0.93523+0.00269\ttest-auc:0.77262+0.01614\n",
      "[149]\ttrain-auc:0.93561+0.00245\ttest-auc:0.77260+0.01630\n",
      "[150]\ttrain-auc:0.93609+0.00242\ttest-auc:0.77241+0.01611\n",
      "[151]\ttrain-auc:0.93650+0.00230\ttest-auc:0.77255+0.01629\n",
      "[152]\ttrain-auc:0.93683+0.00228\ttest-auc:0.77277+0.01625\n",
      "[153]\ttrain-auc:0.93722+0.00244\ttest-auc:0.77286+0.01621\n",
      "[154]\ttrain-auc:0.93754+0.00237\ttest-auc:0.77296+0.01604\n",
      "[155]\ttrain-auc:0.93801+0.00228\ttest-auc:0.77302+0.01627\n",
      "[156]\ttrain-auc:0.93854+0.00226\ttest-auc:0.77338+0.01632\n",
      "[157]\ttrain-auc:0.93890+0.00229\ttest-auc:0.77378+0.01638\n",
      "[158]\ttrain-auc:0.93931+0.00214\ttest-auc:0.77375+0.01644\n",
      "[159]\ttrain-auc:0.93966+0.00224\ttest-auc:0.77397+0.01645\n",
      "[160]\ttrain-auc:0.93999+0.00213\ttest-auc:0.77405+0.01647\n",
      "[161]\ttrain-auc:0.94026+0.00203\ttest-auc:0.77421+0.01669\n",
      "[162]\ttrain-auc:0.94079+0.00187\ttest-auc:0.77423+0.01689\n",
      "[163]\ttrain-auc:0.94102+0.00183\ttest-auc:0.77428+0.01686\n",
      "[164]\ttrain-auc:0.94128+0.00192\ttest-auc:0.77418+0.01689\n",
      "[165]\ttrain-auc:0.94158+0.00198\ttest-auc:0.77428+0.01695\n",
      "[166]\ttrain-auc:0.94190+0.00187\ttest-auc:0.77427+0.01701\n",
      "[167]\ttrain-auc:0.94233+0.00201\ttest-auc:0.77446+0.01685\n",
      "[168]\ttrain-auc:0.94266+0.00205\ttest-auc:0.77432+0.01663\n",
      "[169]\ttrain-auc:0.94309+0.00198\ttest-auc:0.77439+0.01701\n",
      "[170]\ttrain-auc:0.94344+0.00198\ttest-auc:0.77466+0.01688\n",
      "[171]\ttrain-auc:0.94367+0.00187\ttest-auc:0.77463+0.01686\n",
      "[172]\ttrain-auc:0.94401+0.00183\ttest-auc:0.77457+0.01658\n",
      "[173]\ttrain-auc:0.94427+0.00187\ttest-auc:0.77459+0.01649\n",
      "[174]\ttrain-auc:0.94470+0.00164\ttest-auc:0.77486+0.01674\n",
      "[175]\ttrain-auc:0.94502+0.00155\ttest-auc:0.77501+0.01657\n",
      "[176]\ttrain-auc:0.94526+0.00155\ttest-auc:0.77504+0.01672\n",
      "[177]\ttrain-auc:0.94562+0.00156\ttest-auc:0.77502+0.01673\n",
      "[178]\ttrain-auc:0.94598+0.00159\ttest-auc:0.77500+0.01683\n",
      "[179]\ttrain-auc:0.94632+0.00144\ttest-auc:0.77526+0.01689\n",
      "[180]\ttrain-auc:0.94670+0.00140\ttest-auc:0.77538+0.01697\n",
      "[181]\ttrain-auc:0.94685+0.00139\ttest-auc:0.77536+0.01715\n",
      "[182]\ttrain-auc:0.94726+0.00132\ttest-auc:0.77539+0.01726\n",
      "[183]\ttrain-auc:0.94756+0.00136\ttest-auc:0.77550+0.01725\n",
      "[184]\ttrain-auc:0.94781+0.00136\ttest-auc:0.77553+0.01728\n",
      "[185]\ttrain-auc:0.94813+0.00139\ttest-auc:0.77546+0.01716\n",
      "[186]\ttrain-auc:0.94850+0.00114\ttest-auc:0.77549+0.01711\n",
      "[187]\ttrain-auc:0.94887+0.00098\ttest-auc:0.77573+0.01722\n",
      "[188]\ttrain-auc:0.94907+0.00093\ttest-auc:0.77592+0.01747\n",
      "[189]\ttrain-auc:0.94934+0.00088\ttest-auc:0.77604+0.01725\n",
      "[190]\ttrain-auc:0.94964+0.00080\ttest-auc:0.77612+0.01747\n",
      "[191]\ttrain-auc:0.94979+0.00084\ttest-auc:0.77601+0.01754\n",
      "[192]\ttrain-auc:0.94994+0.00087\ttest-auc:0.77585+0.01766\n",
      "[193]\ttrain-auc:0.95022+0.00098\ttest-auc:0.77570+0.01776\n",
      "[194]\ttrain-auc:0.95049+0.00104\ttest-auc:0.77563+0.01766\n",
      "[195]\ttrain-auc:0.95070+0.00109\ttest-auc:0.77553+0.01755\n",
      "[196]\ttrain-auc:0.95101+0.00112\ttest-auc:0.77556+0.01759\n",
      "[197]\ttrain-auc:0.95127+0.00120\ttest-auc:0.77541+0.01762\n",
      "[198]\ttrain-auc:0.95156+0.00118\ttest-auc:0.77546+0.01772\n",
      "[199]\ttrain-auc:0.95178+0.00105\ttest-auc:0.77546+0.01791\n",
      "[200]\ttrain-auc:0.95211+0.00122\ttest-auc:0.77563+0.01770\n",
      "[201]\ttrain-auc:0.95236+0.00125\ttest-auc:0.77571+0.01765\n",
      "[202]\ttrain-auc:0.95260+0.00135\ttest-auc:0.77588+0.01768\n",
      "[203]\ttrain-auc:0.95286+0.00138\ttest-auc:0.77609+0.01772\n",
      "[204]\ttrain-auc:0.95308+0.00137\ttest-auc:0.77597+0.01781\n",
      "[205]\ttrain-auc:0.95332+0.00135\ttest-auc:0.77609+0.01789\n",
      "[206]\ttrain-auc:0.95355+0.00132\ttest-auc:0.77637+0.01807\n",
      "[207]\ttrain-auc:0.95380+0.00133\ttest-auc:0.77641+0.01806\n",
      "[208]\ttrain-auc:0.95394+0.00134\ttest-auc:0.77646+0.01812\n",
      "[209]\ttrain-auc:0.95416+0.00140\ttest-auc:0.77644+0.01797\n",
      "[210]\ttrain-auc:0.95435+0.00133\ttest-auc:0.77660+0.01807\n",
      "[211]\ttrain-auc:0.95455+0.00124\ttest-auc:0.77672+0.01814\n",
      "[212]\ttrain-auc:0.95471+0.00122\ttest-auc:0.77679+0.01838\n",
      "[213]\ttrain-auc:0.95502+0.00116\ttest-auc:0.77687+0.01814\n",
      "[214]\ttrain-auc:0.95531+0.00101\ttest-auc:0.77686+0.01806\n",
      "[215]\ttrain-auc:0.95541+0.00104\ttest-auc:0.77686+0.01809\n",
      "[216]\ttrain-auc:0.95559+0.00097\ttest-auc:0.77676+0.01799\n",
      "[217]\ttrain-auc:0.95575+0.00088\ttest-auc:0.77681+0.01804\n",
      "[218]\ttrain-auc:0.95592+0.00091\ttest-auc:0.77680+0.01790\n",
      "[219]\ttrain-auc:0.95604+0.00091\ttest-auc:0.77693+0.01777\n",
      "[220]\ttrain-auc:0.95621+0.00086\ttest-auc:0.77703+0.01786\n",
      "[221]\ttrain-auc:0.95639+0.00088\ttest-auc:0.77704+0.01777\n",
      "[222]\ttrain-auc:0.95664+0.00082\ttest-auc:0.77681+0.01778\n",
      "[223]\ttrain-auc:0.95696+0.00074\ttest-auc:0.77671+0.01773\n",
      "[224]\ttrain-auc:0.95709+0.00076\ttest-auc:0.77679+0.01770\n",
      "[225]\ttrain-auc:0.95731+0.00075\ttest-auc:0.77659+0.01768\n",
      "[226]\ttrain-auc:0.95746+0.00068\ttest-auc:0.77665+0.01742\n",
      "[227]\ttrain-auc:0.95763+0.00071\ttest-auc:0.77668+0.01724\n",
      "[228]\ttrain-auc:0.95796+0.00074\ttest-auc:0.77672+0.01698\n",
      "[229]\ttrain-auc:0.95817+0.00074\ttest-auc:0.77683+0.01700\n",
      "[230]\ttrain-auc:0.95830+0.00073\ttest-auc:0.77674+0.01712\n",
      "[231]\ttrain-auc:0.95847+0.00070\ttest-auc:0.77683+0.01724\n",
      "[232]\ttrain-auc:0.95857+0.00073\ttest-auc:0.77693+0.01714\n",
      "[233]\ttrain-auc:0.95889+0.00073\ttest-auc:0.77715+0.01716\n",
      "[234]\ttrain-auc:0.95904+0.00068\ttest-auc:0.77689+0.01712\n",
      "[235]\ttrain-auc:0.95927+0.00067\ttest-auc:0.77712+0.01730\n",
      "[236]\ttrain-auc:0.95948+0.00075\ttest-auc:0.77694+0.01721\n",
      "[237]\ttrain-auc:0.95970+0.00089\ttest-auc:0.77690+0.01713\n",
      "[238]\ttrain-auc:0.95993+0.00092\ttest-auc:0.77701+0.01722\n",
      "[239]\ttrain-auc:0.96015+0.00091\ttest-auc:0.77700+0.01703\n",
      "[240]\ttrain-auc:0.96034+0.00093\ttest-auc:0.77697+0.01694\n",
      "[241]\ttrain-auc:0.96055+0.00092\ttest-auc:0.77699+0.01688\n",
      "[242]\ttrain-auc:0.96069+0.00092\ttest-auc:0.77690+0.01698\n",
      "[243]\ttrain-auc:0.96097+0.00105\ttest-auc:0.77707+0.01685\n",
      "[244]\ttrain-auc:0.96119+0.00099\ttest-auc:0.77696+0.01669\n",
      "[245]\ttrain-auc:0.96147+0.00107\ttest-auc:0.77688+0.01656\n",
      "[246]\ttrain-auc:0.96169+0.00107\ttest-auc:0.77684+0.01680\n",
      "[247]\ttrain-auc:0.96197+0.00105\ttest-auc:0.77716+0.01699\n",
      "[248]\ttrain-auc:0.96218+0.00104\ttest-auc:0.77696+0.01687\n",
      "[249]\ttrain-auc:0.96233+0.00110\ttest-auc:0.77688+0.01679\n",
      "[250]\ttrain-auc:0.96260+0.00102\ttest-auc:0.77686+0.01664\n",
      "[251]\ttrain-auc:0.96285+0.00103\ttest-auc:0.77682+0.01658\n",
      "[252]\ttrain-auc:0.96300+0.00104\ttest-auc:0.77694+0.01653\n",
      "[253]\ttrain-auc:0.96324+0.00111\ttest-auc:0.77694+0.01665\n",
      "[254]\ttrain-auc:0.96336+0.00110\ttest-auc:0.77695+0.01643\n",
      "[255]\ttrain-auc:0.96357+0.00117\ttest-auc:0.77704+0.01640\n",
      "[256]\ttrain-auc:0.96378+0.00113\ttest-auc:0.77700+0.01627\n",
      "[257]\ttrain-auc:0.96405+0.00107\ttest-auc:0.77730+0.01638\n",
      "[258]\ttrain-auc:0.96416+0.00111\ttest-auc:0.77722+0.01639\n",
      "[259]\ttrain-auc:0.96425+0.00112\ttest-auc:0.77722+0.01638\n",
      "[260]\ttrain-auc:0.96435+0.00115\ttest-auc:0.77725+0.01642\n",
      "[261]\ttrain-auc:0.96450+0.00111\ttest-auc:0.77709+0.01616\n",
      "[262]\ttrain-auc:0.96468+0.00100\ttest-auc:0.77695+0.01607\n",
      "[263]\ttrain-auc:0.96480+0.00093\ttest-auc:0.77703+0.01589\n",
      "[264]\ttrain-auc:0.96496+0.00088\ttest-auc:0.77710+0.01594\n",
      "[265]\ttrain-auc:0.96511+0.00079\ttest-auc:0.77716+0.01599\n",
      "[266]\ttrain-auc:0.96521+0.00081\ttest-auc:0.77701+0.01596\n",
      "[267]\ttrain-auc:0.96539+0.00082\ttest-auc:0.77721+0.01598\n",
      "[268]\ttrain-auc:0.96547+0.00084\ttest-auc:0.77716+0.01593\n",
      "[269]\ttrain-auc:0.96557+0.00084\ttest-auc:0.77724+0.01604\n",
      "[270]\ttrain-auc:0.96571+0.00091\ttest-auc:0.77730+0.01591\n",
      "[271]\ttrain-auc:0.96586+0.00092\ttest-auc:0.77720+0.01583\n",
      "[272]\ttrain-auc:0.96600+0.00097\ttest-auc:0.77732+0.01588\n",
      "[273]\ttrain-auc:0.96615+0.00100\ttest-auc:0.77727+0.01589\n",
      "[274]\ttrain-auc:0.96634+0.00099\ttest-auc:0.77744+0.01610\n",
      "[275]\ttrain-auc:0.96648+0.00102\ttest-auc:0.77747+0.01598\n",
      "[276]\ttrain-auc:0.96662+0.00107\ttest-auc:0.77751+0.01606\n",
      "[277]\ttrain-auc:0.96676+0.00098\ttest-auc:0.77762+0.01614\n",
      "[278]\ttrain-auc:0.96689+0.00103\ttest-auc:0.77759+0.01614\n",
      "[279]\ttrain-auc:0.96710+0.00097\ttest-auc:0.77758+0.01616\n",
      "[280]\ttrain-auc:0.96728+0.00094\ttest-auc:0.77758+0.01620\n",
      "[281]\ttrain-auc:0.96740+0.00095\ttest-auc:0.77746+0.01619\n",
      "[282]\ttrain-auc:0.96753+0.00100\ttest-auc:0.77753+0.01614\n",
      "[283]\ttrain-auc:0.96766+0.00103\ttest-auc:0.77760+0.01609\n",
      "[284]\ttrain-auc:0.96775+0.00105\ttest-auc:0.77755+0.01606\n",
      "[285]\ttrain-auc:0.96792+0.00101\ttest-auc:0.77757+0.01610\n",
      "[286]\ttrain-auc:0.96808+0.00101\ttest-auc:0.77763+0.01624\n",
      "[287]\ttrain-auc:0.96833+0.00094\ttest-auc:0.77760+0.01644\n",
      "[288]\ttrain-auc:0.96850+0.00096\ttest-auc:0.77750+0.01655\n",
      "[289]\ttrain-auc:0.96859+0.00097\ttest-auc:0.77741+0.01663\n",
      "[290]\ttrain-auc:0.96873+0.00097\ttest-auc:0.77740+0.01674\n",
      "[291]\ttrain-auc:0.96884+0.00100\ttest-auc:0.77745+0.01674\n",
      "[292]\ttrain-auc:0.96899+0.00095\ttest-auc:0.77738+0.01672\n",
      "[293]\ttrain-auc:0.96917+0.00096\ttest-auc:0.77766+0.01662\n",
      "[294]\ttrain-auc:0.96935+0.00102\ttest-auc:0.77772+0.01673\n",
      "[295]\ttrain-auc:0.96947+0.00104\ttest-auc:0.77783+0.01679\n",
      "[296]\ttrain-auc:0.96967+0.00108\ttest-auc:0.77774+0.01678\n",
      "[297]\ttrain-auc:0.96976+0.00106\ttest-auc:0.77780+0.01698\n",
      "[298]\ttrain-auc:0.96989+0.00109\ttest-auc:0.77778+0.01708\n",
      "[299]\ttrain-auc:0.97005+0.00105\ttest-auc:0.77776+0.01704\n",
      "[300]\ttrain-auc:0.97013+0.00104\ttest-auc:0.77779+0.01700\n",
      "[301]\ttrain-auc:0.97022+0.00104\ttest-auc:0.77766+0.01684\n",
      "[302]\ttrain-auc:0.97033+0.00105\ttest-auc:0.77763+0.01680\n",
      "[303]\ttrain-auc:0.97045+0.00107\ttest-auc:0.77766+0.01696\n",
      "[304]\ttrain-auc:0.97056+0.00103\ttest-auc:0.77764+0.01700\n",
      "[305]\ttrain-auc:0.97067+0.00107\ttest-auc:0.77776+0.01694\n",
      "[306]\ttrain-auc:0.97075+0.00105\ttest-auc:0.77769+0.01696\n",
      "[307]\ttrain-auc:0.97082+0.00102\ttest-auc:0.77743+0.01693\n",
      "[308]\ttrain-auc:0.97094+0.00104\ttest-auc:0.77720+0.01679\n",
      "[309]\ttrain-auc:0.97106+0.00103\ttest-auc:0.77713+0.01666\n",
      "[310]\ttrain-auc:0.97120+0.00104\ttest-auc:0.77702+0.01670\n",
      "[311]\ttrain-auc:0.97133+0.00105\ttest-auc:0.77710+0.01659\n",
      "[312]\ttrain-auc:0.97148+0.00097\ttest-auc:0.77713+0.01669\n",
      "[313]\ttrain-auc:0.97167+0.00105\ttest-auc:0.77716+0.01662\n",
      "[314]\ttrain-auc:0.97177+0.00102\ttest-auc:0.77724+0.01668\n",
      "[315]\ttrain-auc:0.97187+0.00099\ttest-auc:0.77732+0.01680\n",
      "[316]\ttrain-auc:0.97204+0.00096\ttest-auc:0.77731+0.01672\n",
      "[317]\ttrain-auc:0.97214+0.00091\ttest-auc:0.77740+0.01684\n",
      "[318]\ttrain-auc:0.97223+0.00089\ttest-auc:0.77745+0.01675\n",
      "[319]\ttrain-auc:0.97233+0.00089\ttest-auc:0.77750+0.01684\n",
      "[320]\ttrain-auc:0.97244+0.00088\ttest-auc:0.77755+0.01687\n",
      "[321]\ttrain-auc:0.97256+0.00086\ttest-auc:0.77757+0.01713\n",
      "[322]\ttrain-auc:0.97264+0.00093\ttest-auc:0.77761+0.01710\n",
      "[323]\ttrain-auc:0.97271+0.00096\ttest-auc:0.77770+0.01717\n",
      "[324]\ttrain-auc:0.97292+0.00091\ttest-auc:0.77783+0.01735\n",
      "[325]\ttrain-auc:0.97301+0.00092\ttest-auc:0.77772+0.01733\n",
      "[326]\ttrain-auc:0.97309+0.00094\ttest-auc:0.77763+0.01726\n",
      "[327]\ttrain-auc:0.97315+0.00096\ttest-auc:0.77771+0.01715\n",
      "[328]\ttrain-auc:0.97328+0.00091\ttest-auc:0.77775+0.01719\n",
      "[329]\ttrain-auc:0.97333+0.00092\ttest-auc:0.77776+0.01710\n",
      "[330]\ttrain-auc:0.97342+0.00092\ttest-auc:0.77781+0.01723\n",
      "[331]\ttrain-auc:0.97350+0.00095\ttest-auc:0.77787+0.01721\n",
      "[332]\ttrain-auc:0.97365+0.00090\ttest-auc:0.77788+0.01704\n",
      "[333]\ttrain-auc:0.97374+0.00092\ttest-auc:0.77783+0.01727\n",
      "[334]\ttrain-auc:0.97383+0.00092\ttest-auc:0.77789+0.01730\n",
      "[335]\ttrain-auc:0.97396+0.00091\ttest-auc:0.77781+0.01741\n",
      "[336]\ttrain-auc:0.97407+0.00095\ttest-auc:0.77772+0.01749\n",
      "[337]\ttrain-auc:0.97420+0.00093\ttest-auc:0.77768+0.01750\n",
      "[338]\ttrain-auc:0.97427+0.00093\ttest-auc:0.77771+0.01748\n",
      "[339]\ttrain-auc:0.97436+0.00095\ttest-auc:0.77758+0.01752\n",
      "[340]\ttrain-auc:0.97449+0.00097\ttest-auc:0.77753+0.01735\n",
      "[341]\ttrain-auc:0.97458+0.00096\ttest-auc:0.77759+0.01730\n",
      "[342]\ttrain-auc:0.97471+0.00088\ttest-auc:0.77756+0.01739\n",
      "[343]\ttrain-auc:0.97479+0.00089\ttest-auc:0.77739+0.01733\n",
      "[344]\ttrain-auc:0.97485+0.00092\ttest-auc:0.77729+0.01736\n",
      "[345]\ttrain-auc:0.97496+0.00090\ttest-auc:0.77737+0.01750\n",
      "[346]\ttrain-auc:0.97504+0.00093\ttest-auc:0.77723+0.01744\n",
      "[347]\ttrain-auc:0.97517+0.00091\ttest-auc:0.77714+0.01748\n",
      "[348]\ttrain-auc:0.97528+0.00090\ttest-auc:0.77709+0.01747\n",
      "[349]\ttrain-auc:0.97536+0.00091\ttest-auc:0.77689+0.01755\n",
      "[350]\ttrain-auc:0.97549+0.00091\ttest-auc:0.77679+0.01737\n",
      "[351]\ttrain-auc:0.97555+0.00092\ttest-auc:0.77676+0.01733\n",
      "[352]\ttrain-auc:0.97567+0.00091\ttest-auc:0.77688+0.01733\n",
      "[353]\ttrain-auc:0.97575+0.00096\ttest-auc:0.77671+0.01747\n",
      "[354]\ttrain-auc:0.97582+0.00097\ttest-auc:0.77675+0.01757\n",
      "[355]\ttrain-auc:0.97594+0.00096\ttest-auc:0.77675+0.01733\n",
      "[356]\ttrain-auc:0.97606+0.00095\ttest-auc:0.77684+0.01737\n",
      "[357]\ttrain-auc:0.97616+0.00096\ttest-auc:0.77711+0.01727\n",
      "[358]\ttrain-auc:0.97626+0.00094\ttest-auc:0.77705+0.01718\n",
      "[359]\ttrain-auc:0.97634+0.00091\ttest-auc:0.77700+0.01726\n",
      "[360]\ttrain-auc:0.97645+0.00085\ttest-auc:0.77700+0.01722\n",
      "[361]\ttrain-auc:0.97659+0.00085\ttest-auc:0.77704+0.01746\n",
      "[362]\ttrain-auc:0.97669+0.00088\ttest-auc:0.77693+0.01764\n",
      "[363]\ttrain-auc:0.97676+0.00084\ttest-auc:0.77687+0.01773\n",
      "[364]\ttrain-auc:0.97684+0.00086\ttest-auc:0.77688+0.01777\n",
      "[365]\ttrain-auc:0.97700+0.00090\ttest-auc:0.77710+0.01770\n",
      "[366]\ttrain-auc:0.97712+0.00093\ttest-auc:0.77711+0.01764\n",
      "[367]\ttrain-auc:0.97717+0.00094\ttest-auc:0.77706+0.01758\n",
      "[368]\ttrain-auc:0.97724+0.00094\ttest-auc:0.77705+0.01750\n",
      "[369]\ttrain-auc:0.97738+0.00098\ttest-auc:0.77702+0.01756\n",
      "[370]\ttrain-auc:0.97749+0.00098\ttest-auc:0.77701+0.01746\n",
      "[371]\ttrain-auc:0.97757+0.00099\ttest-auc:0.77688+0.01736\n",
      "[372]\ttrain-auc:0.97764+0.00101\ttest-auc:0.77687+0.01735\n",
      "[373]\ttrain-auc:0.97770+0.00102\ttest-auc:0.77682+0.01721\n",
      "[374]\ttrain-auc:0.97781+0.00103\ttest-auc:0.77688+0.01733\n",
      "[375]\ttrain-auc:0.97787+0.00103\ttest-auc:0.77664+0.01731\n",
      "[376]\ttrain-auc:0.97797+0.00110\ttest-auc:0.77654+0.01730\n",
      "[377]\ttrain-auc:0.97803+0.00111\ttest-auc:0.77653+0.01733\n",
      "[378]\ttrain-auc:0.97818+0.00101\ttest-auc:0.77658+0.01726\n",
      "[379]\ttrain-auc:0.97824+0.00100\ttest-auc:0.77646+0.01727\n",
      "[380]\ttrain-auc:0.97834+0.00104\ttest-auc:0.77650+0.01723\n",
      "[381]\ttrain-auc:0.97844+0.00102\ttest-auc:0.77654+0.01723\n",
      "[382]\ttrain-auc:0.97852+0.00105\ttest-auc:0.77669+0.01722\n",
      "[383]\ttrain-auc:0.97863+0.00102\ttest-auc:0.77679+0.01734\n",
      "[384]\ttrain-auc:0.97870+0.00103\ttest-auc:0.77683+0.01733\n",
      "[385]\ttrain-auc:0.97882+0.00101\ttest-auc:0.77682+0.01747\n",
      "[386]\ttrain-auc:0.97889+0.00103\ttest-auc:0.77691+0.01749\n",
      "[387]\ttrain-auc:0.97896+0.00107\ttest-auc:0.77690+0.01763\n",
      "[388]\ttrain-auc:0.97901+0.00103\ttest-auc:0.77688+0.01761\n",
      "[389]\ttrain-auc:0.97906+0.00102\ttest-auc:0.77683+0.01759\n",
      "[390]\ttrain-auc:0.97911+0.00104\ttest-auc:0.77672+0.01748\n",
      "[391]\ttrain-auc:0.97917+0.00101\ttest-auc:0.77674+0.01750\n",
      "[392]\ttrain-auc:0.97928+0.00098\ttest-auc:0.77683+0.01738\n",
      "[393]\ttrain-auc:0.97937+0.00098\ttest-auc:0.77680+0.01736\n",
      "[394]\ttrain-auc:0.97945+0.00097\ttest-auc:0.77673+0.01727\n",
      "[395]\ttrain-auc:0.97950+0.00099\ttest-auc:0.77683+0.01727\n",
      "[396]\ttrain-auc:0.97958+0.00096\ttest-auc:0.77689+0.01717\n",
      "[397]\ttrain-auc:0.97965+0.00096\ttest-auc:0.77681+0.01715\n",
      "[398]\ttrain-auc:0.97972+0.00093\ttest-auc:0.77680+0.01716\n",
      "[399]\ttrain-auc:0.97978+0.00094\ttest-auc:0.77688+0.01719\n",
      "[400]\ttrain-auc:0.97984+0.00095\ttest-auc:0.77682+0.01724\n",
      "[401]\ttrain-auc:0.97989+0.00094\ttest-auc:0.77668+0.01719\n",
      "[402]\ttrain-auc:0.97995+0.00094\ttest-auc:0.77674+0.01712\n",
      "[403]\ttrain-auc:0.98004+0.00094\ttest-auc:0.77668+0.01705\n",
      "[404]\ttrain-auc:0.98012+0.00093\ttest-auc:0.77683+0.01698\n",
      "[405]\ttrain-auc:0.98015+0.00095\ttest-auc:0.77685+0.01700\n",
      "[406]\ttrain-auc:0.98024+0.00096\ttest-auc:0.77694+0.01703\n",
      "[407]\ttrain-auc:0.98031+0.00097\ttest-auc:0.77704+0.01696\n",
      "[408]\ttrain-auc:0.98035+0.00097\ttest-auc:0.77693+0.01708\n",
      "[409]\ttrain-auc:0.98040+0.00097\ttest-auc:0.77697+0.01720\n",
      "[410]\ttrain-auc:0.98047+0.00098\ttest-auc:0.77680+0.01712\n",
      "[411]\ttrain-auc:0.98052+0.00101\ttest-auc:0.77673+0.01700\n",
      "[412]\ttrain-auc:0.98058+0.00102\ttest-auc:0.77675+0.01707\n",
      "[413]\ttrain-auc:0.98063+0.00102\ttest-auc:0.77658+0.01713\n",
      "[414]\ttrain-auc:0.98071+0.00104\ttest-auc:0.77666+0.01716\n",
      "[415]\ttrain-auc:0.98075+0.00103\ttest-auc:0.77673+0.01715\n",
      "[416]\ttrain-auc:0.98084+0.00100\ttest-auc:0.77680+0.01706\n",
      "[417]\ttrain-auc:0.98088+0.00100\ttest-auc:0.77680+0.01711\n",
      "[418]\ttrain-auc:0.98096+0.00103\ttest-auc:0.77682+0.01703\n",
      "[419]\ttrain-auc:0.98100+0.00103\ttest-auc:0.77684+0.01709\n",
      "[420]\ttrain-auc:0.98105+0.00105\ttest-auc:0.77684+0.01723\n",
      "[421]\ttrain-auc:0.98113+0.00105\ttest-auc:0.77688+0.01730\n",
      "[422]\ttrain-auc:0.98120+0.00105\ttest-auc:0.77684+0.01737\n",
      "[423]\ttrain-auc:0.98128+0.00105\ttest-auc:0.77693+0.01744\n",
      "[424]\ttrain-auc:0.98135+0.00104\ttest-auc:0.77695+0.01751\n",
      "[425]\ttrain-auc:0.98145+0.00104\ttest-auc:0.77713+0.01742\n",
      "[426]\ttrain-auc:0.98154+0.00098\ttest-auc:0.77711+0.01743\n",
      "[427]\ttrain-auc:0.98160+0.00099\ttest-auc:0.77705+0.01740\n",
      "[428]\ttrain-auc:0.98166+0.00098\ttest-auc:0.77701+0.01747\n",
      "[429]\ttrain-auc:0.98172+0.00101\ttest-auc:0.77711+0.01754\n",
      "[430]\ttrain-auc:0.98174+0.00100\ttest-auc:0.77710+0.01743\n",
      "[431]\ttrain-auc:0.98178+0.00104\ttest-auc:0.77719+0.01750\n",
      "[432]\ttrain-auc:0.98187+0.00102\ttest-auc:0.77712+0.01752\n",
      "[433]\ttrain-auc:0.98191+0.00104\ttest-auc:0.77714+0.01747\n",
      "Stopping. Best iteration:\n",
      "[334]\ttrain-auc:0.97383+0.00092\ttest-auc:0.77789+0.01730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\training.py:20: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_result = xgb.cv(xgb1.get_xgb_params(),\n",
    "dtrain,\n",
    "num_boost_round=xgb1.get_params()['n_estimators'],\n",
    "nfold=5,\n",
    "metrics='auc',\n",
    "early_stopping_rounds=100,\n",
    "callbacks=[xgb.callback.early_stop(100),\n",
    "xgb.callback.print_evaluation(period=1,show_stdv=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到最佳迭代次数为334，修改为334测试得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.05,\n",
    "                     n_estimators=334,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.5397672192893087 0.6752529346205619\n",
      "f1= 0.14678899082568805 0.5175\n",
      "precision_score= 0.75 0.9857142857142858\n",
      "recall_score= 0.08135593220338982 0.35084745762711866\n",
      "accuracy= 0.9404736505227225 0.9588156841824487\n",
      "auc= 0.5397672192893087 0.6752529346205619\n",
      "#####混淆矩阵#########\n",
      "[[4384    8]\n",
      " [ 271   24]] [[17559     6]\n",
      " [  766   414]]\n"
     ]
    }
   ],
   "source": [
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.01,\n",
    "                     n_estimators=10000,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[0]\ttrain-auc:0.71898+0.01835\ttest-auc:0.69875+0.01339\n",
      "[1]\ttrain-auc:0.73414+0.00877\ttest-auc:0.71026+0.02635\n",
      "[2]\ttrain-auc:0.73687+0.01013\ttest-auc:0.71095+0.02558\n",
      "[3]\ttrain-auc:0.74004+0.00829\ttest-auc:0.71338+0.02348\n",
      "[4]\ttrain-auc:0.74397+0.00744\ttest-auc:0.71888+0.02758\n",
      "[5]\ttrain-auc:0.74595+0.00856\ttest-auc:0.71984+0.02759\n",
      "[6]\ttrain-auc:0.74893+0.00579\ttest-auc:0.72063+0.02613\n",
      "[7]\ttrain-auc:0.74913+0.00598\ttest-auc:0.72119+0.02559\n",
      "[8]\ttrain-auc:0.75060+0.00462\ttest-auc:0.72172+0.02546\n",
      "[9]\ttrain-auc:0.75443+0.00449\ttest-auc:0.72199+0.02384\n",
      "[10]\ttrain-auc:0.75550+0.00484\ttest-auc:0.72226+0.02527\n",
      "[11]\ttrain-auc:0.75641+0.00457\ttest-auc:0.72220+0.02525\n",
      "[12]\ttrain-auc:0.75690+0.00361\ttest-auc:0.72300+0.02491\n",
      "[13]\ttrain-auc:0.75835+0.00409\ttest-auc:0.72446+0.02362\n",
      "[14]\ttrain-auc:0.76013+0.00233\ttest-auc:0.72422+0.02451\n",
      "[15]\ttrain-auc:0.76300+0.00443\ttest-auc:0.72521+0.02451\n",
      "[16]\ttrain-auc:0.76403+0.00402\ttest-auc:0.72621+0.02525\n",
      "[17]\ttrain-auc:0.76574+0.00370\ttest-auc:0.72622+0.02518\n",
      "[18]\ttrain-auc:0.76706+0.00317\ttest-auc:0.72633+0.02523\n",
      "[19]\ttrain-auc:0.76815+0.00365\ttest-auc:0.72702+0.02493\n",
      "[20]\ttrain-auc:0.76865+0.00353\ttest-auc:0.72718+0.02573\n",
      "[21]\ttrain-auc:0.77005+0.00244\ttest-auc:0.72721+0.02584\n",
      "[22]\ttrain-auc:0.77065+0.00266\ttest-auc:0.72681+0.02515\n",
      "[23]\ttrain-auc:0.77195+0.00190\ttest-auc:0.72705+0.02492\n",
      "[24]\ttrain-auc:0.77237+0.00177\ttest-auc:0.72746+0.02449\n",
      "[25]\ttrain-auc:0.77381+0.00216\ttest-auc:0.72885+0.02335\n",
      "[26]\ttrain-auc:0.77540+0.00291\ttest-auc:0.72964+0.02410\n",
      "[27]\ttrain-auc:0.77575+0.00305\ttest-auc:0.72917+0.02393\n",
      "[28]\ttrain-auc:0.77627+0.00298\ttest-auc:0.72882+0.02333\n",
      "[29]\ttrain-auc:0.77707+0.00325\ttest-auc:0.72937+0.02320\n",
      "[30]\ttrain-auc:0.77818+0.00263\ttest-auc:0.73035+0.02288\n",
      "[31]\ttrain-auc:0.77862+0.00207\ttest-auc:0.73051+0.02306\n",
      "[32]\ttrain-auc:0.77899+0.00226\ttest-auc:0.73081+0.02345\n",
      "[33]\ttrain-auc:0.78037+0.00255\ttest-auc:0.73102+0.02404\n",
      "[34]\ttrain-auc:0.78158+0.00297\ttest-auc:0.73163+0.02430\n",
      "[35]\ttrain-auc:0.78187+0.00320\ttest-auc:0.73208+0.02376\n",
      "[36]\ttrain-auc:0.78231+0.00299\ttest-auc:0.73211+0.02350\n",
      "[37]\ttrain-auc:0.78285+0.00303\ttest-auc:0.73248+0.02337\n",
      "[38]\ttrain-auc:0.78320+0.00298\ttest-auc:0.73231+0.02314\n",
      "[39]\ttrain-auc:0.78381+0.00324\ttest-auc:0.73243+0.02368\n",
      "[40]\ttrain-auc:0.78480+0.00386\ttest-auc:0.73266+0.02414\n",
      "[41]\ttrain-auc:0.78685+0.00364\ttest-auc:0.73308+0.02390\n",
      "[42]\ttrain-auc:0.78729+0.00371\ttest-auc:0.73292+0.02387\n",
      "[43]\ttrain-auc:0.78839+0.00320\ttest-auc:0.73401+0.02321\n",
      "[44]\ttrain-auc:0.78853+0.00348\ttest-auc:0.73445+0.02393\n",
      "[45]\ttrain-auc:0.78928+0.00299\ttest-auc:0.73449+0.02402\n",
      "[46]\ttrain-auc:0.79007+0.00298\ttest-auc:0.73448+0.02394\n",
      "[47]\ttrain-auc:0.79194+0.00288\ttest-auc:0.73584+0.02334\n",
      "[48]\ttrain-auc:0.79243+0.00292\ttest-auc:0.73597+0.02336\n",
      "[49]\ttrain-auc:0.79290+0.00295\ttest-auc:0.73562+0.02311\n",
      "[50]\ttrain-auc:0.79329+0.00333\ttest-auc:0.73538+0.02331\n",
      "[51]\ttrain-auc:0.79385+0.00305\ttest-auc:0.73553+0.02334\n",
      "[52]\ttrain-auc:0.79414+0.00297\ttest-auc:0.73534+0.02354\n",
      "[53]\ttrain-auc:0.79495+0.00318\ttest-auc:0.73536+0.02299\n",
      "[54]\ttrain-auc:0.79547+0.00273\ttest-auc:0.73580+0.02306\n",
      "[55]\ttrain-auc:0.79588+0.00241\ttest-auc:0.73560+0.02323\n",
      "[56]\ttrain-auc:0.79664+0.00221\ttest-auc:0.73604+0.02307\n",
      "[57]\ttrain-auc:0.79681+0.00216\ttest-auc:0.73631+0.02308\n",
      "[58]\ttrain-auc:0.79727+0.00197\ttest-auc:0.73639+0.02338\n",
      "[59]\ttrain-auc:0.79780+0.00215\ttest-auc:0.73650+0.02343\n",
      "[60]\ttrain-auc:0.79831+0.00206\ttest-auc:0.73660+0.02328\n",
      "[61]\ttrain-auc:0.79898+0.00165\ttest-auc:0.73686+0.02322\n",
      "[62]\ttrain-auc:0.79937+0.00159\ttest-auc:0.73705+0.02316\n",
      "[63]\ttrain-auc:0.79999+0.00174\ttest-auc:0.73728+0.02323\n",
      "[64]\ttrain-auc:0.80032+0.00184\ttest-auc:0.73756+0.02294\n",
      "[65]\ttrain-auc:0.80085+0.00180\ttest-auc:0.73797+0.02303\n",
      "[66]\ttrain-auc:0.80196+0.00131\ttest-auc:0.73848+0.02308\n",
      "[67]\ttrain-auc:0.80217+0.00130\ttest-auc:0.73856+0.02309\n",
      "[68]\ttrain-auc:0.80296+0.00145\ttest-auc:0.73898+0.02377\n",
      "[69]\ttrain-auc:0.80364+0.00130\ttest-auc:0.73908+0.02347\n",
      "[70]\ttrain-auc:0.80435+0.00112\ttest-auc:0.73899+0.02318\n",
      "[71]\ttrain-auc:0.80493+0.00129\ttest-auc:0.73933+0.02318\n",
      "[72]\ttrain-auc:0.80559+0.00109\ttest-auc:0.73961+0.02344\n",
      "[73]\ttrain-auc:0.80615+0.00119\ttest-auc:0.73972+0.02347\n",
      "[74]\ttrain-auc:0.80677+0.00120\ttest-auc:0.74001+0.02337\n",
      "[75]\ttrain-auc:0.80690+0.00116\ttest-auc:0.73975+0.02321\n",
      "[76]\ttrain-auc:0.80728+0.00135\ttest-auc:0.74022+0.02322\n",
      "[77]\ttrain-auc:0.80764+0.00157\ttest-auc:0.74032+0.02328\n",
      "[78]\ttrain-auc:0.80788+0.00167\ttest-auc:0.74072+0.02339\n",
      "[79]\ttrain-auc:0.80827+0.00177\ttest-auc:0.74064+0.02344\n",
      "[80]\ttrain-auc:0.80859+0.00192\ttest-auc:0.74100+0.02333\n",
      "[81]\ttrain-auc:0.80895+0.00215\ttest-auc:0.74117+0.02335\n",
      "[82]\ttrain-auc:0.80913+0.00217\ttest-auc:0.74142+0.02350\n",
      "[83]\ttrain-auc:0.80962+0.00216\ttest-auc:0.74186+0.02339\n",
      "[84]\ttrain-auc:0.81024+0.00237\ttest-auc:0.74211+0.02349\n",
      "[85]\ttrain-auc:0.81074+0.00228\ttest-auc:0.74223+0.02364\n",
      "[86]\ttrain-auc:0.81103+0.00231\ttest-auc:0.74228+0.02369\n",
      "[87]\ttrain-auc:0.81142+0.00229\ttest-auc:0.74207+0.02356\n",
      "[88]\ttrain-auc:0.81194+0.00245\ttest-auc:0.74236+0.02333\n",
      "[89]\ttrain-auc:0.81218+0.00243\ttest-auc:0.74248+0.02347\n",
      "[90]\ttrain-auc:0.81240+0.00234\ttest-auc:0.74249+0.02349\n",
      "[91]\ttrain-auc:0.81313+0.00226\ttest-auc:0.74254+0.02327\n",
      "[92]\ttrain-auc:0.81346+0.00234\ttest-auc:0.74271+0.02308\n",
      "[93]\ttrain-auc:0.81391+0.00233\ttest-auc:0.74299+0.02362\n",
      "[94]\ttrain-auc:0.81426+0.00259\ttest-auc:0.74307+0.02352\n",
      "[95]\ttrain-auc:0.81470+0.00264\ttest-auc:0.74340+0.02342\n",
      "[96]\ttrain-auc:0.81495+0.00253\ttest-auc:0.74363+0.02348\n",
      "[97]\ttrain-auc:0.81535+0.00213\ttest-auc:0.74347+0.02365\n",
      "[98]\ttrain-auc:0.81563+0.00224\ttest-auc:0.74365+0.02362\n",
      "[99]\ttrain-auc:0.81607+0.00207\ttest-auc:0.74408+0.02367\n",
      "[100]\ttrain-auc:0.81612+0.00221\ttest-auc:0.74407+0.02339\n",
      "[101]\ttrain-auc:0.81637+0.00234\ttest-auc:0.74420+0.02326\n",
      "[102]\ttrain-auc:0.81658+0.00235\ttest-auc:0.74445+0.02340\n",
      "[103]\ttrain-auc:0.81700+0.00245\ttest-auc:0.74439+0.02322\n",
      "[104]\ttrain-auc:0.81716+0.00262\ttest-auc:0.74434+0.02336\n",
      "[105]\ttrain-auc:0.81751+0.00260\ttest-auc:0.74435+0.02317\n",
      "[106]\ttrain-auc:0.81782+0.00248\ttest-auc:0.74427+0.02323\n",
      "[107]\ttrain-auc:0.81811+0.00256\ttest-auc:0.74440+0.02307\n",
      "[108]\ttrain-auc:0.81825+0.00267\ttest-auc:0.74462+0.02317\n",
      "[109]\ttrain-auc:0.81850+0.00267\ttest-auc:0.74477+0.02319\n",
      "[110]\ttrain-auc:0.81886+0.00266\ttest-auc:0.74464+0.02309\n",
      "[111]\ttrain-auc:0.81938+0.00261\ttest-auc:0.74481+0.02304\n",
      "[112]\ttrain-auc:0.81964+0.00261\ttest-auc:0.74496+0.02297\n",
      "[113]\ttrain-auc:0.81985+0.00263\ttest-auc:0.74502+0.02282\n",
      "[114]\ttrain-auc:0.82014+0.00247\ttest-auc:0.74516+0.02284\n",
      "[115]\ttrain-auc:0.82045+0.00249\ttest-auc:0.74529+0.02281\n",
      "[116]\ttrain-auc:0.82086+0.00245\ttest-auc:0.74560+0.02298\n",
      "[117]\ttrain-auc:0.82110+0.00270\ttest-auc:0.74572+0.02263\n",
      "[118]\ttrain-auc:0.82157+0.00283\ttest-auc:0.74574+0.02250\n",
      "[119]\ttrain-auc:0.82177+0.00277\ttest-auc:0.74586+0.02257\n",
      "[120]\ttrain-auc:0.82225+0.00255\ttest-auc:0.74615+0.02260\n",
      "[121]\ttrain-auc:0.82255+0.00237\ttest-auc:0.74634+0.02266\n",
      "[122]\ttrain-auc:0.82284+0.00238\ttest-auc:0.74638+0.02258\n",
      "[123]\ttrain-auc:0.82304+0.00247\ttest-auc:0.74637+0.02258\n",
      "[124]\ttrain-auc:0.82326+0.00256\ttest-auc:0.74639+0.02253\n",
      "[125]\ttrain-auc:0.82356+0.00263\ttest-auc:0.74668+0.02256\n",
      "[126]\ttrain-auc:0.82373+0.00281\ttest-auc:0.74659+0.02266\n",
      "[127]\ttrain-auc:0.82411+0.00287\ttest-auc:0.74677+0.02260\n",
      "[128]\ttrain-auc:0.82429+0.00293\ttest-auc:0.74691+0.02253\n",
      "[129]\ttrain-auc:0.82452+0.00299\ttest-auc:0.74709+0.02263\n",
      "[130]\ttrain-auc:0.82480+0.00315\ttest-auc:0.74724+0.02254\n",
      "[131]\ttrain-auc:0.82490+0.00315\ttest-auc:0.74725+0.02245\n",
      "[132]\ttrain-auc:0.82509+0.00320\ttest-auc:0.74734+0.02233\n",
      "[133]\ttrain-auc:0.82539+0.00309\ttest-auc:0.74742+0.02232\n",
      "[134]\ttrain-auc:0.82571+0.00305\ttest-auc:0.74760+0.02213\n",
      "[135]\ttrain-auc:0.82593+0.00315\ttest-auc:0.74765+0.02206\n",
      "[136]\ttrain-auc:0.82619+0.00323\ttest-auc:0.74801+0.02196\n",
      "[137]\ttrain-auc:0.82662+0.00306\ttest-auc:0.74830+0.02204\n",
      "[138]\ttrain-auc:0.82711+0.00326\ttest-auc:0.74842+0.02199\n",
      "[139]\ttrain-auc:0.82747+0.00316\ttest-auc:0.74850+0.02194\n",
      "[140]\ttrain-auc:0.82782+0.00322\ttest-auc:0.74859+0.02189\n",
      "[141]\ttrain-auc:0.82817+0.00330\ttest-auc:0.74867+0.02163\n",
      "[142]\ttrain-auc:0.82852+0.00343\ttest-auc:0.74872+0.02152\n",
      "[143]\ttrain-auc:0.82896+0.00352\ttest-auc:0.74884+0.02144\n",
      "[144]\ttrain-auc:0.82932+0.00341\ttest-auc:0.74886+0.02127\n",
      "[145]\ttrain-auc:0.82952+0.00356\ttest-auc:0.74881+0.02136\n",
      "[146]\ttrain-auc:0.82986+0.00349\ttest-auc:0.74884+0.02134\n",
      "[147]\ttrain-auc:0.83007+0.00357\ttest-auc:0.74917+0.02110\n",
      "[148]\ttrain-auc:0.83049+0.00343\ttest-auc:0.74936+0.02112\n",
      "[149]\ttrain-auc:0.83055+0.00350\ttest-auc:0.74919+0.02115\n",
      "[150]\ttrain-auc:0.83089+0.00341\ttest-auc:0.74909+0.02108\n",
      "[151]\ttrain-auc:0.83118+0.00339\ttest-auc:0.74917+0.02094\n",
      "[152]\ttrain-auc:0.83139+0.00346\ttest-auc:0.74935+0.02096\n",
      "[153]\ttrain-auc:0.83166+0.00332\ttest-auc:0.74952+0.02111\n",
      "[154]\ttrain-auc:0.83199+0.00329\ttest-auc:0.74966+0.02114\n",
      "[155]\ttrain-auc:0.83217+0.00320\ttest-auc:0.74965+0.02097\n",
      "[156]\ttrain-auc:0.83250+0.00320\ttest-auc:0.74991+0.02105\n",
      "[157]\ttrain-auc:0.83290+0.00302\ttest-auc:0.75027+0.02120\n",
      "[158]\ttrain-auc:0.83310+0.00311\ttest-auc:0.75010+0.02118\n",
      "[159]\ttrain-auc:0.83326+0.00311\ttest-auc:0.75014+0.02130\n",
      "[160]\ttrain-auc:0.83384+0.00295\ttest-auc:0.75028+0.02144\n",
      "[161]\ttrain-auc:0.83415+0.00300\ttest-auc:0.75036+0.02138\n",
      "[162]\ttrain-auc:0.83432+0.00308\ttest-auc:0.75029+0.02131\n",
      "[163]\ttrain-auc:0.83466+0.00302\ttest-auc:0.75037+0.02121\n",
      "[164]\ttrain-auc:0.83499+0.00322\ttest-auc:0.75043+0.02127\n",
      "[165]\ttrain-auc:0.83526+0.00324\ttest-auc:0.75028+0.02135\n",
      "[166]\ttrain-auc:0.83553+0.00328\ttest-auc:0.75052+0.02127\n",
      "[167]\ttrain-auc:0.83578+0.00324\ttest-auc:0.75049+0.02120\n",
      "[168]\ttrain-auc:0.83602+0.00321\ttest-auc:0.75055+0.02119\n",
      "[169]\ttrain-auc:0.83619+0.00318\ttest-auc:0.75049+0.02118\n",
      "[170]\ttrain-auc:0.83660+0.00323\ttest-auc:0.75074+0.02106\n",
      "[171]\ttrain-auc:0.83686+0.00315\ttest-auc:0.75074+0.02109\n",
      "[172]\ttrain-auc:0.83731+0.00321\ttest-auc:0.75086+0.02097\n",
      "[173]\ttrain-auc:0.83749+0.00330\ttest-auc:0.75099+0.02094\n",
      "[174]\ttrain-auc:0.83768+0.00331\ttest-auc:0.75095+0.02093\n",
      "[175]\ttrain-auc:0.83802+0.00330\ttest-auc:0.75099+0.02090\n",
      "[176]\ttrain-auc:0.83830+0.00346\ttest-auc:0.75102+0.02079\n",
      "[177]\ttrain-auc:0.83856+0.00356\ttest-auc:0.75115+0.02093\n",
      "[178]\ttrain-auc:0.83891+0.00350\ttest-auc:0.75122+0.02086\n",
      "[179]\ttrain-auc:0.83911+0.00352\ttest-auc:0.75119+0.02089\n",
      "[180]\ttrain-auc:0.83944+0.00335\ttest-auc:0.75130+0.02100\n",
      "[181]\ttrain-auc:0.83980+0.00332\ttest-auc:0.75152+0.02107\n",
      "[182]\ttrain-auc:0.84007+0.00339\ttest-auc:0.75164+0.02103\n",
      "[183]\ttrain-auc:0.84022+0.00335\ttest-auc:0.75167+0.02116\n",
      "[184]\ttrain-auc:0.84052+0.00343\ttest-auc:0.75166+0.02111\n",
      "[185]\ttrain-auc:0.84073+0.00351\ttest-auc:0.75172+0.02120\n",
      "[186]\ttrain-auc:0.84095+0.00346\ttest-auc:0.75173+0.02121\n",
      "[187]\ttrain-auc:0.84133+0.00317\ttest-auc:0.75196+0.02135\n",
      "[188]\ttrain-auc:0.84153+0.00309\ttest-auc:0.75189+0.02139\n",
      "[189]\ttrain-auc:0.84183+0.00306\ttest-auc:0.75195+0.02132\n",
      "[190]\ttrain-auc:0.84214+0.00309\ttest-auc:0.75206+0.02136\n",
      "[191]\ttrain-auc:0.84232+0.00316\ttest-auc:0.75222+0.02140\n",
      "[192]\ttrain-auc:0.84267+0.00309\ttest-auc:0.75232+0.02149\n",
      "[193]\ttrain-auc:0.84296+0.00314\ttest-auc:0.75234+0.02150\n",
      "[194]\ttrain-auc:0.84324+0.00317\ttest-auc:0.75233+0.02148\n",
      "[195]\ttrain-auc:0.84352+0.00315\ttest-auc:0.75242+0.02143\n",
      "[196]\ttrain-auc:0.84380+0.00317\ttest-auc:0.75235+0.02141\n",
      "[197]\ttrain-auc:0.84412+0.00312\ttest-auc:0.75257+0.02143\n",
      "[198]\ttrain-auc:0.84449+0.00314\ttest-auc:0.75268+0.02155\n",
      "[199]\ttrain-auc:0.84477+0.00302\ttest-auc:0.75273+0.02162\n",
      "[200]\ttrain-auc:0.84514+0.00313\ttest-auc:0.75283+0.02186\n",
      "[201]\ttrain-auc:0.84536+0.00310\ttest-auc:0.75294+0.02177\n",
      "[202]\ttrain-auc:0.84568+0.00313\ttest-auc:0.75304+0.02172\n",
      "[203]\ttrain-auc:0.84595+0.00325\ttest-auc:0.75313+0.02166\n",
      "[204]\ttrain-auc:0.84628+0.00318\ttest-auc:0.75335+0.02181\n",
      "[205]\ttrain-auc:0.84672+0.00301\ttest-auc:0.75340+0.02174\n",
      "[206]\ttrain-auc:0.84699+0.00316\ttest-auc:0.75354+0.02157\n",
      "[207]\ttrain-auc:0.84724+0.00309\ttest-auc:0.75351+0.02149\n",
      "[208]\ttrain-auc:0.84747+0.00313\ttest-auc:0.75364+0.02141\n",
      "[209]\ttrain-auc:0.84772+0.00310\ttest-auc:0.75372+0.02128\n",
      "[210]\ttrain-auc:0.84802+0.00301\ttest-auc:0.75392+0.02125\n",
      "[211]\ttrain-auc:0.84824+0.00308\ttest-auc:0.75380+0.02122\n",
      "[212]\ttrain-auc:0.84855+0.00303\ttest-auc:0.75391+0.02113\n",
      "[213]\ttrain-auc:0.84878+0.00298\ttest-auc:0.75395+0.02117\n",
      "[214]\ttrain-auc:0.84902+0.00279\ttest-auc:0.75397+0.02123\n",
      "[215]\ttrain-auc:0.84933+0.00276\ttest-auc:0.75396+0.02122\n",
      "[216]\ttrain-auc:0.84964+0.00288\ttest-auc:0.75405+0.02142\n",
      "[217]\ttrain-auc:0.85004+0.00287\ttest-auc:0.75417+0.02133\n",
      "[218]\ttrain-auc:0.85029+0.00284\ttest-auc:0.75430+0.02114\n",
      "[219]\ttrain-auc:0.85059+0.00299\ttest-auc:0.75435+0.02111\n",
      "[220]\ttrain-auc:0.85084+0.00288\ttest-auc:0.75450+0.02121\n",
      "[221]\ttrain-auc:0.85126+0.00288\ttest-auc:0.75463+0.02131\n",
      "[222]\ttrain-auc:0.85158+0.00297\ttest-auc:0.75469+0.02134\n",
      "[223]\ttrain-auc:0.85176+0.00298\ttest-auc:0.75473+0.02134\n",
      "[224]\ttrain-auc:0.85189+0.00297\ttest-auc:0.75485+0.02137\n",
      "[225]\ttrain-auc:0.85218+0.00286\ttest-auc:0.75502+0.02151\n",
      "[226]\ttrain-auc:0.85238+0.00289\ttest-auc:0.75511+0.02156\n",
      "[227]\ttrain-auc:0.85260+0.00292\ttest-auc:0.75516+0.02150\n",
      "[228]\ttrain-auc:0.85278+0.00291\ttest-auc:0.75521+0.02137\n",
      "[229]\ttrain-auc:0.85319+0.00279\ttest-auc:0.75547+0.02154\n",
      "[230]\ttrain-auc:0.85349+0.00278\ttest-auc:0.75548+0.02152\n",
      "[231]\ttrain-auc:0.85386+0.00288\ttest-auc:0.75543+0.02147\n",
      "[232]\ttrain-auc:0.85434+0.00288\ttest-auc:0.75563+0.02151\n",
      "[233]\ttrain-auc:0.85460+0.00289\ttest-auc:0.75581+0.02154\n",
      "[234]\ttrain-auc:0.85494+0.00283\ttest-auc:0.75588+0.02159\n",
      "[235]\ttrain-auc:0.85515+0.00290\ttest-auc:0.75594+0.02160\n",
      "[236]\ttrain-auc:0.85551+0.00299\ttest-auc:0.75604+0.02157\n",
      "[237]\ttrain-auc:0.85589+0.00300\ttest-auc:0.75613+0.02163\n",
      "[238]\ttrain-auc:0.85598+0.00306\ttest-auc:0.75624+0.02172\n",
      "[239]\ttrain-auc:0.85619+0.00302\ttest-auc:0.75641+0.02181\n",
      "[240]\ttrain-auc:0.85646+0.00311\ttest-auc:0.75648+0.02186\n",
      "[241]\ttrain-auc:0.85684+0.00300\ttest-auc:0.75668+0.02195\n",
      "[242]\ttrain-auc:0.85717+0.00296\ttest-auc:0.75661+0.02188\n",
      "[243]\ttrain-auc:0.85752+0.00281\ttest-auc:0.75674+0.02176\n",
      "[244]\ttrain-auc:0.85780+0.00296\ttest-auc:0.75674+0.02181\n",
      "[245]\ttrain-auc:0.85812+0.00312\ttest-auc:0.75669+0.02186\n",
      "[246]\ttrain-auc:0.85841+0.00313\ttest-auc:0.75676+0.02182\n",
      "[247]\ttrain-auc:0.85871+0.00301\ttest-auc:0.75694+0.02208\n",
      "[248]\ttrain-auc:0.85898+0.00298\ttest-auc:0.75701+0.02213\n",
      "[249]\ttrain-auc:0.85920+0.00308\ttest-auc:0.75707+0.02204\n",
      "[250]\ttrain-auc:0.85946+0.00301\ttest-auc:0.75720+0.02211\n",
      "[251]\ttrain-auc:0.85980+0.00304\ttest-auc:0.75731+0.02200\n",
      "[252]\ttrain-auc:0.86015+0.00319\ttest-auc:0.75728+0.02200\n",
      "[253]\ttrain-auc:0.86045+0.00314\ttest-auc:0.75733+0.02194\n",
      "[254]\ttrain-auc:0.86085+0.00305\ttest-auc:0.75740+0.02185\n",
      "[255]\ttrain-auc:0.86098+0.00302\ttest-auc:0.75742+0.02187\n",
      "[256]\ttrain-auc:0.86129+0.00304\ttest-auc:0.75757+0.02188\n",
      "[257]\ttrain-auc:0.86152+0.00302\ttest-auc:0.75769+0.02195\n",
      "[258]\ttrain-auc:0.86168+0.00303\ttest-auc:0.75772+0.02195\n",
      "[259]\ttrain-auc:0.86195+0.00305\ttest-auc:0.75780+0.02194\n",
      "[260]\ttrain-auc:0.86225+0.00306\ttest-auc:0.75786+0.02180\n",
      "[261]\ttrain-auc:0.86245+0.00303\ttest-auc:0.75794+0.02181\n",
      "[262]\ttrain-auc:0.86265+0.00302\ttest-auc:0.75808+0.02176\n",
      "[263]\ttrain-auc:0.86288+0.00296\ttest-auc:0.75813+0.02171\n",
      "[264]\ttrain-auc:0.86319+0.00292\ttest-auc:0.75817+0.02167\n",
      "[265]\ttrain-auc:0.86363+0.00293\ttest-auc:0.75831+0.02168\n",
      "[266]\ttrain-auc:0.86393+0.00303\ttest-auc:0.75837+0.02166\n",
      "[267]\ttrain-auc:0.86418+0.00295\ttest-auc:0.75853+0.02180\n",
      "[268]\ttrain-auc:0.86440+0.00303\ttest-auc:0.75858+0.02177\n",
      "[269]\ttrain-auc:0.86455+0.00304\ttest-auc:0.75871+0.02166\n",
      "[270]\ttrain-auc:0.86489+0.00311\ttest-auc:0.75882+0.02173\n",
      "[271]\ttrain-auc:0.86511+0.00315\ttest-auc:0.75891+0.02174\n",
      "[272]\ttrain-auc:0.86538+0.00309\ttest-auc:0.75901+0.02177\n",
      "[273]\ttrain-auc:0.86568+0.00306\ttest-auc:0.75904+0.02176\n",
      "[274]\ttrain-auc:0.86590+0.00299\ttest-auc:0.75902+0.02172\n",
      "[275]\ttrain-auc:0.86612+0.00299\ttest-auc:0.75910+0.02177\n",
      "[276]\ttrain-auc:0.86634+0.00307\ttest-auc:0.75929+0.02180\n",
      "[277]\ttrain-auc:0.86656+0.00303\ttest-auc:0.75945+0.02183\n",
      "[278]\ttrain-auc:0.86684+0.00295\ttest-auc:0.75946+0.02176\n",
      "[279]\ttrain-auc:0.86715+0.00295\ttest-auc:0.75944+0.02179\n",
      "[280]\ttrain-auc:0.86746+0.00302\ttest-auc:0.75964+0.02178\n",
      "[281]\ttrain-auc:0.86790+0.00305\ttest-auc:0.75965+0.02175\n",
      "[282]\ttrain-auc:0.86809+0.00302\ttest-auc:0.75973+0.02174\n",
      "[283]\ttrain-auc:0.86842+0.00308\ttest-auc:0.75980+0.02174\n",
      "[284]\ttrain-auc:0.86865+0.00309\ttest-auc:0.75979+0.02177\n",
      "[285]\ttrain-auc:0.86886+0.00306\ttest-auc:0.75989+0.02188\n",
      "[286]\ttrain-auc:0.86917+0.00310\ttest-auc:0.76002+0.02189\n",
      "[287]\ttrain-auc:0.86946+0.00314\ttest-auc:0.76010+0.02190\n",
      "[288]\ttrain-auc:0.86979+0.00319\ttest-auc:0.76024+0.02187\n",
      "[289]\ttrain-auc:0.87007+0.00312\ttest-auc:0.76036+0.02189\n",
      "[290]\ttrain-auc:0.87022+0.00316\ttest-auc:0.76041+0.02187\n",
      "[291]\ttrain-auc:0.87044+0.00321\ttest-auc:0.76035+0.02187\n",
      "[292]\ttrain-auc:0.87072+0.00316\ttest-auc:0.76037+0.02191\n",
      "[293]\ttrain-auc:0.87093+0.00312\ttest-auc:0.76043+0.02196\n",
      "[294]\ttrain-auc:0.87112+0.00321\ttest-auc:0.76042+0.02196\n",
      "[295]\ttrain-auc:0.87137+0.00327\ttest-auc:0.76052+0.02198\n",
      "[296]\ttrain-auc:0.87165+0.00321\ttest-auc:0.76054+0.02193\n",
      "[297]\ttrain-auc:0.87190+0.00335\ttest-auc:0.76069+0.02190\n",
      "[298]\ttrain-auc:0.87229+0.00350\ttest-auc:0.76083+0.02191\n",
      "[299]\ttrain-auc:0.87249+0.00357\ttest-auc:0.76094+0.02191\n",
      "[300]\ttrain-auc:0.87275+0.00361\ttest-auc:0.76098+0.02196\n",
      "[301]\ttrain-auc:0.87313+0.00357\ttest-auc:0.76116+0.02202\n",
      "[302]\ttrain-auc:0.87341+0.00355\ttest-auc:0.76124+0.02201\n",
      "[303]\ttrain-auc:0.87359+0.00360\ttest-auc:0.76120+0.02198\n",
      "[304]\ttrain-auc:0.87379+0.00351\ttest-auc:0.76128+0.02207\n",
      "[305]\ttrain-auc:0.87399+0.00359\ttest-auc:0.76139+0.02205\n",
      "[306]\ttrain-auc:0.87421+0.00346\ttest-auc:0.76139+0.02198\n",
      "[307]\ttrain-auc:0.87445+0.00347\ttest-auc:0.76152+0.02185\n",
      "[308]\ttrain-auc:0.87479+0.00347\ttest-auc:0.76160+0.02197\n",
      "[309]\ttrain-auc:0.87501+0.00354\ttest-auc:0.76172+0.02193\n",
      "[310]\ttrain-auc:0.87533+0.00343\ttest-auc:0.76186+0.02197\n",
      "[311]\ttrain-auc:0.87557+0.00342\ttest-auc:0.76187+0.02208\n",
      "[312]\ttrain-auc:0.87584+0.00337\ttest-auc:0.76198+0.02195\n",
      "[313]\ttrain-auc:0.87612+0.00334\ttest-auc:0.76200+0.02194\n",
      "[314]\ttrain-auc:0.87646+0.00332\ttest-auc:0.76206+0.02189\n",
      "[315]\ttrain-auc:0.87674+0.00327\ttest-auc:0.76209+0.02186\n",
      "[316]\ttrain-auc:0.87692+0.00325\ttest-auc:0.76205+0.02176\n",
      "[317]\ttrain-auc:0.87711+0.00322\ttest-auc:0.76224+0.02184\n",
      "[318]\ttrain-auc:0.87731+0.00321\ttest-auc:0.76228+0.02187\n",
      "[319]\ttrain-auc:0.87753+0.00324\ttest-auc:0.76243+0.02199\n",
      "[320]\ttrain-auc:0.87780+0.00328\ttest-auc:0.76262+0.02211\n",
      "[321]\ttrain-auc:0.87814+0.00317\ttest-auc:0.76275+0.02209\n",
      "[322]\ttrain-auc:0.87840+0.00312\ttest-auc:0.76282+0.02224\n",
      "[323]\ttrain-auc:0.87872+0.00312\ttest-auc:0.76284+0.02228\n",
      "[324]\ttrain-auc:0.87894+0.00299\ttest-auc:0.76290+0.02233\n",
      "[325]\ttrain-auc:0.87913+0.00298\ttest-auc:0.76290+0.02226\n",
      "[326]\ttrain-auc:0.87929+0.00298\ttest-auc:0.76295+0.02229\n",
      "[327]\ttrain-auc:0.87942+0.00301\ttest-auc:0.76291+0.02226\n",
      "[328]\ttrain-auc:0.87963+0.00297\ttest-auc:0.76293+0.02223\n",
      "[329]\ttrain-auc:0.87992+0.00289\ttest-auc:0.76298+0.02215\n",
      "[330]\ttrain-auc:0.88016+0.00291\ttest-auc:0.76294+0.02215\n",
      "[331]\ttrain-auc:0.88034+0.00292\ttest-auc:0.76306+0.02205\n",
      "[332]\ttrain-auc:0.88048+0.00295\ttest-auc:0.76306+0.02196\n",
      "[333]\ttrain-auc:0.88079+0.00288\ttest-auc:0.76317+0.02191\n",
      "[334]\ttrain-auc:0.88104+0.00298\ttest-auc:0.76329+0.02184\n",
      "[335]\ttrain-auc:0.88128+0.00299\ttest-auc:0.76325+0.02180\n",
      "[336]\ttrain-auc:0.88154+0.00299\ttest-auc:0.76338+0.02175\n",
      "[337]\ttrain-auc:0.88194+0.00295\ttest-auc:0.76369+0.02173\n",
      "[338]\ttrain-auc:0.88212+0.00302\ttest-auc:0.76371+0.02173\n",
      "[339]\ttrain-auc:0.88228+0.00305\ttest-auc:0.76375+0.02173\n",
      "[340]\ttrain-auc:0.88257+0.00305\ttest-auc:0.76381+0.02166\n",
      "[341]\ttrain-auc:0.88272+0.00305\ttest-auc:0.76388+0.02166\n",
      "[342]\ttrain-auc:0.88300+0.00300\ttest-auc:0.76392+0.02159\n",
      "[343]\ttrain-auc:0.88326+0.00309\ttest-auc:0.76406+0.02151\n",
      "[344]\ttrain-auc:0.88343+0.00313\ttest-auc:0.76405+0.02153\n",
      "[345]\ttrain-auc:0.88362+0.00314\ttest-auc:0.76417+0.02158\n",
      "[346]\ttrain-auc:0.88384+0.00311\ttest-auc:0.76430+0.02154\n",
      "[347]\ttrain-auc:0.88412+0.00319\ttest-auc:0.76427+0.02162\n",
      "[348]\ttrain-auc:0.88434+0.00322\ttest-auc:0.76425+0.02161\n",
      "[349]\ttrain-auc:0.88457+0.00325\ttest-auc:0.76420+0.02151\n",
      "[350]\ttrain-auc:0.88483+0.00331\ttest-auc:0.76419+0.02147\n",
      "[351]\ttrain-auc:0.88500+0.00326\ttest-auc:0.76422+0.02145\n",
      "[352]\ttrain-auc:0.88524+0.00329\ttest-auc:0.76429+0.02145\n",
      "[353]\ttrain-auc:0.88542+0.00327\ttest-auc:0.76441+0.02156\n",
      "[354]\ttrain-auc:0.88560+0.00323\ttest-auc:0.76454+0.02159\n",
      "[355]\ttrain-auc:0.88574+0.00323\ttest-auc:0.76452+0.02152\n",
      "[356]\ttrain-auc:0.88593+0.00329\ttest-auc:0.76456+0.02151\n",
      "[357]\ttrain-auc:0.88618+0.00328\ttest-auc:0.76457+0.02162\n",
      "[358]\ttrain-auc:0.88634+0.00326\ttest-auc:0.76463+0.02165\n",
      "[359]\ttrain-auc:0.88659+0.00330\ttest-auc:0.76471+0.02166\n",
      "[360]\ttrain-auc:0.88690+0.00322\ttest-auc:0.76476+0.02165\n",
      "[361]\ttrain-auc:0.88710+0.00318\ttest-auc:0.76477+0.02163\n",
      "[362]\ttrain-auc:0.88733+0.00322\ttest-auc:0.76479+0.02164\n",
      "[363]\ttrain-auc:0.88758+0.00317\ttest-auc:0.76483+0.02167\n",
      "[364]\ttrain-auc:0.88780+0.00318\ttest-auc:0.76482+0.02181\n",
      "[365]\ttrain-auc:0.88791+0.00321\ttest-auc:0.76483+0.02176\n",
      "[366]\ttrain-auc:0.88815+0.00321\ttest-auc:0.76480+0.02171\n",
      "[367]\ttrain-auc:0.88835+0.00326\ttest-auc:0.76482+0.02170\n",
      "[368]\ttrain-auc:0.88854+0.00325\ttest-auc:0.76486+0.02171\n",
      "[369]\ttrain-auc:0.88881+0.00331\ttest-auc:0.76488+0.02170\n",
      "[370]\ttrain-auc:0.88901+0.00322\ttest-auc:0.76489+0.02173\n",
      "[371]\ttrain-auc:0.88922+0.00319\ttest-auc:0.76501+0.02178\n",
      "[372]\ttrain-auc:0.88940+0.00315\ttest-auc:0.76509+0.02177\n",
      "[373]\ttrain-auc:0.88954+0.00313\ttest-auc:0.76508+0.02180\n",
      "[374]\ttrain-auc:0.88969+0.00315\ttest-auc:0.76517+0.02182\n",
      "[375]\ttrain-auc:0.88981+0.00317\ttest-auc:0.76514+0.02182\n",
      "[376]\ttrain-auc:0.89000+0.00321\ttest-auc:0.76512+0.02173\n",
      "[377]\ttrain-auc:0.89016+0.00319\ttest-auc:0.76506+0.02174\n",
      "[378]\ttrain-auc:0.89031+0.00315\ttest-auc:0.76507+0.02170\n",
      "[379]\ttrain-auc:0.89044+0.00315\ttest-auc:0.76510+0.02176\n",
      "[380]\ttrain-auc:0.89067+0.00313\ttest-auc:0.76519+0.02172\n",
      "[381]\ttrain-auc:0.89090+0.00305\ttest-auc:0.76520+0.02182\n",
      "[382]\ttrain-auc:0.89109+0.00306\ttest-auc:0.76531+0.02175\n",
      "[383]\ttrain-auc:0.89130+0.00304\ttest-auc:0.76545+0.02172\n",
      "[384]\ttrain-auc:0.89149+0.00301\ttest-auc:0.76556+0.02177\n",
      "[385]\ttrain-auc:0.89168+0.00301\ttest-auc:0.76564+0.02171\n",
      "[386]\ttrain-auc:0.89191+0.00302\ttest-auc:0.76579+0.02168\n",
      "[387]\ttrain-auc:0.89213+0.00306\ttest-auc:0.76591+0.02176\n",
      "[388]\ttrain-auc:0.89226+0.00306\ttest-auc:0.76592+0.02178\n",
      "[389]\ttrain-auc:0.89253+0.00313\ttest-auc:0.76590+0.02170\n",
      "[390]\ttrain-auc:0.89273+0.00307\ttest-auc:0.76599+0.02167\n",
      "[391]\ttrain-auc:0.89291+0.00312\ttest-auc:0.76604+0.02159\n",
      "[392]\ttrain-auc:0.89313+0.00305\ttest-auc:0.76606+0.02162\n",
      "[393]\ttrain-auc:0.89329+0.00309\ttest-auc:0.76606+0.02157\n",
      "[394]\ttrain-auc:0.89343+0.00313\ttest-auc:0.76613+0.02161\n",
      "[395]\ttrain-auc:0.89365+0.00305\ttest-auc:0.76611+0.02164\n",
      "[396]\ttrain-auc:0.89380+0.00305\ttest-auc:0.76617+0.02155\n",
      "[397]\ttrain-auc:0.89401+0.00305\ttest-auc:0.76624+0.02143\n",
      "[398]\ttrain-auc:0.89418+0.00306\ttest-auc:0.76635+0.02148\n",
      "[399]\ttrain-auc:0.89438+0.00295\ttest-auc:0.76636+0.02145\n",
      "[400]\ttrain-auc:0.89464+0.00296\ttest-auc:0.76642+0.02148\n",
      "[401]\ttrain-auc:0.89483+0.00295\ttest-auc:0.76638+0.02155\n",
      "[402]\ttrain-auc:0.89510+0.00287\ttest-auc:0.76656+0.02154\n",
      "[403]\ttrain-auc:0.89525+0.00286\ttest-auc:0.76668+0.02152\n",
      "[404]\ttrain-auc:0.89545+0.00288\ttest-auc:0.76666+0.02142\n",
      "[405]\ttrain-auc:0.89567+0.00288\ttest-auc:0.76675+0.02137\n",
      "[406]\ttrain-auc:0.89583+0.00286\ttest-auc:0.76684+0.02135\n",
      "[407]\ttrain-auc:0.89607+0.00289\ttest-auc:0.76682+0.02135\n",
      "[408]\ttrain-auc:0.89623+0.00284\ttest-auc:0.76685+0.02130\n",
      "[409]\ttrain-auc:0.89642+0.00290\ttest-auc:0.76689+0.02134\n",
      "[410]\ttrain-auc:0.89665+0.00283\ttest-auc:0.76691+0.02132\n",
      "[411]\ttrain-auc:0.89687+0.00290\ttest-auc:0.76696+0.02126\n",
      "[412]\ttrain-auc:0.89707+0.00293\ttest-auc:0.76704+0.02126\n",
      "[413]\ttrain-auc:0.89727+0.00290\ttest-auc:0.76703+0.02129\n",
      "[414]\ttrain-auc:0.89746+0.00290\ttest-auc:0.76713+0.02120\n",
      "[415]\ttrain-auc:0.89764+0.00282\ttest-auc:0.76723+0.02119\n",
      "[416]\ttrain-auc:0.89778+0.00282\ttest-auc:0.76726+0.02118\n",
      "[417]\ttrain-auc:0.89799+0.00283\ttest-auc:0.76735+0.02120\n",
      "[418]\ttrain-auc:0.89810+0.00286\ttest-auc:0.76742+0.02116\n",
      "[419]\ttrain-auc:0.89828+0.00286\ttest-auc:0.76743+0.02110\n",
      "[420]\ttrain-auc:0.89852+0.00282\ttest-auc:0.76752+0.02120\n",
      "[421]\ttrain-auc:0.89880+0.00280\ttest-auc:0.76751+0.02126\n",
      "[422]\ttrain-auc:0.89898+0.00276\ttest-auc:0.76759+0.02130\n",
      "[423]\ttrain-auc:0.89919+0.00273\ttest-auc:0.76767+0.02134\n",
      "[424]\ttrain-auc:0.89938+0.00276\ttest-auc:0.76781+0.02130\n",
      "[425]\ttrain-auc:0.89961+0.00276\ttest-auc:0.76799+0.02128\n",
      "[426]\ttrain-auc:0.89975+0.00271\ttest-auc:0.76799+0.02125\n",
      "[427]\ttrain-auc:0.89994+0.00274\ttest-auc:0.76803+0.02121\n",
      "[428]\ttrain-auc:0.90014+0.00273\ttest-auc:0.76809+0.02118\n",
      "[429]\ttrain-auc:0.90029+0.00271\ttest-auc:0.76815+0.02114\n",
      "[430]\ttrain-auc:0.90048+0.00269\ttest-auc:0.76821+0.02115\n",
      "[431]\ttrain-auc:0.90066+0.00276\ttest-auc:0.76820+0.02118\n",
      "[432]\ttrain-auc:0.90087+0.00280\ttest-auc:0.76823+0.02111\n",
      "[433]\ttrain-auc:0.90097+0.00279\ttest-auc:0.76821+0.02120\n",
      "[434]\ttrain-auc:0.90110+0.00277\ttest-auc:0.76823+0.02127\n",
      "[435]\ttrain-auc:0.90127+0.00276\ttest-auc:0.76831+0.02126\n",
      "[436]\ttrain-auc:0.90147+0.00271\ttest-auc:0.76845+0.02116\n",
      "[437]\ttrain-auc:0.90164+0.00274\ttest-auc:0.76852+0.02113\n",
      "[438]\ttrain-auc:0.90191+0.00271\ttest-auc:0.76860+0.02108\n",
      "[439]\ttrain-auc:0.90206+0.00270\ttest-auc:0.76863+0.02113\n",
      "[440]\ttrain-auc:0.90217+0.00267\ttest-auc:0.76864+0.02115\n",
      "[441]\ttrain-auc:0.90235+0.00256\ttest-auc:0.76868+0.02112\n",
      "[442]\ttrain-auc:0.90253+0.00257\ttest-auc:0.76874+0.02105\n",
      "[443]\ttrain-auc:0.90272+0.00247\ttest-auc:0.76878+0.02098\n",
      "[444]\ttrain-auc:0.90292+0.00251\ttest-auc:0.76886+0.02089\n",
      "[445]\ttrain-auc:0.90304+0.00253\ttest-auc:0.76885+0.02097\n",
      "[446]\ttrain-auc:0.90328+0.00255\ttest-auc:0.76888+0.02096\n",
      "[447]\ttrain-auc:0.90343+0.00253\ttest-auc:0.76896+0.02095\n",
      "[448]\ttrain-auc:0.90363+0.00247\ttest-auc:0.76900+0.02097\n",
      "[449]\ttrain-auc:0.90379+0.00247\ttest-auc:0.76898+0.02093\n",
      "[450]\ttrain-auc:0.90393+0.00252\ttest-auc:0.76908+0.02091\n",
      "[451]\ttrain-auc:0.90407+0.00252\ttest-auc:0.76911+0.02077\n",
      "[452]\ttrain-auc:0.90419+0.00257\ttest-auc:0.76920+0.02064\n",
      "[453]\ttrain-auc:0.90430+0.00255\ttest-auc:0.76928+0.02065\n",
      "[454]\ttrain-auc:0.90443+0.00255\ttest-auc:0.76931+0.02073\n",
      "[455]\ttrain-auc:0.90460+0.00261\ttest-auc:0.76935+0.02075\n",
      "[456]\ttrain-auc:0.90471+0.00261\ttest-auc:0.76936+0.02073\n",
      "[457]\ttrain-auc:0.90491+0.00268\ttest-auc:0.76938+0.02070\n",
      "[458]\ttrain-auc:0.90510+0.00272\ttest-auc:0.76945+0.02064\n",
      "[459]\ttrain-auc:0.90522+0.00272\ttest-auc:0.76948+0.02057\n",
      "[460]\ttrain-auc:0.90532+0.00272\ttest-auc:0.76960+0.02063\n",
      "[461]\ttrain-auc:0.90543+0.00276\ttest-auc:0.76958+0.02065\n",
      "[462]\ttrain-auc:0.90552+0.00274\ttest-auc:0.76962+0.02060\n",
      "[463]\ttrain-auc:0.90568+0.00281\ttest-auc:0.76962+0.02059\n",
      "[464]\ttrain-auc:0.90578+0.00283\ttest-auc:0.76961+0.02059\n",
      "[465]\ttrain-auc:0.90594+0.00283\ttest-auc:0.76967+0.02058\n",
      "[466]\ttrain-auc:0.90610+0.00282\ttest-auc:0.76968+0.02061\n",
      "[467]\ttrain-auc:0.90629+0.00288\ttest-auc:0.76963+0.02063\n",
      "[468]\ttrain-auc:0.90647+0.00288\ttest-auc:0.76961+0.02066\n",
      "[469]\ttrain-auc:0.90673+0.00302\ttest-auc:0.76966+0.02062\n",
      "[470]\ttrain-auc:0.90688+0.00304\ttest-auc:0.76968+0.02066\n",
      "[471]\ttrain-auc:0.90703+0.00308\ttest-auc:0.76970+0.02066\n",
      "[472]\ttrain-auc:0.90716+0.00306\ttest-auc:0.76975+0.02068\n",
      "[473]\ttrain-auc:0.90734+0.00312\ttest-auc:0.76970+0.02065\n",
      "[474]\ttrain-auc:0.90746+0.00313\ttest-auc:0.76982+0.02059\n",
      "[475]\ttrain-auc:0.90759+0.00308\ttest-auc:0.76984+0.02057\n",
      "[476]\ttrain-auc:0.90777+0.00306\ttest-auc:0.76999+0.02062\n",
      "[477]\ttrain-auc:0.90789+0.00313\ttest-auc:0.76997+0.02063\n",
      "[478]\ttrain-auc:0.90800+0.00315\ttest-auc:0.76994+0.02062\n",
      "[479]\ttrain-auc:0.90815+0.00316\ttest-auc:0.76999+0.02061\n",
      "[480]\ttrain-auc:0.90827+0.00319\ttest-auc:0.76998+0.02062\n",
      "[481]\ttrain-auc:0.90835+0.00321\ttest-auc:0.76999+0.02063\n",
      "[482]\ttrain-auc:0.90846+0.00318\ttest-auc:0.76997+0.02067\n",
      "[483]\ttrain-auc:0.90855+0.00320\ttest-auc:0.77005+0.02070\n",
      "[484]\ttrain-auc:0.90869+0.00323\ttest-auc:0.77005+0.02076\n",
      "[485]\ttrain-auc:0.90883+0.00318\ttest-auc:0.77004+0.02072\n",
      "[486]\ttrain-auc:0.90901+0.00318\ttest-auc:0.77015+0.02071\n",
      "[487]\ttrain-auc:0.90910+0.00319\ttest-auc:0.77020+0.02065\n",
      "[488]\ttrain-auc:0.90921+0.00314\ttest-auc:0.77024+0.02061\n",
      "[489]\ttrain-auc:0.90933+0.00312\ttest-auc:0.77032+0.02057\n",
      "[490]\ttrain-auc:0.90943+0.00315\ttest-auc:0.77036+0.02056\n",
      "[491]\ttrain-auc:0.90956+0.00317\ttest-auc:0.77034+0.02057\n",
      "[492]\ttrain-auc:0.90970+0.00317\ttest-auc:0.77035+0.02051\n",
      "[493]\ttrain-auc:0.90986+0.00318\ttest-auc:0.77043+0.02045\n",
      "[494]\ttrain-auc:0.90998+0.00313\ttest-auc:0.77051+0.02044\n",
      "[495]\ttrain-auc:0.91015+0.00314\ttest-auc:0.77053+0.02056\n",
      "[496]\ttrain-auc:0.91024+0.00313\ttest-auc:0.77053+0.02058\n",
      "[497]\ttrain-auc:0.91040+0.00311\ttest-auc:0.77058+0.02057\n",
      "[498]\ttrain-auc:0.91052+0.00309\ttest-auc:0.77058+0.02057\n",
      "[499]\ttrain-auc:0.91065+0.00313\ttest-auc:0.77057+0.02059\n",
      "[500]\ttrain-auc:0.91082+0.00313\ttest-auc:0.77064+0.02062\n",
      "[501]\ttrain-auc:0.91097+0.00306\ttest-auc:0.77064+0.02058\n",
      "[502]\ttrain-auc:0.91120+0.00297\ttest-auc:0.77068+0.02059\n",
      "[503]\ttrain-auc:0.91137+0.00294\ttest-auc:0.77076+0.02056\n",
      "[504]\ttrain-auc:0.91145+0.00291\ttest-auc:0.77078+0.02053\n",
      "[505]\ttrain-auc:0.91157+0.00289\ttest-auc:0.77078+0.02052\n",
      "[506]\ttrain-auc:0.91175+0.00283\ttest-auc:0.77081+0.02050\n",
      "[507]\ttrain-auc:0.91191+0.00283\ttest-auc:0.77092+0.02050\n",
      "[508]\ttrain-auc:0.91204+0.00277\ttest-auc:0.77095+0.02055\n",
      "[509]\ttrain-auc:0.91217+0.00281\ttest-auc:0.77097+0.02059\n",
      "[510]\ttrain-auc:0.91234+0.00277\ttest-auc:0.77102+0.02065\n",
      "[511]\ttrain-auc:0.91251+0.00277\ttest-auc:0.77113+0.02071\n",
      "[512]\ttrain-auc:0.91264+0.00282\ttest-auc:0.77108+0.02071\n",
      "[513]\ttrain-auc:0.91279+0.00278\ttest-auc:0.77115+0.02071\n",
      "[514]\ttrain-auc:0.91303+0.00291\ttest-auc:0.77122+0.02066\n",
      "[515]\ttrain-auc:0.91316+0.00293\ttest-auc:0.77122+0.02062\n",
      "[516]\ttrain-auc:0.91338+0.00286\ttest-auc:0.77124+0.02060\n",
      "[517]\ttrain-auc:0.91357+0.00293\ttest-auc:0.77123+0.02061\n",
      "[518]\ttrain-auc:0.91369+0.00294\ttest-auc:0.77119+0.02067\n",
      "[519]\ttrain-auc:0.91381+0.00289\ttest-auc:0.77124+0.02072\n",
      "[520]\ttrain-auc:0.91389+0.00291\ttest-auc:0.77121+0.02081\n",
      "[521]\ttrain-auc:0.91397+0.00295\ttest-auc:0.77120+0.02083\n",
      "[522]\ttrain-auc:0.91414+0.00292\ttest-auc:0.77124+0.02081\n",
      "[523]\ttrain-auc:0.91430+0.00290\ttest-auc:0.77126+0.02076\n",
      "[524]\ttrain-auc:0.91449+0.00293\ttest-auc:0.77133+0.02075\n",
      "[525]\ttrain-auc:0.91462+0.00293\ttest-auc:0.77132+0.02075\n",
      "[526]\ttrain-auc:0.91472+0.00292\ttest-auc:0.77127+0.02077\n",
      "[527]\ttrain-auc:0.91488+0.00289\ttest-auc:0.77124+0.02080\n",
      "[528]\ttrain-auc:0.91497+0.00288\ttest-auc:0.77129+0.02077\n",
      "[529]\ttrain-auc:0.91510+0.00287\ttest-auc:0.77131+0.02077\n",
      "[530]\ttrain-auc:0.91534+0.00293\ttest-auc:0.77138+0.02073\n",
      "[531]\ttrain-auc:0.91546+0.00297\ttest-auc:0.77140+0.02074\n",
      "[532]\ttrain-auc:0.91560+0.00304\ttest-auc:0.77145+0.02068\n",
      "[533]\ttrain-auc:0.91571+0.00309\ttest-auc:0.77151+0.02070\n",
      "[534]\ttrain-auc:0.91583+0.00315\ttest-auc:0.77150+0.02069\n",
      "[535]\ttrain-auc:0.91588+0.00315\ttest-auc:0.77154+0.02071\n",
      "[536]\ttrain-auc:0.91601+0.00319\ttest-auc:0.77154+0.02071\n",
      "[537]\ttrain-auc:0.91611+0.00319\ttest-auc:0.77154+0.02067\n",
      "[538]\ttrain-auc:0.91624+0.00313\ttest-auc:0.77142+0.02063\n",
      "[539]\ttrain-auc:0.91642+0.00313\ttest-auc:0.77142+0.02074\n",
      "[540]\ttrain-auc:0.91656+0.00311\ttest-auc:0.77146+0.02069\n",
      "[541]\ttrain-auc:0.91674+0.00313\ttest-auc:0.77143+0.02072\n",
      "[542]\ttrain-auc:0.91686+0.00316\ttest-auc:0.77149+0.02065\n",
      "[543]\ttrain-auc:0.91701+0.00313\ttest-auc:0.77150+0.02068\n",
      "[544]\ttrain-auc:0.91711+0.00310\ttest-auc:0.77146+0.02072\n",
      "[545]\ttrain-auc:0.91723+0.00312\ttest-auc:0.77144+0.02075\n",
      "[546]\ttrain-auc:0.91731+0.00309\ttest-auc:0.77147+0.02079\n",
      "[547]\ttrain-auc:0.91741+0.00307\ttest-auc:0.77154+0.02076\n",
      "[548]\ttrain-auc:0.91752+0.00305\ttest-auc:0.77155+0.02068\n",
      "[549]\ttrain-auc:0.91773+0.00301\ttest-auc:0.77160+0.02063\n",
      "[550]\ttrain-auc:0.91779+0.00298\ttest-auc:0.77168+0.02060\n",
      "[551]\ttrain-auc:0.91796+0.00302\ttest-auc:0.77183+0.02052\n",
      "[552]\ttrain-auc:0.91808+0.00301\ttest-auc:0.77183+0.02049\n",
      "[553]\ttrain-auc:0.91821+0.00301\ttest-auc:0.77193+0.02052\n",
      "[554]\ttrain-auc:0.91837+0.00295\ttest-auc:0.77193+0.02053\n",
      "[555]\ttrain-auc:0.91856+0.00291\ttest-auc:0.77194+0.02047\n",
      "[556]\ttrain-auc:0.91863+0.00295\ttest-auc:0.77188+0.02051\n",
      "[557]\ttrain-auc:0.91873+0.00294\ttest-auc:0.77183+0.02048\n",
      "[558]\ttrain-auc:0.91886+0.00297\ttest-auc:0.77185+0.02043\n",
      "[559]\ttrain-auc:0.91894+0.00299\ttest-auc:0.77176+0.02038\n",
      "[560]\ttrain-auc:0.91910+0.00299\ttest-auc:0.77182+0.02036\n",
      "[561]\ttrain-auc:0.91918+0.00299\ttest-auc:0.77181+0.02037\n",
      "[562]\ttrain-auc:0.91929+0.00296\ttest-auc:0.77179+0.02026\n",
      "[563]\ttrain-auc:0.91940+0.00293\ttest-auc:0.77186+0.02019\n",
      "[564]\ttrain-auc:0.91952+0.00291\ttest-auc:0.77203+0.02008\n",
      "[565]\ttrain-auc:0.91961+0.00291\ttest-auc:0.77204+0.02014\n",
      "[566]\ttrain-auc:0.91977+0.00284\ttest-auc:0.77202+0.02019\n",
      "[567]\ttrain-auc:0.91991+0.00278\ttest-auc:0.77203+0.02016\n",
      "[568]\ttrain-auc:0.92000+0.00274\ttest-auc:0.77210+0.02020\n",
      "[569]\ttrain-auc:0.92010+0.00268\ttest-auc:0.77208+0.02019\n",
      "[570]\ttrain-auc:0.92027+0.00272\ttest-auc:0.77203+0.02014\n",
      "[571]\ttrain-auc:0.92035+0.00271\ttest-auc:0.77201+0.02010\n",
      "[572]\ttrain-auc:0.92041+0.00273\ttest-auc:0.77200+0.02011\n",
      "[573]\ttrain-auc:0.92058+0.00282\ttest-auc:0.77207+0.02003\n",
      "[574]\ttrain-auc:0.92071+0.00274\ttest-auc:0.77210+0.02006\n",
      "[575]\ttrain-auc:0.92080+0.00277\ttest-auc:0.77204+0.01998\n",
      "[576]\ttrain-auc:0.92086+0.00280\ttest-auc:0.77204+0.01999\n",
      "[577]\ttrain-auc:0.92100+0.00278\ttest-auc:0.77207+0.01994\n",
      "[578]\ttrain-auc:0.92107+0.00273\ttest-auc:0.77207+0.01994\n",
      "[579]\ttrain-auc:0.92118+0.00270\ttest-auc:0.77200+0.02002\n",
      "[580]\ttrain-auc:0.92133+0.00266\ttest-auc:0.77210+0.02005\n",
      "[581]\ttrain-auc:0.92146+0.00269\ttest-auc:0.77212+0.02004\n",
      "[582]\ttrain-auc:0.92155+0.00271\ttest-auc:0.77213+0.02003\n",
      "[583]\ttrain-auc:0.92172+0.00265\ttest-auc:0.77222+0.02005\n",
      "[584]\ttrain-auc:0.92186+0.00265\ttest-auc:0.77227+0.02010\n",
      "[585]\ttrain-auc:0.92193+0.00264\ttest-auc:0.77225+0.02004\n",
      "[586]\ttrain-auc:0.92200+0.00263\ttest-auc:0.77223+0.02001\n",
      "[587]\ttrain-auc:0.92214+0.00262\ttest-auc:0.77221+0.02009\n",
      "[588]\ttrain-auc:0.92224+0.00260\ttest-auc:0.77221+0.02015\n",
      "[589]\ttrain-auc:0.92234+0.00263\ttest-auc:0.77220+0.02011\n",
      "[590]\ttrain-auc:0.92247+0.00266\ttest-auc:0.77227+0.02011\n",
      "[591]\ttrain-auc:0.92256+0.00267\ttest-auc:0.77220+0.02014\n",
      "[592]\ttrain-auc:0.92268+0.00266\ttest-auc:0.77221+0.02007\n",
      "[593]\ttrain-auc:0.92275+0.00268\ttest-auc:0.77222+0.02005\n",
      "[594]\ttrain-auc:0.92288+0.00274\ttest-auc:0.77228+0.02002\n",
      "[595]\ttrain-auc:0.92299+0.00272\ttest-auc:0.77230+0.02007\n",
      "[596]\ttrain-auc:0.92309+0.00272\ttest-auc:0.77231+0.02007\n",
      "[597]\ttrain-auc:0.92319+0.00273\ttest-auc:0.77232+0.02008\n",
      "[598]\ttrain-auc:0.92327+0.00272\ttest-auc:0.77235+0.02011\n",
      "[599]\ttrain-auc:0.92335+0.00276\ttest-auc:0.77231+0.02012\n",
      "[600]\ttrain-auc:0.92347+0.00273\ttest-auc:0.77238+0.02011\n",
      "[601]\ttrain-auc:0.92355+0.00278\ttest-auc:0.77239+0.02010\n",
      "[602]\ttrain-auc:0.92373+0.00283\ttest-auc:0.77243+0.02010\n",
      "[603]\ttrain-auc:0.92381+0.00283\ttest-auc:0.77250+0.02010\n",
      "[604]\ttrain-auc:0.92391+0.00285\ttest-auc:0.77249+0.02010\n",
      "[605]\ttrain-auc:0.92407+0.00288\ttest-auc:0.77254+0.02001\n",
      "[606]\ttrain-auc:0.92416+0.00284\ttest-auc:0.77253+0.02005\n",
      "[607]\ttrain-auc:0.92431+0.00280\ttest-auc:0.77262+0.02004\n",
      "[608]\ttrain-auc:0.92444+0.00279\ttest-auc:0.77267+0.02000\n",
      "[609]\ttrain-auc:0.92453+0.00277\ttest-auc:0.77268+0.02001\n",
      "[610]\ttrain-auc:0.92465+0.00272\ttest-auc:0.77271+0.02003\n",
      "[611]\ttrain-auc:0.92481+0.00272\ttest-auc:0.77275+0.02006\n",
      "[612]\ttrain-auc:0.92493+0.00272\ttest-auc:0.77272+0.02008\n",
      "[613]\ttrain-auc:0.92506+0.00273\ttest-auc:0.77281+0.02004\n",
      "[614]\ttrain-auc:0.92516+0.00276\ttest-auc:0.77285+0.02005\n",
      "[615]\ttrain-auc:0.92526+0.00276\ttest-auc:0.77288+0.02003\n",
      "[616]\ttrain-auc:0.92533+0.00274\ttest-auc:0.77285+0.01999\n",
      "[617]\ttrain-auc:0.92547+0.00264\ttest-auc:0.77295+0.02006\n",
      "[618]\ttrain-auc:0.92560+0.00267\ttest-auc:0.77303+0.02006\n",
      "[619]\ttrain-auc:0.92569+0.00271\ttest-auc:0.77306+0.02004\n",
      "[620]\ttrain-auc:0.92579+0.00278\ttest-auc:0.77301+0.02006\n",
      "[621]\ttrain-auc:0.92587+0.00278\ttest-auc:0.77305+0.02001\n",
      "[622]\ttrain-auc:0.92600+0.00275\ttest-auc:0.77306+0.01997\n",
      "[623]\ttrain-auc:0.92607+0.00273\ttest-auc:0.77303+0.01998\n",
      "[624]\ttrain-auc:0.92616+0.00272\ttest-auc:0.77296+0.01995\n",
      "[625]\ttrain-auc:0.92633+0.00273\ttest-auc:0.77303+0.02001\n",
      "[626]\ttrain-auc:0.92646+0.00274\ttest-auc:0.77308+0.02004\n",
      "[627]\ttrain-auc:0.92660+0.00275\ttest-auc:0.77313+0.02003\n",
      "[628]\ttrain-auc:0.92675+0.00271\ttest-auc:0.77316+0.01999\n",
      "[629]\ttrain-auc:0.92688+0.00268\ttest-auc:0.77322+0.01992\n",
      "[630]\ttrain-auc:0.92696+0.00270\ttest-auc:0.77325+0.01996\n",
      "[631]\ttrain-auc:0.92707+0.00268\ttest-auc:0.77332+0.01996\n",
      "[632]\ttrain-auc:0.92718+0.00273\ttest-auc:0.77336+0.01995\n",
      "[633]\ttrain-auc:0.92724+0.00272\ttest-auc:0.77340+0.01992\n",
      "[634]\ttrain-auc:0.92735+0.00276\ttest-auc:0.77337+0.01987\n",
      "[635]\ttrain-auc:0.92743+0.00276\ttest-auc:0.77343+0.01988\n",
      "[636]\ttrain-auc:0.92752+0.00280\ttest-auc:0.77343+0.01982\n",
      "[637]\ttrain-auc:0.92761+0.00284\ttest-auc:0.77344+0.01974\n",
      "[638]\ttrain-auc:0.92777+0.00288\ttest-auc:0.77342+0.01975\n",
      "[639]\ttrain-auc:0.92789+0.00292\ttest-auc:0.77339+0.01976\n",
      "[640]\ttrain-auc:0.92797+0.00288\ttest-auc:0.77344+0.01981\n",
      "[641]\ttrain-auc:0.92808+0.00288\ttest-auc:0.77349+0.01976\n",
      "[642]\ttrain-auc:0.92823+0.00289\ttest-auc:0.77352+0.01980\n",
      "[643]\ttrain-auc:0.92829+0.00289\ttest-auc:0.77351+0.01984\n",
      "[644]\ttrain-auc:0.92836+0.00288\ttest-auc:0.77349+0.01988\n",
      "[645]\ttrain-auc:0.92844+0.00290\ttest-auc:0.77350+0.01985\n",
      "[646]\ttrain-auc:0.92851+0.00294\ttest-auc:0.77351+0.01986\n",
      "[647]\ttrain-auc:0.92865+0.00294\ttest-auc:0.77359+0.01982\n",
      "[648]\ttrain-auc:0.92871+0.00291\ttest-auc:0.77358+0.01982\n",
      "[649]\ttrain-auc:0.92883+0.00288\ttest-auc:0.77354+0.01977\n",
      "[650]\ttrain-auc:0.92893+0.00286\ttest-auc:0.77353+0.01979\n",
      "[651]\ttrain-auc:0.92905+0.00283\ttest-auc:0.77351+0.01981\n",
      "[652]\ttrain-auc:0.92919+0.00276\ttest-auc:0.77351+0.01976\n",
      "[653]\ttrain-auc:0.92927+0.00282\ttest-auc:0.77347+0.01975\n",
      "[654]\ttrain-auc:0.92940+0.00277\ttest-auc:0.77358+0.01979\n",
      "[655]\ttrain-auc:0.92947+0.00276\ttest-auc:0.77362+0.01981\n",
      "[656]\ttrain-auc:0.92956+0.00276\ttest-auc:0.77363+0.01980\n",
      "[657]\ttrain-auc:0.92975+0.00269\ttest-auc:0.77370+0.01985\n",
      "[658]\ttrain-auc:0.92985+0.00272\ttest-auc:0.77375+0.01978\n",
      "[659]\ttrain-auc:0.92995+0.00270\ttest-auc:0.77370+0.01978\n",
      "[660]\ttrain-auc:0.93001+0.00270\ttest-auc:0.77370+0.01980\n",
      "[661]\ttrain-auc:0.93010+0.00272\ttest-auc:0.77375+0.01977\n",
      "[662]\ttrain-auc:0.93019+0.00268\ttest-auc:0.77378+0.01977\n",
      "[663]\ttrain-auc:0.93033+0.00268\ttest-auc:0.77378+0.01973\n",
      "[664]\ttrain-auc:0.93041+0.00267\ttest-auc:0.77372+0.01975\n",
      "[665]\ttrain-auc:0.93048+0.00268\ttest-auc:0.77369+0.01974\n",
      "[666]\ttrain-auc:0.93057+0.00272\ttest-auc:0.77375+0.01964\n",
      "[667]\ttrain-auc:0.93067+0.00271\ttest-auc:0.77376+0.01963\n",
      "[668]\ttrain-auc:0.93076+0.00269\ttest-auc:0.77376+0.01961\n",
      "[669]\ttrain-auc:0.93086+0.00268\ttest-auc:0.77380+0.01963\n",
      "[670]\ttrain-auc:0.93099+0.00268\ttest-auc:0.77379+0.01966\n",
      "[671]\ttrain-auc:0.93111+0.00270\ttest-auc:0.77382+0.01970\n",
      "[672]\ttrain-auc:0.93117+0.00271\ttest-auc:0.77373+0.01968\n",
      "[673]\ttrain-auc:0.93127+0.00270\ttest-auc:0.77374+0.01969\n",
      "[674]\ttrain-auc:0.93132+0.00271\ttest-auc:0.77372+0.01961\n",
      "[675]\ttrain-auc:0.93135+0.00270\ttest-auc:0.77373+0.01959\n",
      "[676]\ttrain-auc:0.93147+0.00264\ttest-auc:0.77375+0.01955\n",
      "[677]\ttrain-auc:0.93160+0.00266\ttest-auc:0.77379+0.01957\n",
      "[678]\ttrain-auc:0.93165+0.00265\ttest-auc:0.77383+0.01958\n",
      "[679]\ttrain-auc:0.93175+0.00266\ttest-auc:0.77389+0.01955\n",
      "[680]\ttrain-auc:0.93185+0.00263\ttest-auc:0.77388+0.01954\n",
      "[681]\ttrain-auc:0.93196+0.00268\ttest-auc:0.77388+0.01945\n",
      "[682]\ttrain-auc:0.93206+0.00269\ttest-auc:0.77390+0.01943\n",
      "[683]\ttrain-auc:0.93215+0.00271\ttest-auc:0.77391+0.01945\n",
      "[684]\ttrain-auc:0.93221+0.00271\ttest-auc:0.77389+0.01946\n",
      "[685]\ttrain-auc:0.93225+0.00272\ttest-auc:0.77386+0.01949\n",
      "[686]\ttrain-auc:0.93234+0.00274\ttest-auc:0.77379+0.01951\n",
      "[687]\ttrain-auc:0.93241+0.00274\ttest-auc:0.77385+0.01947\n",
      "[688]\ttrain-auc:0.93249+0.00274\ttest-auc:0.77387+0.01949\n",
      "[689]\ttrain-auc:0.93257+0.00273\ttest-auc:0.77381+0.01955\n",
      "[690]\ttrain-auc:0.93268+0.00267\ttest-auc:0.77384+0.01959\n",
      "[691]\ttrain-auc:0.93276+0.00267\ttest-auc:0.77381+0.01956\n",
      "[692]\ttrain-auc:0.93283+0.00269\ttest-auc:0.77388+0.01951\n",
      "[693]\ttrain-auc:0.93291+0.00270\ttest-auc:0.77388+0.01946\n",
      "[694]\ttrain-auc:0.93297+0.00269\ttest-auc:0.77390+0.01946\n",
      "[695]\ttrain-auc:0.93308+0.00270\ttest-auc:0.77400+0.01948\n",
      "[696]\ttrain-auc:0.93315+0.00272\ttest-auc:0.77405+0.01945\n",
      "[697]\ttrain-auc:0.93322+0.00275\ttest-auc:0.77403+0.01943\n",
      "[698]\ttrain-auc:0.93332+0.00270\ttest-auc:0.77412+0.01950\n",
      "[699]\ttrain-auc:0.93340+0.00271\ttest-auc:0.77414+0.01953\n",
      "[700]\ttrain-auc:0.93349+0.00272\ttest-auc:0.77411+0.01951\n",
      "[701]\ttrain-auc:0.93360+0.00273\ttest-auc:0.77414+0.01946\n",
      "[702]\ttrain-auc:0.93371+0.00272\ttest-auc:0.77415+0.01948\n",
      "[703]\ttrain-auc:0.93379+0.00267\ttest-auc:0.77425+0.01950\n",
      "[704]\ttrain-auc:0.93390+0.00270\ttest-auc:0.77424+0.01940\n",
      "[705]\ttrain-auc:0.93397+0.00272\ttest-auc:0.77424+0.01945\n",
      "[706]\ttrain-auc:0.93406+0.00272\ttest-auc:0.77424+0.01947\n",
      "[707]\ttrain-auc:0.93417+0.00271\ttest-auc:0.77424+0.01946\n",
      "[708]\ttrain-auc:0.93425+0.00270\ttest-auc:0.77422+0.01949\n",
      "[709]\ttrain-auc:0.93437+0.00266\ttest-auc:0.77424+0.01949\n",
      "[710]\ttrain-auc:0.93449+0.00265\ttest-auc:0.77422+0.01946\n",
      "[711]\ttrain-auc:0.93456+0.00263\ttest-auc:0.77417+0.01951\n",
      "[712]\ttrain-auc:0.93466+0.00265\ttest-auc:0.77419+0.01945\n",
      "[713]\ttrain-auc:0.93471+0.00266\ttest-auc:0.77426+0.01939\n",
      "[714]\ttrain-auc:0.93484+0.00266\ttest-auc:0.77430+0.01940\n",
      "[715]\ttrain-auc:0.93497+0.00261\ttest-auc:0.77432+0.01943\n",
      "[716]\ttrain-auc:0.93505+0.00260\ttest-auc:0.77435+0.01948\n",
      "[717]\ttrain-auc:0.93512+0.00255\ttest-auc:0.77435+0.01950\n",
      "[718]\ttrain-auc:0.93526+0.00259\ttest-auc:0.77439+0.01948\n",
      "[719]\ttrain-auc:0.93535+0.00260\ttest-auc:0.77452+0.01946\n",
      "[720]\ttrain-auc:0.93540+0.00262\ttest-auc:0.77453+0.01940\n",
      "[721]\ttrain-auc:0.93552+0.00259\ttest-auc:0.77453+0.01939\n",
      "[722]\ttrain-auc:0.93561+0.00259\ttest-auc:0.77454+0.01938\n",
      "[723]\ttrain-auc:0.93572+0.00259\ttest-auc:0.77455+0.01935\n",
      "[724]\ttrain-auc:0.93586+0.00263\ttest-auc:0.77459+0.01932\n",
      "[725]\ttrain-auc:0.93594+0.00262\ttest-auc:0.77463+0.01933\n",
      "[726]\ttrain-auc:0.93603+0.00261\ttest-auc:0.77470+0.01933\n",
      "[727]\ttrain-auc:0.93608+0.00261\ttest-auc:0.77466+0.01931\n",
      "[728]\ttrain-auc:0.93617+0.00264\ttest-auc:0.77472+0.01929\n",
      "[729]\ttrain-auc:0.93624+0.00264\ttest-auc:0.77469+0.01930\n",
      "[730]\ttrain-auc:0.93631+0.00266\ttest-auc:0.77475+0.01930\n",
      "[731]\ttrain-auc:0.93640+0.00268\ttest-auc:0.77478+0.01930\n",
      "[732]\ttrain-auc:0.93647+0.00268\ttest-auc:0.77476+0.01929\n",
      "[733]\ttrain-auc:0.93654+0.00269\ttest-auc:0.77479+0.01934\n",
      "[734]\ttrain-auc:0.93666+0.00268\ttest-auc:0.77480+0.01936\n",
      "[735]\ttrain-auc:0.93670+0.00267\ttest-auc:0.77482+0.01933\n",
      "[736]\ttrain-auc:0.93675+0.00269\ttest-auc:0.77481+0.01929\n",
      "[737]\ttrain-auc:0.93682+0.00271\ttest-auc:0.77483+0.01933\n",
      "[738]\ttrain-auc:0.93692+0.00276\ttest-auc:0.77483+0.01933\n",
      "[739]\ttrain-auc:0.93702+0.00276\ttest-auc:0.77486+0.01926\n",
      "[740]\ttrain-auc:0.93714+0.00274\ttest-auc:0.77488+0.01926\n",
      "[741]\ttrain-auc:0.93723+0.00280\ttest-auc:0.77494+0.01924\n",
      "[742]\ttrain-auc:0.93734+0.00280\ttest-auc:0.77497+0.01922\n",
      "[743]\ttrain-auc:0.93744+0.00281\ttest-auc:0.77501+0.01918\n",
      "[744]\ttrain-auc:0.93751+0.00279\ttest-auc:0.77501+0.01909\n",
      "[745]\ttrain-auc:0.93757+0.00281\ttest-auc:0.77499+0.01914\n",
      "[746]\ttrain-auc:0.93768+0.00281\ttest-auc:0.77497+0.01912\n",
      "[747]\ttrain-auc:0.93780+0.00276\ttest-auc:0.77493+0.01914\n",
      "[748]\ttrain-auc:0.93786+0.00274\ttest-auc:0.77491+0.01914\n",
      "[749]\ttrain-auc:0.93797+0.00275\ttest-auc:0.77492+0.01913\n",
      "[750]\ttrain-auc:0.93804+0.00279\ttest-auc:0.77491+0.01912\n",
      "[751]\ttrain-auc:0.93816+0.00274\ttest-auc:0.77492+0.01909\n",
      "[752]\ttrain-auc:0.93823+0.00277\ttest-auc:0.77495+0.01906\n",
      "[753]\ttrain-auc:0.93829+0.00278\ttest-auc:0.77500+0.01910\n",
      "[754]\ttrain-auc:0.93839+0.00276\ttest-auc:0.77507+0.01911\n",
      "[755]\ttrain-auc:0.93844+0.00275\ttest-auc:0.77507+0.01913\n",
      "[756]\ttrain-auc:0.93849+0.00274\ttest-auc:0.77508+0.01914\n",
      "[757]\ttrain-auc:0.93855+0.00276\ttest-auc:0.77503+0.01910\n",
      "[758]\ttrain-auc:0.93865+0.00272\ttest-auc:0.77505+0.01912\n",
      "[759]\ttrain-auc:0.93874+0.00269\ttest-auc:0.77503+0.01901\n",
      "[760]\ttrain-auc:0.93881+0.00266\ttest-auc:0.77505+0.01905\n",
      "[761]\ttrain-auc:0.93890+0.00267\ttest-auc:0.77506+0.01905\n",
      "[762]\ttrain-auc:0.93896+0.00267\ttest-auc:0.77504+0.01905\n",
      "[763]\ttrain-auc:0.93901+0.00268\ttest-auc:0.77502+0.01903\n",
      "[764]\ttrain-auc:0.93908+0.00269\ttest-auc:0.77501+0.01900\n",
      "[765]\ttrain-auc:0.93918+0.00265\ttest-auc:0.77508+0.01904\n",
      "[766]\ttrain-auc:0.93924+0.00266\ttest-auc:0.77515+0.01907\n",
      "[767]\ttrain-auc:0.93933+0.00262\ttest-auc:0.77523+0.01907\n",
      "[768]\ttrain-auc:0.93941+0.00261\ttest-auc:0.77520+0.01905\n",
      "[769]\ttrain-auc:0.93948+0.00259\ttest-auc:0.77522+0.01916\n",
      "[770]\ttrain-auc:0.93957+0.00264\ttest-auc:0.77531+0.01915\n",
      "[771]\ttrain-auc:0.93963+0.00262\ttest-auc:0.77532+0.01911\n",
      "[772]\ttrain-auc:0.93971+0.00260\ttest-auc:0.77531+0.01913\n",
      "[773]\ttrain-auc:0.93974+0.00260\ttest-auc:0.77528+0.01910\n",
      "[774]\ttrain-auc:0.93982+0.00261\ttest-auc:0.77526+0.01908\n",
      "[775]\ttrain-auc:0.93990+0.00255\ttest-auc:0.77528+0.01911\n",
      "[776]\ttrain-auc:0.93998+0.00255\ttest-auc:0.77527+0.01910\n",
      "[777]\ttrain-auc:0.94012+0.00259\ttest-auc:0.77537+0.01905\n",
      "[778]\ttrain-auc:0.94022+0.00259\ttest-auc:0.77537+0.01910\n",
      "[779]\ttrain-auc:0.94031+0.00258\ttest-auc:0.77539+0.01915\n",
      "[780]\ttrain-auc:0.94041+0.00262\ttest-auc:0.77542+0.01914\n",
      "[781]\ttrain-auc:0.94049+0.00255\ttest-auc:0.77543+0.01923\n",
      "[782]\ttrain-auc:0.94059+0.00256\ttest-auc:0.77550+0.01924\n",
      "[783]\ttrain-auc:0.94065+0.00257\ttest-auc:0.77546+0.01930\n",
      "[784]\ttrain-auc:0.94072+0.00259\ttest-auc:0.77547+0.01928\n",
      "[785]\ttrain-auc:0.94082+0.00262\ttest-auc:0.77551+0.01926\n",
      "[786]\ttrain-auc:0.94091+0.00260\ttest-auc:0.77553+0.01926\n",
      "[787]\ttrain-auc:0.94098+0.00259\ttest-auc:0.77552+0.01923\n",
      "[788]\ttrain-auc:0.94108+0.00261\ttest-auc:0.77550+0.01919\n",
      "[789]\ttrain-auc:0.94119+0.00264\ttest-auc:0.77558+0.01915\n",
      "[790]\ttrain-auc:0.94127+0.00265\ttest-auc:0.77552+0.01913\n",
      "[791]\ttrain-auc:0.94136+0.00263\ttest-auc:0.77555+0.01911\n",
      "[792]\ttrain-auc:0.94141+0.00264\ttest-auc:0.77555+0.01913\n",
      "[793]\ttrain-auc:0.94149+0.00264\ttest-auc:0.77557+0.01915\n",
      "[794]\ttrain-auc:0.94154+0.00267\ttest-auc:0.77560+0.01919\n",
      "[795]\ttrain-auc:0.94159+0.00265\ttest-auc:0.77559+0.01917\n",
      "[796]\ttrain-auc:0.94167+0.00267\ttest-auc:0.77562+0.01920\n",
      "[797]\ttrain-auc:0.94174+0.00265\ttest-auc:0.77563+0.01920\n",
      "[798]\ttrain-auc:0.94184+0.00259\ttest-auc:0.77563+0.01924\n",
      "[799]\ttrain-auc:0.94194+0.00259\ttest-auc:0.77564+0.01924\n",
      "[800]\ttrain-auc:0.94203+0.00260\ttest-auc:0.77562+0.01926\n",
      "[801]\ttrain-auc:0.94210+0.00257\ttest-auc:0.77560+0.01933\n",
      "[802]\ttrain-auc:0.94217+0.00259\ttest-auc:0.77564+0.01930\n",
      "[803]\ttrain-auc:0.94221+0.00258\ttest-auc:0.77563+0.01927\n",
      "[804]\ttrain-auc:0.94228+0.00256\ttest-auc:0.77568+0.01924\n",
      "[805]\ttrain-auc:0.94233+0.00254\ttest-auc:0.77566+0.01927\n",
      "[806]\ttrain-auc:0.94237+0.00255\ttest-auc:0.77566+0.01928\n",
      "[807]\ttrain-auc:0.94245+0.00254\ttest-auc:0.77568+0.01921\n",
      "[808]\ttrain-auc:0.94254+0.00255\ttest-auc:0.77571+0.01919\n",
      "[809]\ttrain-auc:0.94261+0.00252\ttest-auc:0.77573+0.01921\n",
      "[810]\ttrain-auc:0.94265+0.00252\ttest-auc:0.77570+0.01923\n",
      "[811]\ttrain-auc:0.94272+0.00251\ttest-auc:0.77569+0.01923\n",
      "[812]\ttrain-auc:0.94277+0.00253\ttest-auc:0.77570+0.01925\n",
      "[813]\ttrain-auc:0.94284+0.00253\ttest-auc:0.77569+0.01926\n",
      "[814]\ttrain-auc:0.94292+0.00254\ttest-auc:0.77568+0.01926\n",
      "[815]\ttrain-auc:0.94302+0.00255\ttest-auc:0.77573+0.01932\n",
      "[816]\ttrain-auc:0.94307+0.00254\ttest-auc:0.77574+0.01931\n",
      "[817]\ttrain-auc:0.94316+0.00252\ttest-auc:0.77574+0.01928\n",
      "[818]\ttrain-auc:0.94320+0.00252\ttest-auc:0.77575+0.01927\n",
      "[819]\ttrain-auc:0.94327+0.00251\ttest-auc:0.77573+0.01931\n",
      "[820]\ttrain-auc:0.94332+0.00248\ttest-auc:0.77574+0.01926\n",
      "[821]\ttrain-auc:0.94338+0.00247\ttest-auc:0.77571+0.01927\n",
      "[822]\ttrain-auc:0.94350+0.00244\ttest-auc:0.77576+0.01924\n",
      "[823]\ttrain-auc:0.94354+0.00242\ttest-auc:0.77572+0.01919\n",
      "[824]\ttrain-auc:0.94357+0.00242\ttest-auc:0.77575+0.01915\n",
      "[825]\ttrain-auc:0.94365+0.00242\ttest-auc:0.77574+0.01912\n",
      "[826]\ttrain-auc:0.94375+0.00242\ttest-auc:0.77576+0.01903\n",
      "[827]\ttrain-auc:0.94390+0.00242\ttest-auc:0.77582+0.01906\n",
      "[828]\ttrain-auc:0.94398+0.00238\ttest-auc:0.77579+0.01911\n",
      "[829]\ttrain-auc:0.94407+0.00240\ttest-auc:0.77574+0.01908\n",
      "[830]\ttrain-auc:0.94418+0.00240\ttest-auc:0.77584+0.01905\n",
      "[831]\ttrain-auc:0.94425+0.00237\ttest-auc:0.77586+0.01911\n",
      "[832]\ttrain-auc:0.94429+0.00238\ttest-auc:0.77586+0.01912\n",
      "[833]\ttrain-auc:0.94434+0.00237\ttest-auc:0.77588+0.01911\n",
      "[834]\ttrain-auc:0.94441+0.00235\ttest-auc:0.77587+0.01911\n",
      "[835]\ttrain-auc:0.94446+0.00235\ttest-auc:0.77587+0.01903\n",
      "[836]\ttrain-auc:0.94452+0.00233\ttest-auc:0.77593+0.01903\n",
      "[837]\ttrain-auc:0.94458+0.00233\ttest-auc:0.77597+0.01906\n",
      "[838]\ttrain-auc:0.94464+0.00234\ttest-auc:0.77597+0.01906\n",
      "[839]\ttrain-auc:0.94471+0.00232\ttest-auc:0.77598+0.01910\n",
      "[840]\ttrain-auc:0.94480+0.00230\ttest-auc:0.77596+0.01907\n",
      "[841]\ttrain-auc:0.94489+0.00225\ttest-auc:0.77592+0.01908\n",
      "[842]\ttrain-auc:0.94495+0.00223\ttest-auc:0.77594+0.01917\n",
      "[843]\ttrain-auc:0.94501+0.00224\ttest-auc:0.77595+0.01921\n",
      "[844]\ttrain-auc:0.94512+0.00228\ttest-auc:0.77601+0.01920\n",
      "[845]\ttrain-auc:0.94525+0.00225\ttest-auc:0.77608+0.01916\n",
      "[846]\ttrain-auc:0.94531+0.00224\ttest-auc:0.77609+0.01914\n",
      "[847]\ttrain-auc:0.94536+0.00223\ttest-auc:0.77607+0.01912\n",
      "[848]\ttrain-auc:0.94540+0.00224\ttest-auc:0.77608+0.01912\n",
      "[849]\ttrain-auc:0.94547+0.00220\ttest-auc:0.77616+0.01910\n",
      "[850]\ttrain-auc:0.94552+0.00222\ttest-auc:0.77618+0.01905\n",
      "[851]\ttrain-auc:0.94557+0.00221\ttest-auc:0.77617+0.01905\n",
      "[852]\ttrain-auc:0.94561+0.00221\ttest-auc:0.77615+0.01905\n",
      "[853]\ttrain-auc:0.94567+0.00218\ttest-auc:0.77614+0.01912\n",
      "[854]\ttrain-auc:0.94572+0.00221\ttest-auc:0.77617+0.01909\n",
      "[855]\ttrain-auc:0.94578+0.00220\ttest-auc:0.77618+0.01908\n",
      "[856]\ttrain-auc:0.94584+0.00221\ttest-auc:0.77620+0.01903\n",
      "[857]\ttrain-auc:0.94592+0.00219\ttest-auc:0.77624+0.01907\n",
      "[858]\ttrain-auc:0.94597+0.00216\ttest-auc:0.77624+0.01910\n",
      "[859]\ttrain-auc:0.94602+0.00214\ttest-auc:0.77624+0.01910\n",
      "[860]\ttrain-auc:0.94605+0.00214\ttest-auc:0.77628+0.01909\n",
      "[861]\ttrain-auc:0.94614+0.00211\ttest-auc:0.77626+0.01911\n",
      "[862]\ttrain-auc:0.94620+0.00212\ttest-auc:0.77624+0.01916\n",
      "[863]\ttrain-auc:0.94628+0.00210\ttest-auc:0.77626+0.01921\n",
      "[864]\ttrain-auc:0.94637+0.00207\ttest-auc:0.77626+0.01920\n",
      "[865]\ttrain-auc:0.94640+0.00206\ttest-auc:0.77626+0.01923\n",
      "[866]\ttrain-auc:0.94646+0.00207\ttest-auc:0.77629+0.01923\n",
      "[867]\ttrain-auc:0.94652+0.00208\ttest-auc:0.77630+0.01922\n",
      "[868]\ttrain-auc:0.94656+0.00208\ttest-auc:0.77626+0.01921\n",
      "[869]\ttrain-auc:0.94665+0.00204\ttest-auc:0.77623+0.01923\n",
      "[870]\ttrain-auc:0.94671+0.00204\ttest-auc:0.77624+0.01925\n",
      "[871]\ttrain-auc:0.94683+0.00202\ttest-auc:0.77627+0.01920\n",
      "[872]\ttrain-auc:0.94691+0.00201\ttest-auc:0.77626+0.01922\n",
      "[873]\ttrain-auc:0.94698+0.00204\ttest-auc:0.77629+0.01921\n",
      "[874]\ttrain-auc:0.94706+0.00206\ttest-auc:0.77630+0.01922\n",
      "[875]\ttrain-auc:0.94711+0.00206\ttest-auc:0.77634+0.01919\n",
      "[876]\ttrain-auc:0.94716+0.00204\ttest-auc:0.77637+0.01925\n",
      "[877]\ttrain-auc:0.94723+0.00200\ttest-auc:0.77637+0.01921\n",
      "[878]\ttrain-auc:0.94729+0.00198\ttest-auc:0.77635+0.01914\n",
      "[879]\ttrain-auc:0.94733+0.00199\ttest-auc:0.77634+0.01912\n",
      "[880]\ttrain-auc:0.94738+0.00202\ttest-auc:0.77637+0.01912\n",
      "[881]\ttrain-auc:0.94743+0.00203\ttest-auc:0.77638+0.01916\n",
      "[882]\ttrain-auc:0.94751+0.00201\ttest-auc:0.77637+0.01913\n",
      "[883]\ttrain-auc:0.94758+0.00198\ttest-auc:0.77635+0.01915\n",
      "[884]\ttrain-auc:0.94762+0.00199\ttest-auc:0.77632+0.01914\n",
      "[885]\ttrain-auc:0.94770+0.00199\ttest-auc:0.77635+0.01920\n",
      "[886]\ttrain-auc:0.94776+0.00198\ttest-auc:0.77642+0.01925\n",
      "[887]\ttrain-auc:0.94783+0.00199\ttest-auc:0.77639+0.01924\n",
      "[888]\ttrain-auc:0.94791+0.00199\ttest-auc:0.77637+0.01921\n",
      "[889]\ttrain-auc:0.94800+0.00198\ttest-auc:0.77643+0.01920\n",
      "[890]\ttrain-auc:0.94809+0.00195\ttest-auc:0.77644+0.01911\n",
      "[891]\ttrain-auc:0.94814+0.00195\ttest-auc:0.77648+0.01911\n",
      "[892]\ttrain-auc:0.94819+0.00195\ttest-auc:0.77650+0.01905\n",
      "[893]\ttrain-auc:0.94823+0.00196\ttest-auc:0.77649+0.01902\n",
      "[894]\ttrain-auc:0.94830+0.00198\ttest-auc:0.77647+0.01909\n",
      "[895]\ttrain-auc:0.94837+0.00198\ttest-auc:0.77648+0.01910\n",
      "[896]\ttrain-auc:0.94845+0.00200\ttest-auc:0.77655+0.01900\n",
      "[897]\ttrain-auc:0.94853+0.00201\ttest-auc:0.77654+0.01898\n",
      "[898]\ttrain-auc:0.94859+0.00199\ttest-auc:0.77658+0.01900\n",
      "[899]\ttrain-auc:0.94864+0.00199\ttest-auc:0.77664+0.01902\n",
      "[900]\ttrain-auc:0.94870+0.00200\ttest-auc:0.77660+0.01898\n",
      "[901]\ttrain-auc:0.94878+0.00202\ttest-auc:0.77660+0.01898\n",
      "[902]\ttrain-auc:0.94884+0.00200\ttest-auc:0.77661+0.01892\n",
      "[903]\ttrain-auc:0.94890+0.00200\ttest-auc:0.77663+0.01892\n",
      "[904]\ttrain-auc:0.94896+0.00196\ttest-auc:0.77664+0.01891\n",
      "[905]\ttrain-auc:0.94900+0.00197\ttest-auc:0.77663+0.01894\n",
      "[906]\ttrain-auc:0.94906+0.00197\ttest-auc:0.77660+0.01892\n",
      "[907]\ttrain-auc:0.94908+0.00196\ttest-auc:0.77661+0.01893\n",
      "[908]\ttrain-auc:0.94912+0.00196\ttest-auc:0.77657+0.01891\n",
      "[909]\ttrain-auc:0.94916+0.00196\ttest-auc:0.77657+0.01894\n",
      "[910]\ttrain-auc:0.94926+0.00194\ttest-auc:0.77656+0.01897\n",
      "[911]\ttrain-auc:0.94930+0.00193\ttest-auc:0.77656+0.01896\n",
      "[912]\ttrain-auc:0.94938+0.00192\ttest-auc:0.77655+0.01895\n",
      "[913]\ttrain-auc:0.94946+0.00190\ttest-auc:0.77660+0.01896\n",
      "[914]\ttrain-auc:0.94949+0.00190\ttest-auc:0.77659+0.01894\n",
      "[915]\ttrain-auc:0.94954+0.00191\ttest-auc:0.77659+0.01889\n",
      "[916]\ttrain-auc:0.94961+0.00191\ttest-auc:0.77665+0.01886\n",
      "[917]\ttrain-auc:0.94966+0.00190\ttest-auc:0.77665+0.01888\n",
      "[918]\ttrain-auc:0.94971+0.00191\ttest-auc:0.77671+0.01893\n",
      "[919]\ttrain-auc:0.94977+0.00192\ttest-auc:0.77672+0.01888\n",
      "[920]\ttrain-auc:0.94982+0.00193\ttest-auc:0.77674+0.01883\n",
      "[921]\ttrain-auc:0.94988+0.00196\ttest-auc:0.77674+0.01880\n",
      "[922]\ttrain-auc:0.94993+0.00196\ttest-auc:0.77671+0.01882\n",
      "[923]\ttrain-auc:0.94995+0.00195\ttest-auc:0.77673+0.01880\n",
      "[924]\ttrain-auc:0.94999+0.00195\ttest-auc:0.77676+0.01880\n",
      "[925]\ttrain-auc:0.95006+0.00195\ttest-auc:0.77674+0.01885\n",
      "[926]\ttrain-auc:0.95010+0.00194\ttest-auc:0.77677+0.01881\n",
      "[927]\ttrain-auc:0.95016+0.00194\ttest-auc:0.77680+0.01877\n",
      "[928]\ttrain-auc:0.95020+0.00193\ttest-auc:0.77686+0.01884\n",
      "[929]\ttrain-auc:0.95026+0.00194\ttest-auc:0.77684+0.01883\n",
      "[930]\ttrain-auc:0.95034+0.00192\ttest-auc:0.77682+0.01886\n",
      "[931]\ttrain-auc:0.95038+0.00191\ttest-auc:0.77684+0.01887\n",
      "[932]\ttrain-auc:0.95049+0.00193\ttest-auc:0.77680+0.01885\n",
      "[933]\ttrain-auc:0.95054+0.00193\ttest-auc:0.77681+0.01885\n",
      "[934]\ttrain-auc:0.95060+0.00195\ttest-auc:0.77683+0.01883\n",
      "[935]\ttrain-auc:0.95066+0.00194\ttest-auc:0.77687+0.01886\n",
      "[936]\ttrain-auc:0.95071+0.00196\ttest-auc:0.77687+0.01886\n",
      "[937]\ttrain-auc:0.95076+0.00196\ttest-auc:0.77687+0.01887\n",
      "[938]\ttrain-auc:0.95085+0.00198\ttest-auc:0.77694+0.01886\n",
      "[939]\ttrain-auc:0.95090+0.00197\ttest-auc:0.77697+0.01885\n",
      "[940]\ttrain-auc:0.95096+0.00196\ttest-auc:0.77694+0.01885\n",
      "[941]\ttrain-auc:0.95100+0.00195\ttest-auc:0.77690+0.01885\n",
      "[942]\ttrain-auc:0.95105+0.00193\ttest-auc:0.77695+0.01888\n",
      "[943]\ttrain-auc:0.95107+0.00193\ttest-auc:0.77694+0.01886\n",
      "[944]\ttrain-auc:0.95114+0.00193\ttest-auc:0.77693+0.01883\n",
      "[945]\ttrain-auc:0.95122+0.00195\ttest-auc:0.77699+0.01880\n",
      "[946]\ttrain-auc:0.95132+0.00191\ttest-auc:0.77698+0.01878\n",
      "[947]\ttrain-auc:0.95135+0.00190\ttest-auc:0.77697+0.01878\n",
      "[948]\ttrain-auc:0.95140+0.00192\ttest-auc:0.77698+0.01876\n",
      "[949]\ttrain-auc:0.95144+0.00195\ttest-auc:0.77696+0.01877\n",
      "[950]\ttrain-auc:0.95150+0.00191\ttest-auc:0.77693+0.01873\n",
      "[951]\ttrain-auc:0.95153+0.00191\ttest-auc:0.77690+0.01872\n",
      "[952]\ttrain-auc:0.95158+0.00191\ttest-auc:0.77689+0.01874\n",
      "[953]\ttrain-auc:0.95166+0.00192\ttest-auc:0.77688+0.01872\n",
      "[954]\ttrain-auc:0.95172+0.00191\ttest-auc:0.77690+0.01873\n",
      "[955]\ttrain-auc:0.95179+0.00189\ttest-auc:0.77693+0.01870\n",
      "[956]\ttrain-auc:0.95187+0.00189\ttest-auc:0.77702+0.01868\n",
      "[957]\ttrain-auc:0.95191+0.00189\ttest-auc:0.77699+0.01873\n",
      "[958]\ttrain-auc:0.95197+0.00187\ttest-auc:0.77699+0.01875\n",
      "[959]\ttrain-auc:0.95199+0.00187\ttest-auc:0.77699+0.01876\n",
      "[960]\ttrain-auc:0.95206+0.00187\ttest-auc:0.77705+0.01876\n",
      "[961]\ttrain-auc:0.95211+0.00185\ttest-auc:0.77710+0.01872\n",
      "[962]\ttrain-auc:0.95215+0.00186\ttest-auc:0.77706+0.01868\n",
      "[963]\ttrain-auc:0.95221+0.00186\ttest-auc:0.77707+0.01869\n",
      "[964]\ttrain-auc:0.95224+0.00185\ttest-auc:0.77702+0.01872\n",
      "[965]\ttrain-auc:0.95231+0.00185\ttest-auc:0.77703+0.01873\n",
      "[966]\ttrain-auc:0.95237+0.00186\ttest-auc:0.77700+0.01870\n",
      "[967]\ttrain-auc:0.95242+0.00185\ttest-auc:0.77700+0.01873\n",
      "[968]\ttrain-auc:0.95249+0.00186\ttest-auc:0.77704+0.01869\n",
      "[969]\ttrain-auc:0.95252+0.00185\ttest-auc:0.77707+0.01870\n",
      "[970]\ttrain-auc:0.95257+0.00185\ttest-auc:0.77710+0.01870\n",
      "[971]\ttrain-auc:0.95264+0.00182\ttest-auc:0.77711+0.01875\n",
      "[972]\ttrain-auc:0.95272+0.00183\ttest-auc:0.77712+0.01870\n",
      "[973]\ttrain-auc:0.95275+0.00184\ttest-auc:0.77713+0.01865\n",
      "[974]\ttrain-auc:0.95280+0.00185\ttest-auc:0.77712+0.01864\n",
      "[975]\ttrain-auc:0.95285+0.00188\ttest-auc:0.77710+0.01865\n",
      "[976]\ttrain-auc:0.95292+0.00190\ttest-auc:0.77712+0.01872\n",
      "[977]\ttrain-auc:0.95298+0.00191\ttest-auc:0.77711+0.01868\n",
      "[978]\ttrain-auc:0.95308+0.00188\ttest-auc:0.77712+0.01864\n",
      "[979]\ttrain-auc:0.95312+0.00188\ttest-auc:0.77714+0.01861\n",
      "[980]\ttrain-auc:0.95320+0.00187\ttest-auc:0.77714+0.01869\n",
      "[981]\ttrain-auc:0.95325+0.00187\ttest-auc:0.77709+0.01873\n",
      "[982]\ttrain-auc:0.95329+0.00189\ttest-auc:0.77708+0.01869\n",
      "[983]\ttrain-auc:0.95333+0.00189\ttest-auc:0.77712+0.01868\n",
      "[984]\ttrain-auc:0.95337+0.00191\ttest-auc:0.77714+0.01869\n",
      "[985]\ttrain-auc:0.95342+0.00191\ttest-auc:0.77716+0.01874\n",
      "[986]\ttrain-auc:0.95348+0.00189\ttest-auc:0.77715+0.01874\n",
      "[987]\ttrain-auc:0.95356+0.00189\ttest-auc:0.77717+0.01878\n",
      "[988]\ttrain-auc:0.95362+0.00188\ttest-auc:0.77714+0.01869\n",
      "[989]\ttrain-auc:0.95368+0.00188\ttest-auc:0.77717+0.01865\n",
      "[990]\ttrain-auc:0.95374+0.00186\ttest-auc:0.77723+0.01862\n",
      "[991]\ttrain-auc:0.95380+0.00189\ttest-auc:0.77730+0.01867\n",
      "[992]\ttrain-auc:0.95385+0.00188\ttest-auc:0.77733+0.01865\n",
      "[993]\ttrain-auc:0.95391+0.00187\ttest-auc:0.77736+0.01867\n",
      "[994]\ttrain-auc:0.95397+0.00187\ttest-auc:0.77740+0.01869\n",
      "[995]\ttrain-auc:0.95403+0.00188\ttest-auc:0.77740+0.01864\n",
      "[996]\ttrain-auc:0.95408+0.00189\ttest-auc:0.77738+0.01869\n",
      "[997]\ttrain-auc:0.95414+0.00188\ttest-auc:0.77745+0.01870\n",
      "[998]\ttrain-auc:0.95417+0.00189\ttest-auc:0.77742+0.01873\n",
      "[999]\ttrain-auc:0.95421+0.00188\ttest-auc:0.77747+0.01869\n",
      "[1000]\ttrain-auc:0.95427+0.00186\ttest-auc:0.77745+0.01872\n",
      "[1001]\ttrain-auc:0.95430+0.00185\ttest-auc:0.77744+0.01874\n",
      "[1002]\ttrain-auc:0.95433+0.00187\ttest-auc:0.77743+0.01875\n",
      "[1003]\ttrain-auc:0.95439+0.00186\ttest-auc:0.77743+0.01884\n",
      "[1004]\ttrain-auc:0.95444+0.00185\ttest-auc:0.77741+0.01882\n",
      "[1005]\ttrain-auc:0.95449+0.00185\ttest-auc:0.77743+0.01882\n",
      "[1006]\ttrain-auc:0.95453+0.00186\ttest-auc:0.77741+0.01883\n",
      "[1007]\ttrain-auc:0.95456+0.00187\ttest-auc:0.77744+0.01884\n",
      "[1008]\ttrain-auc:0.95462+0.00186\ttest-auc:0.77741+0.01879\n",
      "[1009]\ttrain-auc:0.95469+0.00188\ttest-auc:0.77744+0.01880\n",
      "[1010]\ttrain-auc:0.95473+0.00186\ttest-auc:0.77742+0.01880\n",
      "[1011]\ttrain-auc:0.95478+0.00186\ttest-auc:0.77745+0.01885\n",
      "[1012]\ttrain-auc:0.95485+0.00189\ttest-auc:0.77746+0.01884\n",
      "[1013]\ttrain-auc:0.95489+0.00189\ttest-auc:0.77744+0.01885\n",
      "[1014]\ttrain-auc:0.95494+0.00189\ttest-auc:0.77744+0.01888\n",
      "[1015]\ttrain-auc:0.95499+0.00188\ttest-auc:0.77746+0.01890\n",
      "[1016]\ttrain-auc:0.95508+0.00186\ttest-auc:0.77748+0.01886\n",
      "[1017]\ttrain-auc:0.95512+0.00187\ttest-auc:0.77746+0.01884\n",
      "[1018]\ttrain-auc:0.95517+0.00186\ttest-auc:0.77747+0.01880\n",
      "[1019]\ttrain-auc:0.95520+0.00187\ttest-auc:0.77749+0.01880\n",
      "[1020]\ttrain-auc:0.95527+0.00187\ttest-auc:0.77749+0.01882\n",
      "[1021]\ttrain-auc:0.95531+0.00185\ttest-auc:0.77751+0.01881\n",
      "[1022]\ttrain-auc:0.95535+0.00187\ttest-auc:0.77752+0.01882\n",
      "[1023]\ttrain-auc:0.95539+0.00189\ttest-auc:0.77752+0.01881\n",
      "[1024]\ttrain-auc:0.95542+0.00190\ttest-auc:0.77755+0.01879\n",
      "[1025]\ttrain-auc:0.95549+0.00189\ttest-auc:0.77757+0.01875\n",
      "[1026]\ttrain-auc:0.95553+0.00190\ttest-auc:0.77761+0.01876\n",
      "[1027]\ttrain-auc:0.95558+0.00190\ttest-auc:0.77766+0.01875\n",
      "[1028]\ttrain-auc:0.95564+0.00190\ttest-auc:0.77767+0.01876\n",
      "[1029]\ttrain-auc:0.95567+0.00189\ttest-auc:0.77761+0.01874\n",
      "[1030]\ttrain-auc:0.95570+0.00190\ttest-auc:0.77760+0.01873\n",
      "[1031]\ttrain-auc:0.95574+0.00188\ttest-auc:0.77757+0.01873\n",
      "[1032]\ttrain-auc:0.95580+0.00186\ttest-auc:0.77762+0.01879\n",
      "[1033]\ttrain-auc:0.95585+0.00186\ttest-auc:0.77761+0.01873\n",
      "[1034]\ttrain-auc:0.95589+0.00186\ttest-auc:0.77761+0.01873\n",
      "[1035]\ttrain-auc:0.95594+0.00186\ttest-auc:0.77762+0.01875\n",
      "[1036]\ttrain-auc:0.95599+0.00186\ttest-auc:0.77761+0.01874\n",
      "[1037]\ttrain-auc:0.95604+0.00185\ttest-auc:0.77767+0.01875\n",
      "[1038]\ttrain-auc:0.95609+0.00183\ttest-auc:0.77767+0.01875\n",
      "[1039]\ttrain-auc:0.95613+0.00184\ttest-auc:0.77766+0.01874\n",
      "[1040]\ttrain-auc:0.95619+0.00183\ttest-auc:0.77763+0.01874\n",
      "[1041]\ttrain-auc:0.95623+0.00183\ttest-auc:0.77765+0.01871\n",
      "[1042]\ttrain-auc:0.95628+0.00181\ttest-auc:0.77770+0.01869\n",
      "[1043]\ttrain-auc:0.95631+0.00183\ttest-auc:0.77767+0.01870\n",
      "[1044]\ttrain-auc:0.95636+0.00180\ttest-auc:0.77768+0.01873\n",
      "[1045]\ttrain-auc:0.95643+0.00184\ttest-auc:0.77767+0.01875\n",
      "[1046]\ttrain-auc:0.95645+0.00183\ttest-auc:0.77766+0.01878\n",
      "[1047]\ttrain-auc:0.95650+0.00183\ttest-auc:0.77769+0.01872\n",
      "[1048]\ttrain-auc:0.95658+0.00183\ttest-auc:0.77774+0.01867\n",
      "[1049]\ttrain-auc:0.95663+0.00184\ttest-auc:0.77771+0.01866\n",
      "[1050]\ttrain-auc:0.95667+0.00182\ttest-auc:0.77770+0.01868\n",
      "[1051]\ttrain-auc:0.95674+0.00182\ttest-auc:0.77772+0.01868\n",
      "[1052]\ttrain-auc:0.95677+0.00182\ttest-auc:0.77775+0.01868\n",
      "[1053]\ttrain-auc:0.95680+0.00181\ttest-auc:0.77774+0.01867\n",
      "[1054]\ttrain-auc:0.95685+0.00183\ttest-auc:0.77780+0.01862\n",
      "[1055]\ttrain-auc:0.95689+0.00180\ttest-auc:0.77783+0.01864\n",
      "[1056]\ttrain-auc:0.95695+0.00180\ttest-auc:0.77784+0.01863\n",
      "[1057]\ttrain-auc:0.95698+0.00180\ttest-auc:0.77785+0.01862\n",
      "[1058]\ttrain-auc:0.95701+0.00179\ttest-auc:0.77787+0.01869\n",
      "[1059]\ttrain-auc:0.95706+0.00180\ttest-auc:0.77787+0.01868\n",
      "[1060]\ttrain-auc:0.95711+0.00181\ttest-auc:0.77789+0.01865\n",
      "[1061]\ttrain-auc:0.95717+0.00183\ttest-auc:0.77784+0.01864\n",
      "[1062]\ttrain-auc:0.95724+0.00182\ttest-auc:0.77783+0.01870\n",
      "[1063]\ttrain-auc:0.95729+0.00183\ttest-auc:0.77787+0.01871\n",
      "[1064]\ttrain-auc:0.95732+0.00183\ttest-auc:0.77787+0.01874\n",
      "[1065]\ttrain-auc:0.95735+0.00183\ttest-auc:0.77790+0.01876\n",
      "[1066]\ttrain-auc:0.95741+0.00180\ttest-auc:0.77790+0.01875\n",
      "[1067]\ttrain-auc:0.95748+0.00179\ttest-auc:0.77793+0.01871\n",
      "[1068]\ttrain-auc:0.95752+0.00178\ttest-auc:0.77792+0.01873\n",
      "[1069]\ttrain-auc:0.95755+0.00177\ttest-auc:0.77790+0.01872\n",
      "[1070]\ttrain-auc:0.95760+0.00176\ttest-auc:0.77792+0.01872\n",
      "[1071]\ttrain-auc:0.95764+0.00178\ttest-auc:0.77798+0.01871\n",
      "[1072]\ttrain-auc:0.95767+0.00177\ttest-auc:0.77799+0.01870\n",
      "[1073]\ttrain-auc:0.95772+0.00177\ttest-auc:0.77800+0.01870\n",
      "[1074]\ttrain-auc:0.95777+0.00175\ttest-auc:0.77802+0.01873\n",
      "[1075]\ttrain-auc:0.95780+0.00176\ttest-auc:0.77803+0.01871\n",
      "[1076]\ttrain-auc:0.95785+0.00175\ttest-auc:0.77801+0.01877\n",
      "[1077]\ttrain-auc:0.95791+0.00173\ttest-auc:0.77801+0.01879\n",
      "[1078]\ttrain-auc:0.95796+0.00174\ttest-auc:0.77802+0.01879\n",
      "[1079]\ttrain-auc:0.95800+0.00173\ttest-auc:0.77803+0.01875\n",
      "[1080]\ttrain-auc:0.95807+0.00172\ttest-auc:0.77806+0.01873\n",
      "[1081]\ttrain-auc:0.95809+0.00171\ttest-auc:0.77803+0.01868\n",
      "[1082]\ttrain-auc:0.95813+0.00172\ttest-auc:0.77808+0.01861\n",
      "[1083]\ttrain-auc:0.95817+0.00171\ttest-auc:0.77809+0.01860\n",
      "[1084]\ttrain-auc:0.95821+0.00171\ttest-auc:0.77809+0.01859\n",
      "[1085]\ttrain-auc:0.95827+0.00168\ttest-auc:0.77807+0.01858\n",
      "[1086]\ttrain-auc:0.95833+0.00166\ttest-auc:0.77806+0.01857\n",
      "[1087]\ttrain-auc:0.95837+0.00167\ttest-auc:0.77808+0.01859\n",
      "[1088]\ttrain-auc:0.95840+0.00166\ttest-auc:0.77808+0.01857\n",
      "[1089]\ttrain-auc:0.95844+0.00165\ttest-auc:0.77810+0.01855\n",
      "[1090]\ttrain-auc:0.95849+0.00163\ttest-auc:0.77809+0.01854\n",
      "[1091]\ttrain-auc:0.95853+0.00162\ttest-auc:0.77806+0.01855\n",
      "[1092]\ttrain-auc:0.95858+0.00162\ttest-auc:0.77805+0.01856\n",
      "[1093]\ttrain-auc:0.95862+0.00160\ttest-auc:0.77805+0.01857\n",
      "[1094]\ttrain-auc:0.95866+0.00160\ttest-auc:0.77804+0.01858\n",
      "[1095]\ttrain-auc:0.95871+0.00159\ttest-auc:0.77806+0.01859\n",
      "[1096]\ttrain-auc:0.95875+0.00158\ttest-auc:0.77805+0.01860\n",
      "[1097]\ttrain-auc:0.95881+0.00158\ttest-auc:0.77804+0.01860\n",
      "[1098]\ttrain-auc:0.95886+0.00156\ttest-auc:0.77801+0.01860\n",
      "[1099]\ttrain-auc:0.95890+0.00156\ttest-auc:0.77801+0.01858\n",
      "[1100]\ttrain-auc:0.95894+0.00157\ttest-auc:0.77800+0.01861\n",
      "[1101]\ttrain-auc:0.95897+0.00155\ttest-auc:0.77802+0.01857\n",
      "[1102]\ttrain-auc:0.95902+0.00155\ttest-auc:0.77803+0.01863\n",
      "[1103]\ttrain-auc:0.95905+0.00153\ttest-auc:0.77804+0.01861\n",
      "[1104]\ttrain-auc:0.95909+0.00154\ttest-auc:0.77805+0.01860\n",
      "[1105]\ttrain-auc:0.95912+0.00156\ttest-auc:0.77804+0.01865\n",
      "[1106]\ttrain-auc:0.95917+0.00155\ttest-auc:0.77804+0.01863\n",
      "[1107]\ttrain-auc:0.95921+0.00155\ttest-auc:0.77802+0.01865\n",
      "[1108]\ttrain-auc:0.95926+0.00156\ttest-auc:0.77802+0.01860\n",
      "[1109]\ttrain-auc:0.95928+0.00157\ttest-auc:0.77801+0.01862\n",
      "[1110]\ttrain-auc:0.95930+0.00156\ttest-auc:0.77800+0.01862\n",
      "[1111]\ttrain-auc:0.95935+0.00154\ttest-auc:0.77804+0.01866\n",
      "[1112]\ttrain-auc:0.95940+0.00153\ttest-auc:0.77800+0.01866\n",
      "[1113]\ttrain-auc:0.95947+0.00151\ttest-auc:0.77804+0.01868\n",
      "[1114]\ttrain-auc:0.95950+0.00149\ttest-auc:0.77799+0.01872\n",
      "[1115]\ttrain-auc:0.95955+0.00148\ttest-auc:0.77798+0.01870\n",
      "[1116]\ttrain-auc:0.95958+0.00147\ttest-auc:0.77796+0.01871\n",
      "[1117]\ttrain-auc:0.95961+0.00145\ttest-auc:0.77797+0.01872\n",
      "[1118]\ttrain-auc:0.95965+0.00144\ttest-auc:0.77797+0.01874\n",
      "[1119]\ttrain-auc:0.95970+0.00143\ttest-auc:0.77798+0.01875\n",
      "[1120]\ttrain-auc:0.95976+0.00144\ttest-auc:0.77795+0.01875\n",
      "[1121]\ttrain-auc:0.95979+0.00144\ttest-auc:0.77798+0.01873\n",
      "[1122]\ttrain-auc:0.95984+0.00145\ttest-auc:0.77798+0.01876\n",
      "[1123]\ttrain-auc:0.95990+0.00147\ttest-auc:0.77797+0.01873\n",
      "[1124]\ttrain-auc:0.95994+0.00145\ttest-auc:0.77800+0.01876\n",
      "[1125]\ttrain-auc:0.95997+0.00145\ttest-auc:0.77802+0.01879\n",
      "[1126]\ttrain-auc:0.96000+0.00145\ttest-auc:0.77809+0.01878\n",
      "[1127]\ttrain-auc:0.96005+0.00145\ttest-auc:0.77807+0.01877\n",
      "[1128]\ttrain-auc:0.96008+0.00143\ttest-auc:0.77809+0.01873\n",
      "[1129]\ttrain-auc:0.96011+0.00144\ttest-auc:0.77809+0.01874\n",
      "[1130]\ttrain-auc:0.96015+0.00143\ttest-auc:0.77809+0.01874\n",
      "[1131]\ttrain-auc:0.96019+0.00144\ttest-auc:0.77810+0.01874\n",
      "[1132]\ttrain-auc:0.96021+0.00145\ttest-auc:0.77816+0.01873\n",
      "[1133]\ttrain-auc:0.96024+0.00144\ttest-auc:0.77810+0.01870\n",
      "[1134]\ttrain-auc:0.96028+0.00144\ttest-auc:0.77810+0.01869\n",
      "[1135]\ttrain-auc:0.96031+0.00144\ttest-auc:0.77812+0.01868\n",
      "[1136]\ttrain-auc:0.96035+0.00145\ttest-auc:0.77810+0.01868\n",
      "[1137]\ttrain-auc:0.96038+0.00144\ttest-auc:0.77812+0.01866\n",
      "[1138]\ttrain-auc:0.96044+0.00144\ttest-auc:0.77815+0.01861\n",
      "[1139]\ttrain-auc:0.96047+0.00144\ttest-auc:0.77815+0.01858\n",
      "[1140]\ttrain-auc:0.96050+0.00143\ttest-auc:0.77816+0.01856\n",
      "[1141]\ttrain-auc:0.96054+0.00145\ttest-auc:0.77817+0.01858\n",
      "[1142]\ttrain-auc:0.96057+0.00146\ttest-auc:0.77817+0.01854\n",
      "[1143]\ttrain-auc:0.96061+0.00145\ttest-auc:0.77816+0.01856\n",
      "[1144]\ttrain-auc:0.96063+0.00146\ttest-auc:0.77816+0.01855\n",
      "[1145]\ttrain-auc:0.96067+0.00145\ttest-auc:0.77819+0.01861\n",
      "[1146]\ttrain-auc:0.96071+0.00143\ttest-auc:0.77820+0.01861\n",
      "[1147]\ttrain-auc:0.96075+0.00143\ttest-auc:0.77824+0.01859\n",
      "[1148]\ttrain-auc:0.96079+0.00144\ttest-auc:0.77823+0.01856\n",
      "[1149]\ttrain-auc:0.96083+0.00144\ttest-auc:0.77821+0.01854\n",
      "[1150]\ttrain-auc:0.96087+0.00144\ttest-auc:0.77821+0.01856\n",
      "[1151]\ttrain-auc:0.96094+0.00146\ttest-auc:0.77822+0.01855\n",
      "[1152]\ttrain-auc:0.96097+0.00146\ttest-auc:0.77822+0.01856\n",
      "[1153]\ttrain-auc:0.96099+0.00146\ttest-auc:0.77819+0.01857\n",
      "[1154]\ttrain-auc:0.96102+0.00145\ttest-auc:0.77822+0.01859\n",
      "[1155]\ttrain-auc:0.96104+0.00144\ttest-auc:0.77821+0.01855\n",
      "[1156]\ttrain-auc:0.96106+0.00143\ttest-auc:0.77822+0.01856\n",
      "[1157]\ttrain-auc:0.96111+0.00143\ttest-auc:0.77826+0.01856\n",
      "[1158]\ttrain-auc:0.96113+0.00142\ttest-auc:0.77826+0.01859\n",
      "[1159]\ttrain-auc:0.96119+0.00146\ttest-auc:0.77823+0.01854\n",
      "[1160]\ttrain-auc:0.96123+0.00147\ttest-auc:0.77824+0.01852\n",
      "[1161]\ttrain-auc:0.96126+0.00145\ttest-auc:0.77828+0.01852\n",
      "[1162]\ttrain-auc:0.96131+0.00146\ttest-auc:0.77831+0.01858\n",
      "[1163]\ttrain-auc:0.96135+0.00145\ttest-auc:0.77827+0.01856\n",
      "[1164]\ttrain-auc:0.96139+0.00145\ttest-auc:0.77827+0.01854\n",
      "[1165]\ttrain-auc:0.96148+0.00142\ttest-auc:0.77828+0.01855\n",
      "[1166]\ttrain-auc:0.96150+0.00142\ttest-auc:0.77828+0.01854\n",
      "[1167]\ttrain-auc:0.96154+0.00142\ttest-auc:0.77831+0.01855\n",
      "[1168]\ttrain-auc:0.96158+0.00141\ttest-auc:0.77833+0.01852\n",
      "[1169]\ttrain-auc:0.96163+0.00142\ttest-auc:0.77828+0.01851\n",
      "[1170]\ttrain-auc:0.96168+0.00142\ttest-auc:0.77827+0.01849\n",
      "[1171]\ttrain-auc:0.96172+0.00141\ttest-auc:0.77826+0.01846\n",
      "[1172]\ttrain-auc:0.96177+0.00140\ttest-auc:0.77827+0.01847\n",
      "[1173]\ttrain-auc:0.96180+0.00139\ttest-auc:0.77828+0.01850\n",
      "[1174]\ttrain-auc:0.96186+0.00143\ttest-auc:0.77829+0.01845\n",
      "[1175]\ttrain-auc:0.96189+0.00143\ttest-auc:0.77825+0.01846\n",
      "[1176]\ttrain-auc:0.96194+0.00142\ttest-auc:0.77828+0.01844\n",
      "[1177]\ttrain-auc:0.96197+0.00143\ttest-auc:0.77828+0.01845\n",
      "[1178]\ttrain-auc:0.96201+0.00145\ttest-auc:0.77827+0.01847\n",
      "[1179]\ttrain-auc:0.96205+0.00144\ttest-auc:0.77829+0.01846\n",
      "[1180]\ttrain-auc:0.96209+0.00143\ttest-auc:0.77829+0.01843\n",
      "[1181]\ttrain-auc:0.96212+0.00144\ttest-auc:0.77830+0.01841\n",
      "[1182]\ttrain-auc:0.96217+0.00144\ttest-auc:0.77829+0.01839\n",
      "[1183]\ttrain-auc:0.96220+0.00143\ttest-auc:0.77826+0.01837\n",
      "[1184]\ttrain-auc:0.96223+0.00141\ttest-auc:0.77832+0.01836\n",
      "[1185]\ttrain-auc:0.96229+0.00138\ttest-auc:0.77834+0.01838\n",
      "[1186]\ttrain-auc:0.96234+0.00140\ttest-auc:0.77836+0.01835\n",
      "[1187]\ttrain-auc:0.96239+0.00139\ttest-auc:0.77836+0.01837\n",
      "[1188]\ttrain-auc:0.96242+0.00139\ttest-auc:0.77838+0.01836\n",
      "[1189]\ttrain-auc:0.96248+0.00138\ttest-auc:0.77838+0.01839\n",
      "[1190]\ttrain-auc:0.96251+0.00139\ttest-auc:0.77840+0.01839\n",
      "[1191]\ttrain-auc:0.96253+0.00138\ttest-auc:0.77839+0.01842\n",
      "[1192]\ttrain-auc:0.96258+0.00137\ttest-auc:0.77837+0.01836\n",
      "[1193]\ttrain-auc:0.96261+0.00136\ttest-auc:0.77840+0.01838\n",
      "[1194]\ttrain-auc:0.96264+0.00138\ttest-auc:0.77841+0.01838\n",
      "[1195]\ttrain-auc:0.96267+0.00138\ttest-auc:0.77840+0.01837\n",
      "[1196]\ttrain-auc:0.96272+0.00138\ttest-auc:0.77847+0.01838\n",
      "[1197]\ttrain-auc:0.96277+0.00136\ttest-auc:0.77847+0.01840\n",
      "[1198]\ttrain-auc:0.96281+0.00135\ttest-auc:0.77846+0.01838\n",
      "[1199]\ttrain-auc:0.96283+0.00135\ttest-auc:0.77847+0.01839\n",
      "[1200]\ttrain-auc:0.96287+0.00134\ttest-auc:0.77844+0.01836\n",
      "[1201]\ttrain-auc:0.96290+0.00136\ttest-auc:0.77843+0.01836\n",
      "[1202]\ttrain-auc:0.96295+0.00136\ttest-auc:0.77842+0.01836\n",
      "[1203]\ttrain-auc:0.96297+0.00137\ttest-auc:0.77837+0.01840\n",
      "[1204]\ttrain-auc:0.96300+0.00136\ttest-auc:0.77837+0.01840\n",
      "[1205]\ttrain-auc:0.96304+0.00137\ttest-auc:0.77836+0.01837\n",
      "[1206]\ttrain-auc:0.96306+0.00136\ttest-auc:0.77838+0.01837\n",
      "[1207]\ttrain-auc:0.96310+0.00135\ttest-auc:0.77839+0.01837\n",
      "[1208]\ttrain-auc:0.96315+0.00137\ttest-auc:0.77838+0.01838\n",
      "[1209]\ttrain-auc:0.96318+0.00137\ttest-auc:0.77836+0.01839\n",
      "[1210]\ttrain-auc:0.96321+0.00137\ttest-auc:0.77836+0.01841\n",
      "[1211]\ttrain-auc:0.96324+0.00137\ttest-auc:0.77839+0.01837\n",
      "[1212]\ttrain-auc:0.96327+0.00138\ttest-auc:0.77839+0.01836\n",
      "[1213]\ttrain-auc:0.96328+0.00138\ttest-auc:0.77840+0.01835\n",
      "[1214]\ttrain-auc:0.96331+0.00139\ttest-auc:0.77841+0.01830\n",
      "[1215]\ttrain-auc:0.96335+0.00140\ttest-auc:0.77841+0.01838\n",
      "[1216]\ttrain-auc:0.96339+0.00138\ttest-auc:0.77843+0.01835\n",
      "[1217]\ttrain-auc:0.96343+0.00137\ttest-auc:0.77847+0.01841\n",
      "[1218]\ttrain-auc:0.96346+0.00137\ttest-auc:0.77845+0.01836\n",
      "[1219]\ttrain-auc:0.96349+0.00138\ttest-auc:0.77844+0.01837\n",
      "[1220]\ttrain-auc:0.96354+0.00136\ttest-auc:0.77841+0.01840\n",
      "[1221]\ttrain-auc:0.96357+0.00136\ttest-auc:0.77845+0.01838\n",
      "[1222]\ttrain-auc:0.96362+0.00134\ttest-auc:0.77844+0.01839\n",
      "[1223]\ttrain-auc:0.96363+0.00133\ttest-auc:0.77844+0.01840\n",
      "[1224]\ttrain-auc:0.96367+0.00134\ttest-auc:0.77845+0.01850\n",
      "[1225]\ttrain-auc:0.96371+0.00136\ttest-auc:0.77846+0.01847\n",
      "[1226]\ttrain-auc:0.96375+0.00134\ttest-auc:0.77846+0.01847\n",
      "[1227]\ttrain-auc:0.96379+0.00133\ttest-auc:0.77847+0.01847\n",
      "[1228]\ttrain-auc:0.96382+0.00133\ttest-auc:0.77846+0.01847\n",
      "[1229]\ttrain-auc:0.96385+0.00133\ttest-auc:0.77847+0.01847\n",
      "[1230]\ttrain-auc:0.96389+0.00134\ttest-auc:0.77842+0.01843\n",
      "[1231]\ttrain-auc:0.96392+0.00134\ttest-auc:0.77842+0.01843\n",
      "[1232]\ttrain-auc:0.96394+0.00134\ttest-auc:0.77839+0.01841\n",
      "[1233]\ttrain-auc:0.96397+0.00134\ttest-auc:0.77847+0.01842\n",
      "[1234]\ttrain-auc:0.96402+0.00132\ttest-auc:0.77850+0.01845\n",
      "[1235]\ttrain-auc:0.96405+0.00132\ttest-auc:0.77854+0.01845\n",
      "[1236]\ttrain-auc:0.96408+0.00133\ttest-auc:0.77849+0.01847\n",
      "[1237]\ttrain-auc:0.96411+0.00133\ttest-auc:0.77849+0.01846\n",
      "[1238]\ttrain-auc:0.96415+0.00133\ttest-auc:0.77849+0.01846\n",
      "[1239]\ttrain-auc:0.96419+0.00134\ttest-auc:0.77849+0.01849\n",
      "[1240]\ttrain-auc:0.96421+0.00134\ttest-auc:0.77846+0.01846\n",
      "[1241]\ttrain-auc:0.96426+0.00135\ttest-auc:0.77849+0.01849\n",
      "[1242]\ttrain-auc:0.96429+0.00136\ttest-auc:0.77849+0.01848\n",
      "[1243]\ttrain-auc:0.96432+0.00137\ttest-auc:0.77848+0.01850\n",
      "[1244]\ttrain-auc:0.96435+0.00136\ttest-auc:0.77851+0.01849\n",
      "[1245]\ttrain-auc:0.96440+0.00137\ttest-auc:0.77853+0.01853\n",
      "[1246]\ttrain-auc:0.96444+0.00139\ttest-auc:0.77852+0.01854\n",
      "[1247]\ttrain-auc:0.96447+0.00139\ttest-auc:0.77849+0.01853\n",
      "[1248]\ttrain-auc:0.96451+0.00139\ttest-auc:0.77846+0.01857\n",
      "[1249]\ttrain-auc:0.96455+0.00138\ttest-auc:0.77847+0.01857\n",
      "[1250]\ttrain-auc:0.96460+0.00138\ttest-auc:0.77848+0.01857\n",
      "[1251]\ttrain-auc:0.96463+0.00139\ttest-auc:0.77844+0.01858\n",
      "[1252]\ttrain-auc:0.96467+0.00139\ttest-auc:0.77848+0.01855\n",
      "[1253]\ttrain-auc:0.96469+0.00138\ttest-auc:0.77848+0.01855\n",
      "[1254]\ttrain-auc:0.96471+0.00139\ttest-auc:0.77845+0.01853\n",
      "[1255]\ttrain-auc:0.96475+0.00137\ttest-auc:0.77851+0.01853\n",
      "[1256]\ttrain-auc:0.96477+0.00137\ttest-auc:0.77851+0.01853\n",
      "[1257]\ttrain-auc:0.96479+0.00136\ttest-auc:0.77850+0.01856\n",
      "[1258]\ttrain-auc:0.96482+0.00136\ttest-auc:0.77849+0.01859\n",
      "[1259]\ttrain-auc:0.96484+0.00137\ttest-auc:0.77848+0.01861\n",
      "[1260]\ttrain-auc:0.96488+0.00138\ttest-auc:0.77849+0.01860\n",
      "[1261]\ttrain-auc:0.96492+0.00140\ttest-auc:0.77845+0.01854\n",
      "[1262]\ttrain-auc:0.96494+0.00139\ttest-auc:0.77851+0.01854\n",
      "[1263]\ttrain-auc:0.96499+0.00139\ttest-auc:0.77852+0.01856\n",
      "[1264]\ttrain-auc:0.96501+0.00138\ttest-auc:0.77849+0.01857\n",
      "[1265]\ttrain-auc:0.96505+0.00138\ttest-auc:0.77849+0.01858\n",
      "[1266]\ttrain-auc:0.96508+0.00138\ttest-auc:0.77846+0.01855\n",
      "[1267]\ttrain-auc:0.96511+0.00138\ttest-auc:0.77852+0.01857\n",
      "[1268]\ttrain-auc:0.96514+0.00137\ttest-auc:0.77847+0.01858\n",
      "[1269]\ttrain-auc:0.96516+0.00138\ttest-auc:0.77844+0.01856\n",
      "[1270]\ttrain-auc:0.96521+0.00135\ttest-auc:0.77851+0.01864\n",
      "[1271]\ttrain-auc:0.96523+0.00135\ttest-auc:0.77850+0.01863\n",
      "[1272]\ttrain-auc:0.96527+0.00134\ttest-auc:0.77848+0.01866\n",
      "[1273]\ttrain-auc:0.96529+0.00134\ttest-auc:0.77847+0.01865\n",
      "[1274]\ttrain-auc:0.96533+0.00134\ttest-auc:0.77852+0.01866\n",
      "[1275]\ttrain-auc:0.96537+0.00134\ttest-auc:0.77850+0.01869\n",
      "[1276]\ttrain-auc:0.96541+0.00133\ttest-auc:0.77852+0.01871\n",
      "[1277]\ttrain-auc:0.96543+0.00133\ttest-auc:0.77853+0.01867\n",
      "[1278]\ttrain-auc:0.96547+0.00130\ttest-auc:0.77854+0.01863\n",
      "[1279]\ttrain-auc:0.96550+0.00130\ttest-auc:0.77855+0.01863\n",
      "[1280]\ttrain-auc:0.96554+0.00131\ttest-auc:0.77858+0.01858\n",
      "[1281]\ttrain-auc:0.96557+0.00131\ttest-auc:0.77855+0.01853\n",
      "[1282]\ttrain-auc:0.96560+0.00131\ttest-auc:0.77856+0.01851\n",
      "[1283]\ttrain-auc:0.96563+0.00131\ttest-auc:0.77857+0.01851\n",
      "[1284]\ttrain-auc:0.96569+0.00129\ttest-auc:0.77860+0.01850\n",
      "[1285]\ttrain-auc:0.96571+0.00128\ttest-auc:0.77862+0.01850\n",
      "[1286]\ttrain-auc:0.96575+0.00131\ttest-auc:0.77863+0.01844\n",
      "[1287]\ttrain-auc:0.96577+0.00130\ttest-auc:0.77868+0.01852\n",
      "[1288]\ttrain-auc:0.96579+0.00129\ttest-auc:0.77873+0.01852\n",
      "[1289]\ttrain-auc:0.96584+0.00128\ttest-auc:0.77873+0.01851\n",
      "[1290]\ttrain-auc:0.96587+0.00128\ttest-auc:0.77876+0.01851\n",
      "[1291]\ttrain-auc:0.96591+0.00126\ttest-auc:0.77874+0.01852\n",
      "[1292]\ttrain-auc:0.96594+0.00127\ttest-auc:0.77879+0.01856\n",
      "[1293]\ttrain-auc:0.96598+0.00127\ttest-auc:0.77885+0.01858\n",
      "[1294]\ttrain-auc:0.96600+0.00126\ttest-auc:0.77883+0.01859\n",
      "[1295]\ttrain-auc:0.96604+0.00127\ttest-auc:0.77884+0.01862\n",
      "[1296]\ttrain-auc:0.96607+0.00127\ttest-auc:0.77887+0.01861\n",
      "[1297]\ttrain-auc:0.96611+0.00126\ttest-auc:0.77889+0.01866\n",
      "[1298]\ttrain-auc:0.96614+0.00125\ttest-auc:0.77886+0.01862\n",
      "[1299]\ttrain-auc:0.96616+0.00124\ttest-auc:0.77888+0.01864\n",
      "[1300]\ttrain-auc:0.96619+0.00125\ttest-auc:0.77891+0.01864\n",
      "[1301]\ttrain-auc:0.96623+0.00124\ttest-auc:0.77888+0.01861\n",
      "[1302]\ttrain-auc:0.96625+0.00124\ttest-auc:0.77889+0.01861\n",
      "[1303]\ttrain-auc:0.96630+0.00123\ttest-auc:0.77887+0.01861\n",
      "[1304]\ttrain-auc:0.96634+0.00123\ttest-auc:0.77886+0.01860\n",
      "[1305]\ttrain-auc:0.96637+0.00123\ttest-auc:0.77886+0.01865\n",
      "[1306]\ttrain-auc:0.96639+0.00123\ttest-auc:0.77884+0.01865\n",
      "[1307]\ttrain-auc:0.96644+0.00124\ttest-auc:0.77890+0.01862\n",
      "[1308]\ttrain-auc:0.96646+0.00124\ttest-auc:0.77889+0.01863\n",
      "[1309]\ttrain-auc:0.96647+0.00124\ttest-auc:0.77885+0.01863\n",
      "[1310]\ttrain-auc:0.96649+0.00124\ttest-auc:0.77885+0.01862\n",
      "[1311]\ttrain-auc:0.96651+0.00124\ttest-auc:0.77884+0.01860\n",
      "[1312]\ttrain-auc:0.96655+0.00124\ttest-auc:0.77887+0.01857\n",
      "[1313]\ttrain-auc:0.96659+0.00124\ttest-auc:0.77891+0.01857\n",
      "[1314]\ttrain-auc:0.96660+0.00124\ttest-auc:0.77892+0.01859\n",
      "[1315]\ttrain-auc:0.96662+0.00123\ttest-auc:0.77896+0.01857\n",
      "[1316]\ttrain-auc:0.96665+0.00123\ttest-auc:0.77899+0.01855\n",
      "[1317]\ttrain-auc:0.96667+0.00123\ttest-auc:0.77898+0.01853\n",
      "[1318]\ttrain-auc:0.96673+0.00120\ttest-auc:0.77896+0.01852\n",
      "[1319]\ttrain-auc:0.96675+0.00120\ttest-auc:0.77894+0.01852\n",
      "[1320]\ttrain-auc:0.96677+0.00120\ttest-auc:0.77895+0.01848\n",
      "[1321]\ttrain-auc:0.96679+0.00120\ttest-auc:0.77894+0.01848\n",
      "[1322]\ttrain-auc:0.96681+0.00120\ttest-auc:0.77898+0.01847\n",
      "[1323]\ttrain-auc:0.96684+0.00120\ttest-auc:0.77899+0.01844\n",
      "[1324]\ttrain-auc:0.96686+0.00119\ttest-auc:0.77900+0.01845\n",
      "[1325]\ttrain-auc:0.96688+0.00119\ttest-auc:0.77900+0.01843\n",
      "[1326]\ttrain-auc:0.96691+0.00117\ttest-auc:0.77901+0.01842\n",
      "[1327]\ttrain-auc:0.96696+0.00116\ttest-auc:0.77905+0.01844\n",
      "[1328]\ttrain-auc:0.96700+0.00116\ttest-auc:0.77902+0.01845\n",
      "[1329]\ttrain-auc:0.96704+0.00117\ttest-auc:0.77902+0.01843\n",
      "[1330]\ttrain-auc:0.96708+0.00117\ttest-auc:0.77901+0.01843\n",
      "[1331]\ttrain-auc:0.96712+0.00117\ttest-auc:0.77900+0.01843\n",
      "[1332]\ttrain-auc:0.96714+0.00116\ttest-auc:0.77903+0.01843\n",
      "[1333]\ttrain-auc:0.96718+0.00113\ttest-auc:0.77904+0.01846\n",
      "[1334]\ttrain-auc:0.96720+0.00113\ttest-auc:0.77908+0.01844\n",
      "[1335]\ttrain-auc:0.96723+0.00112\ttest-auc:0.77911+0.01845\n",
      "[1336]\ttrain-auc:0.96726+0.00112\ttest-auc:0.77911+0.01846\n",
      "[1337]\ttrain-auc:0.96728+0.00112\ttest-auc:0.77911+0.01847\n",
      "[1338]\ttrain-auc:0.96732+0.00110\ttest-auc:0.77912+0.01851\n",
      "[1339]\ttrain-auc:0.96733+0.00110\ttest-auc:0.77912+0.01852\n",
      "[1340]\ttrain-auc:0.96735+0.00111\ttest-auc:0.77911+0.01850\n",
      "[1341]\ttrain-auc:0.96738+0.00112\ttest-auc:0.77912+0.01849\n",
      "[1342]\ttrain-auc:0.96741+0.00111\ttest-auc:0.77912+0.01850\n",
      "[1343]\ttrain-auc:0.96744+0.00110\ttest-auc:0.77911+0.01847\n",
      "[1344]\ttrain-auc:0.96747+0.00110\ttest-auc:0.77910+0.01843\n",
      "[1345]\ttrain-auc:0.96753+0.00111\ttest-auc:0.77907+0.01843\n",
      "[1346]\ttrain-auc:0.96756+0.00110\ttest-auc:0.77907+0.01841\n",
      "[1347]\ttrain-auc:0.96759+0.00109\ttest-auc:0.77905+0.01841\n",
      "[1348]\ttrain-auc:0.96762+0.00108\ttest-auc:0.77907+0.01840\n",
      "[1349]\ttrain-auc:0.96764+0.00108\ttest-auc:0.77909+0.01836\n",
      "[1350]\ttrain-auc:0.96767+0.00110\ttest-auc:0.77910+0.01833\n",
      "[1351]\ttrain-auc:0.96769+0.00109\ttest-auc:0.77908+0.01831\n",
      "[1352]\ttrain-auc:0.96772+0.00109\ttest-auc:0.77914+0.01829\n",
      "[1353]\ttrain-auc:0.96775+0.00108\ttest-auc:0.77914+0.01830\n",
      "[1354]\ttrain-auc:0.96777+0.00108\ttest-auc:0.77917+0.01834\n",
      "[1355]\ttrain-auc:0.96779+0.00109\ttest-auc:0.77917+0.01832\n",
      "[1356]\ttrain-auc:0.96781+0.00109\ttest-auc:0.77918+0.01830\n",
      "[1357]\ttrain-auc:0.96785+0.00108\ttest-auc:0.77915+0.01828\n",
      "[1358]\ttrain-auc:0.96787+0.00107\ttest-auc:0.77919+0.01833\n",
      "[1359]\ttrain-auc:0.96789+0.00107\ttest-auc:0.77915+0.01827\n",
      "[1360]\ttrain-auc:0.96792+0.00106\ttest-auc:0.77914+0.01825\n",
      "[1361]\ttrain-auc:0.96797+0.00108\ttest-auc:0.77912+0.01824\n",
      "[1362]\ttrain-auc:0.96799+0.00108\ttest-auc:0.77911+0.01823\n",
      "[1363]\ttrain-auc:0.96802+0.00108\ttest-auc:0.77913+0.01820\n",
      "[1364]\ttrain-auc:0.96805+0.00109\ttest-auc:0.77912+0.01821\n",
      "[1365]\ttrain-auc:0.96808+0.00109\ttest-auc:0.77913+0.01817\n",
      "[1366]\ttrain-auc:0.96811+0.00109\ttest-auc:0.77914+0.01815\n",
      "[1367]\ttrain-auc:0.96813+0.00108\ttest-auc:0.77919+0.01819\n",
      "[1368]\ttrain-auc:0.96817+0.00107\ttest-auc:0.77921+0.01824\n",
      "[1369]\ttrain-auc:0.96821+0.00106\ttest-auc:0.77922+0.01822\n",
      "[1370]\ttrain-auc:0.96824+0.00108\ttest-auc:0.77922+0.01824\n",
      "[1371]\ttrain-auc:0.96827+0.00108\ttest-auc:0.77926+0.01821\n",
      "[1372]\ttrain-auc:0.96829+0.00109\ttest-auc:0.77927+0.01823\n",
      "[1373]\ttrain-auc:0.96830+0.00109\ttest-auc:0.77927+0.01821\n",
      "[1374]\ttrain-auc:0.96832+0.00108\ttest-auc:0.77928+0.01822\n",
      "[1375]\ttrain-auc:0.96834+0.00108\ttest-auc:0.77925+0.01819\n",
      "[1376]\ttrain-auc:0.96835+0.00108\ttest-auc:0.77923+0.01825\n",
      "[1377]\ttrain-auc:0.96839+0.00109\ttest-auc:0.77925+0.01824\n",
      "[1378]\ttrain-auc:0.96840+0.00109\ttest-auc:0.77926+0.01824\n",
      "[1379]\ttrain-auc:0.96842+0.00110\ttest-auc:0.77928+0.01828\n",
      "[1380]\ttrain-auc:0.96844+0.00109\ttest-auc:0.77931+0.01828\n",
      "[1381]\ttrain-auc:0.96849+0.00113\ttest-auc:0.77936+0.01823\n",
      "[1382]\ttrain-auc:0.96851+0.00113\ttest-auc:0.77936+0.01822\n",
      "[1383]\ttrain-auc:0.96855+0.00112\ttest-auc:0.77937+0.01817\n",
      "[1384]\ttrain-auc:0.96858+0.00112\ttest-auc:0.77935+0.01817\n",
      "[1385]\ttrain-auc:0.96862+0.00113\ttest-auc:0.77938+0.01817\n",
      "[1386]\ttrain-auc:0.96864+0.00113\ttest-auc:0.77938+0.01816\n",
      "[1387]\ttrain-auc:0.96867+0.00114\ttest-auc:0.77938+0.01817\n",
      "[1388]\ttrain-auc:0.96870+0.00115\ttest-auc:0.77942+0.01821\n",
      "[1389]\ttrain-auc:0.96871+0.00114\ttest-auc:0.77943+0.01817\n",
      "[1390]\ttrain-auc:0.96872+0.00115\ttest-auc:0.77945+0.01822\n",
      "[1391]\ttrain-auc:0.96875+0.00114\ttest-auc:0.77942+0.01819\n",
      "[1392]\ttrain-auc:0.96876+0.00113\ttest-auc:0.77938+0.01820\n",
      "[1393]\ttrain-auc:0.96879+0.00113\ttest-auc:0.77938+0.01822\n",
      "[1394]\ttrain-auc:0.96882+0.00113\ttest-auc:0.77936+0.01820\n",
      "[1395]\ttrain-auc:0.96885+0.00113\ttest-auc:0.77933+0.01822\n",
      "[1396]\ttrain-auc:0.96888+0.00113\ttest-auc:0.77937+0.01821\n",
      "[1397]\ttrain-auc:0.96891+0.00113\ttest-auc:0.77936+0.01823\n",
      "[1398]\ttrain-auc:0.96894+0.00113\ttest-auc:0.77934+0.01820\n",
      "[1399]\ttrain-auc:0.96897+0.00112\ttest-auc:0.77936+0.01822\n",
      "[1400]\ttrain-auc:0.96900+0.00113\ttest-auc:0.77935+0.01825\n",
      "[1401]\ttrain-auc:0.96903+0.00111\ttest-auc:0.77939+0.01824\n",
      "[1402]\ttrain-auc:0.96905+0.00111\ttest-auc:0.77942+0.01825\n",
      "[1403]\ttrain-auc:0.96909+0.00110\ttest-auc:0.77939+0.01825\n",
      "[1404]\ttrain-auc:0.96911+0.00111\ttest-auc:0.77942+0.01825\n",
      "[1405]\ttrain-auc:0.96914+0.00111\ttest-auc:0.77945+0.01828\n",
      "[1406]\ttrain-auc:0.96916+0.00110\ttest-auc:0.77947+0.01831\n",
      "[1407]\ttrain-auc:0.96919+0.00109\ttest-auc:0.77946+0.01830\n",
      "[1408]\ttrain-auc:0.96921+0.00109\ttest-auc:0.77943+0.01831\n",
      "[1409]\ttrain-auc:0.96924+0.00110\ttest-auc:0.77945+0.01830\n",
      "[1410]\ttrain-auc:0.96926+0.00109\ttest-auc:0.77948+0.01833\n",
      "[1411]\ttrain-auc:0.96929+0.00109\ttest-auc:0.77948+0.01835\n",
      "[1412]\ttrain-auc:0.96933+0.00109\ttest-auc:0.77953+0.01838\n",
      "[1413]\ttrain-auc:0.96935+0.00110\ttest-auc:0.77954+0.01837\n",
      "[1414]\ttrain-auc:0.96937+0.00109\ttest-auc:0.77957+0.01840\n",
      "[1415]\ttrain-auc:0.96940+0.00109\ttest-auc:0.77955+0.01836\n",
      "[1416]\ttrain-auc:0.96942+0.00109\ttest-auc:0.77953+0.01834\n",
      "[1417]\ttrain-auc:0.96943+0.00108\ttest-auc:0.77956+0.01837\n",
      "[1418]\ttrain-auc:0.96945+0.00109\ttest-auc:0.77957+0.01835\n",
      "[1419]\ttrain-auc:0.96947+0.00109\ttest-auc:0.77959+0.01832\n",
      "[1420]\ttrain-auc:0.96950+0.00109\ttest-auc:0.77958+0.01828\n",
      "[1421]\ttrain-auc:0.96954+0.00109\ttest-auc:0.77961+0.01828\n",
      "[1422]\ttrain-auc:0.96956+0.00109\ttest-auc:0.77960+0.01826\n",
      "[1423]\ttrain-auc:0.96959+0.00108\ttest-auc:0.77961+0.01826\n",
      "[1424]\ttrain-auc:0.96961+0.00107\ttest-auc:0.77962+0.01825\n",
      "[1425]\ttrain-auc:0.96962+0.00107\ttest-auc:0.77963+0.01825\n",
      "[1426]\ttrain-auc:0.96966+0.00107\ttest-auc:0.77963+0.01823\n",
      "[1427]\ttrain-auc:0.96967+0.00107\ttest-auc:0.77962+0.01821\n",
      "[1428]\ttrain-auc:0.96971+0.00108\ttest-auc:0.77962+0.01822\n",
      "[1429]\ttrain-auc:0.96972+0.00108\ttest-auc:0.77962+0.01824\n",
      "[1430]\ttrain-auc:0.96974+0.00108\ttest-auc:0.77961+0.01826\n",
      "[1431]\ttrain-auc:0.96978+0.00108\ttest-auc:0.77959+0.01827\n",
      "[1432]\ttrain-auc:0.96980+0.00109\ttest-auc:0.77957+0.01824\n",
      "[1433]\ttrain-auc:0.96982+0.00108\ttest-auc:0.77954+0.01823\n",
      "[1434]\ttrain-auc:0.96984+0.00108\ttest-auc:0.77956+0.01823\n",
      "[1435]\ttrain-auc:0.96988+0.00109\ttest-auc:0.77953+0.01823\n",
      "[1436]\ttrain-auc:0.96989+0.00110\ttest-auc:0.77952+0.01823\n",
      "[1437]\ttrain-auc:0.96992+0.00109\ttest-auc:0.77955+0.01825\n",
      "[1438]\ttrain-auc:0.96997+0.00108\ttest-auc:0.77957+0.01822\n",
      "[1439]\ttrain-auc:0.96999+0.00109\ttest-auc:0.77957+0.01823\n",
      "[1440]\ttrain-auc:0.97000+0.00109\ttest-auc:0.77954+0.01822\n",
      "[1441]\ttrain-auc:0.97003+0.00108\ttest-auc:0.77955+0.01826\n",
      "[1442]\ttrain-auc:0.97008+0.00108\ttest-auc:0.77960+0.01826\n",
      "[1443]\ttrain-auc:0.97009+0.00109\ttest-auc:0.77964+0.01831\n",
      "[1444]\ttrain-auc:0.97014+0.00108\ttest-auc:0.77966+0.01830\n",
      "[1445]\ttrain-auc:0.97016+0.00109\ttest-auc:0.77969+0.01828\n",
      "[1446]\ttrain-auc:0.97019+0.00109\ttest-auc:0.77967+0.01825\n",
      "[1447]\ttrain-auc:0.97022+0.00108\ttest-auc:0.77968+0.01829\n",
      "[1448]\ttrain-auc:0.97026+0.00108\ttest-auc:0.77968+0.01828\n",
      "[1449]\ttrain-auc:0.97028+0.00109\ttest-auc:0.77970+0.01826\n",
      "[1450]\ttrain-auc:0.97031+0.00110\ttest-auc:0.77974+0.01827\n",
      "[1451]\ttrain-auc:0.97032+0.00109\ttest-auc:0.77973+0.01828\n",
      "[1452]\ttrain-auc:0.97034+0.00109\ttest-auc:0.77974+0.01825\n",
      "[1453]\ttrain-auc:0.97036+0.00109\ttest-auc:0.77975+0.01824\n",
      "[1454]\ttrain-auc:0.97038+0.00108\ttest-auc:0.77977+0.01824\n",
      "[1455]\ttrain-auc:0.97041+0.00108\ttest-auc:0.77978+0.01824\n",
      "[1456]\ttrain-auc:0.97044+0.00106\ttest-auc:0.77980+0.01827\n",
      "[1457]\ttrain-auc:0.97046+0.00106\ttest-auc:0.77981+0.01829\n",
      "[1458]\ttrain-auc:0.97048+0.00107\ttest-auc:0.77980+0.01831\n",
      "[1459]\ttrain-auc:0.97050+0.00106\ttest-auc:0.77981+0.01832\n",
      "[1460]\ttrain-auc:0.97051+0.00106\ttest-auc:0.77981+0.01831\n",
      "[1461]\ttrain-auc:0.97054+0.00107\ttest-auc:0.77984+0.01833\n",
      "[1462]\ttrain-auc:0.97057+0.00106\ttest-auc:0.77986+0.01834\n",
      "[1463]\ttrain-auc:0.97060+0.00107\ttest-auc:0.77988+0.01835\n",
      "[1464]\ttrain-auc:0.97062+0.00106\ttest-auc:0.77985+0.01834\n",
      "[1465]\ttrain-auc:0.97064+0.00105\ttest-auc:0.77986+0.01831\n",
      "[1466]\ttrain-auc:0.97066+0.00104\ttest-auc:0.77985+0.01828\n",
      "[1467]\ttrain-auc:0.97069+0.00103\ttest-auc:0.77984+0.01829\n",
      "[1468]\ttrain-auc:0.97070+0.00103\ttest-auc:0.77982+0.01829\n",
      "[1469]\ttrain-auc:0.97072+0.00103\ttest-auc:0.77986+0.01826\n",
      "[1470]\ttrain-auc:0.97074+0.00104\ttest-auc:0.77985+0.01827\n",
      "[1471]\ttrain-auc:0.97076+0.00104\ttest-auc:0.77983+0.01827\n",
      "[1472]\ttrain-auc:0.97078+0.00103\ttest-auc:0.77985+0.01824\n",
      "[1473]\ttrain-auc:0.97082+0.00103\ttest-auc:0.77984+0.01820\n",
      "[1474]\ttrain-auc:0.97085+0.00102\ttest-auc:0.77984+0.01821\n",
      "[1475]\ttrain-auc:0.97087+0.00102\ttest-auc:0.77984+0.01819\n",
      "[1476]\ttrain-auc:0.97089+0.00103\ttest-auc:0.77985+0.01821\n",
      "[1477]\ttrain-auc:0.97091+0.00104\ttest-auc:0.77988+0.01819\n",
      "[1478]\ttrain-auc:0.97093+0.00104\ttest-auc:0.77987+0.01821\n",
      "[1479]\ttrain-auc:0.97095+0.00104\ttest-auc:0.77983+0.01822\n",
      "[1480]\ttrain-auc:0.97098+0.00104\ttest-auc:0.77984+0.01819\n",
      "[1481]\ttrain-auc:0.97101+0.00105\ttest-auc:0.77984+0.01817\n",
      "[1482]\ttrain-auc:0.97104+0.00105\ttest-auc:0.77983+0.01817\n",
      "[1483]\ttrain-auc:0.97107+0.00107\ttest-auc:0.77980+0.01807\n",
      "[1484]\ttrain-auc:0.97108+0.00107\ttest-auc:0.77981+0.01807\n",
      "[1485]\ttrain-auc:0.97111+0.00107\ttest-auc:0.77984+0.01806\n",
      "[1486]\ttrain-auc:0.97114+0.00107\ttest-auc:0.77986+0.01804\n",
      "[1487]\ttrain-auc:0.97117+0.00108\ttest-auc:0.77985+0.01804\n",
      "[1488]\ttrain-auc:0.97119+0.00107\ttest-auc:0.77987+0.01806\n",
      "[1489]\ttrain-auc:0.97120+0.00107\ttest-auc:0.77985+0.01803\n",
      "[1490]\ttrain-auc:0.97124+0.00107\ttest-auc:0.77988+0.01805\n",
      "[1491]\ttrain-auc:0.97125+0.00108\ttest-auc:0.77987+0.01805\n",
      "[1492]\ttrain-auc:0.97129+0.00107\ttest-auc:0.77988+0.01803\n",
      "[1493]\ttrain-auc:0.97132+0.00107\ttest-auc:0.77990+0.01804\n",
      "[1494]\ttrain-auc:0.97133+0.00106\ttest-auc:0.77989+0.01804\n",
      "[1495]\ttrain-auc:0.97135+0.00107\ttest-auc:0.77990+0.01806\n",
      "[1496]\ttrain-auc:0.97137+0.00107\ttest-auc:0.77990+0.01804\n",
      "[1497]\ttrain-auc:0.97140+0.00108\ttest-auc:0.77989+0.01801\n",
      "[1498]\ttrain-auc:0.97143+0.00105\ttest-auc:0.77984+0.01801\n",
      "[1499]\ttrain-auc:0.97147+0.00104\ttest-auc:0.77984+0.01801\n",
      "[1500]\ttrain-auc:0.97149+0.00104\ttest-auc:0.77982+0.01799\n",
      "[1501]\ttrain-auc:0.97151+0.00105\ttest-auc:0.77982+0.01799\n",
      "[1502]\ttrain-auc:0.97153+0.00105\ttest-auc:0.77981+0.01797\n",
      "[1503]\ttrain-auc:0.97154+0.00105\ttest-auc:0.77981+0.01795\n",
      "[1504]\ttrain-auc:0.97157+0.00104\ttest-auc:0.77982+0.01798\n",
      "[1505]\ttrain-auc:0.97160+0.00104\ttest-auc:0.77979+0.01800\n",
      "[1506]\ttrain-auc:0.97164+0.00104\ttest-auc:0.77980+0.01797\n",
      "[1507]\ttrain-auc:0.97165+0.00103\ttest-auc:0.77982+0.01797\n",
      "[1508]\ttrain-auc:0.97166+0.00103\ttest-auc:0.77980+0.01800\n",
      "[1509]\ttrain-auc:0.97169+0.00103\ttest-auc:0.77979+0.01800\n",
      "[1510]\ttrain-auc:0.97171+0.00102\ttest-auc:0.77977+0.01800\n",
      "[1511]\ttrain-auc:0.97175+0.00101\ttest-auc:0.77978+0.01799\n",
      "[1512]\ttrain-auc:0.97177+0.00101\ttest-auc:0.77979+0.01800\n",
      "[1513]\ttrain-auc:0.97179+0.00101\ttest-auc:0.77976+0.01803\n",
      "[1514]\ttrain-auc:0.97181+0.00101\ttest-auc:0.77976+0.01804\n",
      "[1515]\ttrain-auc:0.97183+0.00101\ttest-auc:0.77974+0.01801\n",
      "[1516]\ttrain-auc:0.97186+0.00103\ttest-auc:0.77976+0.01800\n",
      "[1517]\ttrain-auc:0.97188+0.00103\ttest-auc:0.77976+0.01798\n",
      "[1518]\ttrain-auc:0.97190+0.00104\ttest-auc:0.77973+0.01799\n",
      "[1519]\ttrain-auc:0.97191+0.00105\ttest-auc:0.77975+0.01799\n",
      "[1520]\ttrain-auc:0.97193+0.00104\ttest-auc:0.77974+0.01796\n",
      "[1521]\ttrain-auc:0.97195+0.00104\ttest-auc:0.77975+0.01797\n",
      "[1522]\ttrain-auc:0.97197+0.00104\ttest-auc:0.77974+0.01798\n",
      "[1523]\ttrain-auc:0.97199+0.00105\ttest-auc:0.77976+0.01799\n",
      "[1524]\ttrain-auc:0.97201+0.00105\ttest-auc:0.77975+0.01799\n",
      "[1525]\ttrain-auc:0.97203+0.00104\ttest-auc:0.77976+0.01797\n",
      "[1526]\ttrain-auc:0.97205+0.00105\ttest-auc:0.77973+0.01796\n",
      "[1527]\ttrain-auc:0.97207+0.00105\ttest-auc:0.77978+0.01799\n",
      "[1528]\ttrain-auc:0.97209+0.00105\ttest-auc:0.77979+0.01801\n",
      "[1529]\ttrain-auc:0.97211+0.00105\ttest-auc:0.77979+0.01800\n",
      "[1530]\ttrain-auc:0.97213+0.00105\ttest-auc:0.77979+0.01797\n",
      "[1531]\ttrain-auc:0.97215+0.00105\ttest-auc:0.77978+0.01799\n",
      "[1532]\ttrain-auc:0.97218+0.00104\ttest-auc:0.77978+0.01803\n",
      "[1533]\ttrain-auc:0.97221+0.00104\ttest-auc:0.77976+0.01802\n",
      "[1534]\ttrain-auc:0.97222+0.00104\ttest-auc:0.77975+0.01803\n",
      "[1535]\ttrain-auc:0.97224+0.00104\ttest-auc:0.77974+0.01803\n",
      "[1536]\ttrain-auc:0.97225+0.00104\ttest-auc:0.77975+0.01802\n",
      "[1537]\ttrain-auc:0.97228+0.00104\ttest-auc:0.77979+0.01801\n",
      "[1538]\ttrain-auc:0.97231+0.00104\ttest-auc:0.77976+0.01800\n",
      "[1539]\ttrain-auc:0.97233+0.00104\ttest-auc:0.77975+0.01799\n",
      "[1540]\ttrain-auc:0.97234+0.00103\ttest-auc:0.77970+0.01801\n",
      "[1541]\ttrain-auc:0.97236+0.00103\ttest-auc:0.77970+0.01800\n",
      "[1542]\ttrain-auc:0.97238+0.00101\ttest-auc:0.77972+0.01802\n",
      "[1543]\ttrain-auc:0.97240+0.00101\ttest-auc:0.77968+0.01802\n",
      "[1544]\ttrain-auc:0.97242+0.00101\ttest-auc:0.77969+0.01795\n",
      "[1545]\ttrain-auc:0.97244+0.00101\ttest-auc:0.77967+0.01796\n",
      "[1546]\ttrain-auc:0.97247+0.00101\ttest-auc:0.77965+0.01795\n",
      "[1547]\ttrain-auc:0.97248+0.00102\ttest-auc:0.77967+0.01794\n",
      "[1548]\ttrain-auc:0.97250+0.00101\ttest-auc:0.77970+0.01794\n",
      "[1549]\ttrain-auc:0.97252+0.00099\ttest-auc:0.77973+0.01793\n",
      "[1550]\ttrain-auc:0.97254+0.00099\ttest-auc:0.77974+0.01795\n",
      "[1551]\ttrain-auc:0.97256+0.00099\ttest-auc:0.77970+0.01798\n",
      "[1552]\ttrain-auc:0.97258+0.00099\ttest-auc:0.77973+0.01800\n",
      "[1553]\ttrain-auc:0.97261+0.00097\ttest-auc:0.77971+0.01798\n",
      "[1554]\ttrain-auc:0.97263+0.00098\ttest-auc:0.77973+0.01798\n",
      "[1555]\ttrain-auc:0.97265+0.00097\ttest-auc:0.77970+0.01797\n",
      "[1556]\ttrain-auc:0.97268+0.00098\ttest-auc:0.77973+0.01793\n",
      "[1557]\ttrain-auc:0.97270+0.00098\ttest-auc:0.77972+0.01796\n",
      "[1558]\ttrain-auc:0.97272+0.00098\ttest-auc:0.77972+0.01797\n",
      "[1559]\ttrain-auc:0.97275+0.00097\ttest-auc:0.77969+0.01794\n",
      "[1560]\ttrain-auc:0.97277+0.00097\ttest-auc:0.77970+0.01791\n",
      "[1561]\ttrain-auc:0.97280+0.00098\ttest-auc:0.77968+0.01790\n",
      "[1562]\ttrain-auc:0.97282+0.00098\ttest-auc:0.77965+0.01791\n",
      "[1563]\ttrain-auc:0.97284+0.00099\ttest-auc:0.77971+0.01789\n",
      "[1564]\ttrain-auc:0.97287+0.00100\ttest-auc:0.77970+0.01787\n",
      "[1565]\ttrain-auc:0.97289+0.00100\ttest-auc:0.77968+0.01789\n",
      "[1566]\ttrain-auc:0.97291+0.00099\ttest-auc:0.77969+0.01786\n",
      "[1567]\ttrain-auc:0.97294+0.00099\ttest-auc:0.77970+0.01789\n",
      "[1568]\ttrain-auc:0.97296+0.00099\ttest-auc:0.77969+0.01791\n",
      "[1569]\ttrain-auc:0.97298+0.00098\ttest-auc:0.77970+0.01792\n",
      "[1570]\ttrain-auc:0.97300+0.00098\ttest-auc:0.77973+0.01791\n",
      "[1571]\ttrain-auc:0.97302+0.00099\ttest-auc:0.77977+0.01790\n",
      "[1572]\ttrain-auc:0.97304+0.00099\ttest-auc:0.77977+0.01790\n",
      "[1573]\ttrain-auc:0.97306+0.00098\ttest-auc:0.77978+0.01794\n",
      "[1574]\ttrain-auc:0.97308+0.00098\ttest-auc:0.77977+0.01796\n",
      "[1575]\ttrain-auc:0.97310+0.00096\ttest-auc:0.77979+0.01793\n",
      "[1576]\ttrain-auc:0.97311+0.00096\ttest-auc:0.77978+0.01792\n",
      "[1577]\ttrain-auc:0.97313+0.00095\ttest-auc:0.77977+0.01793\n",
      "[1578]\ttrain-auc:0.97316+0.00095\ttest-auc:0.77980+0.01794\n",
      "[1579]\ttrain-auc:0.97317+0.00095\ttest-auc:0.77981+0.01796\n",
      "[1580]\ttrain-auc:0.97319+0.00095\ttest-auc:0.77976+0.01792\n",
      "[1581]\ttrain-auc:0.97320+0.00096\ttest-auc:0.77976+0.01791\n",
      "[1582]\ttrain-auc:0.97321+0.00095\ttest-auc:0.77978+0.01789\n",
      "[1583]\ttrain-auc:0.97324+0.00094\ttest-auc:0.77976+0.01787\n",
      "[1584]\ttrain-auc:0.97326+0.00094\ttest-auc:0.77976+0.01790\n",
      "[1585]\ttrain-auc:0.97328+0.00093\ttest-auc:0.77977+0.01789\n",
      "[1586]\ttrain-auc:0.97329+0.00094\ttest-auc:0.77980+0.01786\n",
      "[1587]\ttrain-auc:0.97333+0.00096\ttest-auc:0.77979+0.01785\n",
      "[1588]\ttrain-auc:0.97336+0.00096\ttest-auc:0.77983+0.01780\n",
      "[1589]\ttrain-auc:0.97337+0.00096\ttest-auc:0.77984+0.01781\n",
      "[1590]\ttrain-auc:0.97340+0.00095\ttest-auc:0.77988+0.01783\n",
      "[1591]\ttrain-auc:0.97342+0.00096\ttest-auc:0.77987+0.01783\n",
      "[1592]\ttrain-auc:0.97344+0.00096\ttest-auc:0.77988+0.01783\n",
      "Stopping. Best iteration:\n",
      "[1493]\ttrain-auc:0.97132+0.00107\ttest-auc:0.77990+0.01804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\training.py:20: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html\n",
      "  warnings.warn(f'Old style callback is deprecated.  See: {link}', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_result = xgb.cv(xgb1.get_xgb_params(),\n",
    "dtrain,\n",
    "num_boost_round=xgb1.get_params()['n_estimators'],\n",
    "nfold=5,\n",
    "metrics='auc',\n",
    "early_stopping_rounds=100,\n",
    "callbacks=[xgb.callback.early_stop(100),\n",
    "xgb.callback.print_evaluation(period=1,show_stdv=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.01,\n",
    "                     n_estimators=1493,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.5396533759377605 0.6557614091968331\n",
      "f1= 0.1463414634146341 0.4736164736164737\n",
      "precision_score= 0.7272727272727273 0.983957219251337\n",
      "recall_score= 0.08135593220338982 0.31186440677966104\n",
      "accuracy= 0.940260294431406 0.9563616964523873\n",
      "auc= 0.5396533759377605 0.6557614091968331\n",
      "#####混淆矩阵#########\n",
      "[[4383    9]\n",
      " [ 271   24]] [[17559     6]\n",
      " [  812   368]]\n"
     ]
    }
   ],
   "source": [
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(max_depth=8,\n",
    "                     learning_rate=0.05,\n",
    "                     n_estimators=6000,\n",
    "                     objective='binary:logistic',\n",
    "                     booster='gbtree',\n",
    "                     n_jobs=4,\n",
    "                     gamma=0.1,\n",
    "                     min_child_weight=1,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost结果\n",
      "balanced_accuracy_score= 0.6490004939643728 0.9901371178238696\n",
      "f1= 0.42129629629629634 0.982605006364022\n",
      "precision_score= 0.6642335766423357 0.983857264231096\n",
      "recall_score= 0.30847457627118646 0.9813559322033898\n",
      "accuracy= 0.9466609771708983 0.9978127500666845\n",
      "auc= 0.6490004939643728 0.9901371178238696\n",
      "#####混淆矩阵#########\n",
      "[[4346   46]\n",
      " [ 204   91]] [[17546    19]\n",
      " [   22  1158]]\n"
     ]
    }
   ],
   "source": [
    "xgb_bst1 = xgb1.fit(x_train, y_train)\n",
    "y_pred = xgb_bst1.predict(x_test)\n",
    "y_pred2 = xgb_bst1.predict(x_train)\n",
    "print(\"XGBoost结果\")\n",
    "print(\"balanced_accuracy_score=\", balanced_accuracy_score(y_pred=y_pred, y_true=y_test),balanced_accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"f1=\", f1_score(y_pred=y_pred, y_true=y_test), f1_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"precision_score=\", precision_score(y_pred=y_pred, y_true=y_test),precision_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"recall_score=\", recall_score(y_pred=y_pred, y_true=y_test), recall_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"accuracy=\", accuracy_score(y_pred=y_pred, y_true=y_test), accuracy_score(y_pred=y_pred2, y_true=y_train))\n",
    "print(\"auc=\", roc_auc_score(y_true=y_test, y_score=y_pred), roc_auc_score(y_true=y_train, y_score=y_pred2))\n",
    "print(\"#####混淆矩阵#########\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred), confusion_matrix(y_true=y_train, y_pred=y_pred2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
